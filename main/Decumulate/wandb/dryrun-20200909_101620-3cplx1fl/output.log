[%]GPU Enabled
/home/puntawat/Mint/Work/Vision/BallTrajectory/UnityDataset//RealWorld/Unity/Mixed/NormalScaled/No_noise/val_set
Mixed:   0%|                                                                                                                               | 0/2 [00:00<?, ?it/s]Mixed: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 14.98it/s]Mixed: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 14.95it/s]
===============================Dataset shape===============================
Mixed : (2000,)
===========================================================================
Mixed:   0%|                                                                                                                               | 0/2 [00:00<?, ?it/s]Mixed: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 16.37it/s]Mixed: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 16.34it/s]
===============================Dataset shape===============================
Mixed : (2000,)
===========================================================================
======================================================Summary Batch (batch_size = 128)=========================================================================
Input batch [0] : batch=torch.Size([128, 1953, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1953, 3]), initial position=torch.Size([128, 1, 4])
Output batch [0] : batch=torch.Size([128, 1954, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1954, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [1] : batch=torch.Size([128, 2097, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2097, 3]), initial position=torch.Size([128, 1, 4])
Output batch [1] : batch=torch.Size([128, 2098, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2098, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [2] : batch=torch.Size([128, 2028, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2028, 3]), initial position=torch.Size([128, 1, 4])
Output batch [2] : batch=torch.Size([128, 2029, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2029, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [3] : batch=torch.Size([128, 2364, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2364, 3]), initial position=torch.Size([128, 1, 4])
Output batch [3] : batch=torch.Size([128, 2365, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2365, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [4] : batch=torch.Size([128, 2024, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2024, 3]), initial position=torch.Size([128, 1, 4])
Output batch [4] : batch=torch.Size([128, 2025, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2025, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [5] : batch=torch.Size([128, 2248, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2248, 3]), initial position=torch.Size([128, 1, 4])
Output batch [5] : batch=torch.Size([128, 2249, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2249, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [6] : batch=torch.Size([128, 1886, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1886, 3]), initial position=torch.Size([128, 1, 4])
Output batch [6] : batch=torch.Size([128, 1887, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1887, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [7] : batch=torch.Size([128, 1860, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1860, 3]), initial position=torch.Size([128, 1, 4])
Output batch [7] : batch=torch.Size([128, 1861, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1861, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [8] : batch=torch.Size([128, 2028, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2028, 3]), initial position=torch.Size([128, 1, 4])
Output batch [8] : batch=torch.Size([128, 2029, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2029, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [9] : batch=torch.Size([128, 2112, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2112, 3]), initial position=torch.Size([128, 1, 4])
Output batch [9] : batch=torch.Size([128, 2113, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2113, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [10] : batch=torch.Size([128, 1952, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1952, 3]), initial position=torch.Size([128, 1, 4])
Output batch [10] : batch=torch.Size([128, 1953, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1953, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [11] : batch=torch.Size([128, 1910, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1910, 3]), initial position=torch.Size([128, 1, 4])
Output batch [11] : batch=torch.Size([128, 1911, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1911, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [12] : batch=torch.Size([128, 2109, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2109, 3]), initial position=torch.Size([128, 1, 4])
Output batch [12] : batch=torch.Size([128, 2110, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2110, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [13] : batch=torch.Size([128, 1904, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1904, 3]), initial position=torch.Size([128, 1, 4])
Output batch [13] : batch=torch.Size([128, 1905, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1905, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [14] : batch=torch.Size([128, 2171, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2171, 3]), initial position=torch.Size([128, 1, 4])
Output batch [14] : batch=torch.Size([128, 2172, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2172, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
===>No model checkpoint
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - EOT #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(2, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
####### Model - Depth #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(3, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.001
train_ball_trajectory_depth_jointly_decumulate.py:246: RuntimeWarning:

invalid value encountered in long_scalars

===> [Minibatch 1/15].........Train Loss : 18797.762, Val Loss : 813048.938
======> Trajectory Loss : 895.692, Gravity Loss : 970204.500, EndOfTrajectory Loss : 1.388
Opening in existing browser session.
[0909/171634.028518:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
train_ball_trajectory_depth_jointly_decumulate.py:246: RuntimeWarning:

invalid value encountered in long_scalars

===> [Minibatch 2/15].........Train Loss : 18370.055, Val Loss : 784591.062
======> Trajectory Loss : 934.431, Gravity Loss : 888695.625, EndOfTrajectory Loss : 1.388
===> [Minibatch 3/15].........Train Loss : 16022.721, Val Loss : 758542.750
======> Trajectory Loss : 857.661, Gravity Loss : 730747.625, EndOfTrajectory Loss : 1.386
===> [Minibatch 4/15].........Train Loss : 16479.918, Val Loss : 732990.875
======> Trajectory Loss : 837.758, Gravity Loss : 796379.000, EndOfTrajectory Loss : 1.385
===> [Minibatch 5/15].........Train Loss : 15416.352, Val Loss : 706811.875
======> Trajectory Loss : 825.401, Gravity Loss : 702373.375, EndOfTrajectory Loss : 1.386
===> [Minibatch 6/15].........Train Loss : 14905.669, Val Loss : 679711.000
======> Trajectory Loss : 780.943, Gravity Loss : 695791.438, EndOfTrajectory Loss : 1.383
===> [Minibatch 7/15].........Train Loss : 13221.953, Val Loss : 657077.750
======> Trajectory Loss : 697.213, Gravity Loss : 611150.812, EndOfTrajectory Loss : 1.383
===> [Minibatch 8/15].........Train Loss : 13662.859, Val Loss : 646420.938
======> Trajectory Loss : 705.119, Gravity Loss : 647326.125, EndOfTrajectory Loss : 1.384
===> [Minibatch 9/15].........Train Loss : 14705.283, Val Loss : 635022.562
======> Trajectory Loss : 709.088, Gravity Loss : 747601.312, EndOfTrajectory Loss : 1.384
