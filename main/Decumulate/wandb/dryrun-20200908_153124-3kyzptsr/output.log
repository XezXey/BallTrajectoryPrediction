[%]GPU Enabled
/home/puntawat/Mint/Work/Vision/BallTrajectory/UnityDataset//RealWorld/Unity/Mixed/NormalScaled/No_noise/val_set
Mixed:   0%|                                                                                                     | 0/2 [00:00<?, ?it/s]Mixed: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 16.81it/s]===============================Dataset shape===============================
Mixed: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 16.77it/s]
Mixed : (2000,)
===========================================================================
Mixed:   0%|                                                                                                     | 0/2 [00:00<?, ?it/s]Mixed: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 16.60it/s]Mixed: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 16.56it/s]
===============================Dataset shape===============================
Mixed : (2000,)
===========================================================================
======================================================Summary Batch (batch_size = 128)=========================================================================
Input batch [0] : batch=torch.Size([128, 2112, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2112, 3]), initial position=torch.Size([128, 1, 4])
Output batch [0] : batch=torch.Size([128, 2113, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2113, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [1] : batch=torch.Size([128, 2187, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2187, 3]), initial position=torch.Size([128, 1, 4])
Output batch [1] : batch=torch.Size([128, 2188, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2188, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [2] : batch=torch.Size([128, 2171, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2171, 3]), initial position=torch.Size([128, 1, 4])
Output batch [2] : batch=torch.Size([128, 2172, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2172, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [3] : batch=torch.Size([128, 2028, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2028, 3]), initial position=torch.Size([128, 1, 4])
Output batch [3] : batch=torch.Size([128, 2029, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2029, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [4] : batch=torch.Size([128, 1836, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1836, 3]), initial position=torch.Size([128, 1, 4])
Output batch [4] : batch=torch.Size([128, 1837, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1837, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [5] : batch=torch.Size([128, 1953, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1953, 3]), initial position=torch.Size([128, 1, 4])
Output batch [5] : batch=torch.Size([128, 1954, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1954, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [6] : batch=torch.Size([128, 2024, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2024, 3]), initial position=torch.Size([128, 1, 4])
Output batch [6] : batch=torch.Size([128, 2025, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2025, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [7] : batch=torch.Size([128, 2049, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2049, 3]), initial position=torch.Size([128, 1, 4])
Output batch [7] : batch=torch.Size([128, 2050, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2050, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [8] : batch=torch.Size([128, 2097, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2097, 3]), initial position=torch.Size([128, 1, 4])
Output batch [8] : batch=torch.Size([128, 2098, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2098, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [9] : batch=torch.Size([128, 2364, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2364, 3]), initial position=torch.Size([128, 1, 4])
Output batch [9] : batch=torch.Size([128, 2365, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2365, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [10] : batch=torch.Size([128, 1775, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1775, 3]), initial position=torch.Size([128, 1, 4])
Output batch [10] : batch=torch.Size([128, 1776, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1776, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [11] : batch=torch.Size([128, 2255, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2255, 3]), initial position=torch.Size([128, 1, 4])
Output batch [11] : batch=torch.Size([128, 2256, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2256, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [12] : batch=torch.Size([128, 2022, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2022, 3]), initial position=torch.Size([128, 1, 4])
Output batch [12] : batch=torch.Size([128, 2023, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2023, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [13] : batch=torch.Size([128, 2109, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2109, 3]), initial position=torch.Size([128, 1, 4])
Output batch [13] : batch=torch.Size([128, 2110, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2110, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [14] : batch=torch.Size([128, 2248, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 2248, 3]), initial position=torch.Size([128, 1, 4])
Output batch [14] : batch=torch.Size([128, 2249, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 2249, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
===>No model checkpoint
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - EOT #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(2, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
####### Model - Depth #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(3, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.001
===> [Minibatch 1/15].........torch.Size([128, 2171, 1]) torch.Size([128, 2171, 2]) torch.Size([128, 1, 4]) torch.Size([128, 2171, 1])
tensor([[  0],
        [196]], device='cuda:0')
[tensor([[53.7264],
        [ 0.4875],
        [ 0.4877],
        [ 0.4879],
        [ 0.4880],
        [ 0.4884],
        [ 0.4882],
        [ 0.4883],
        [ 0.4885],
        [ 0.4886],
        [ 0.4884],
        [ 0.4886],
        [ 0.4886],
        [ 0.4886],
        [ 0.4886],
        [ 0.4884],
        [ 0.4884],
        [ 0.4885],
        [ 0.4884],
        [ 0.4884],
        [ 0.4884],
        [ 0.4884],
        [ 0.4884],
        [ 0.4884],
        [ 0.4884],
        [ 0.4884],
        [ 0.4884],
        [ 0.4883],
        [ 0.4884],
        [ 0.4883],
        [ 0.4883],
        [ 0.4883],
        [ 0.4882],
        [ 0.4882],
        [ 0.4886],
        [ 0.4881],
        [ 0.4882],
        [ 0.4882],
        [ 0.4882],
        [ 0.4882],
        [ 0.4883],
        [ 0.4880],
        [ 0.4880],
        [ 0.4881],
        [ 0.4881],
        [ 0.4882],
        [ 0.4879],
        [ 0.4879],
        [ 0.4881],
        [ 0.4880],
        [ 0.4879],
        [ 0.4879],
        [ 0.4879],
        [ 0.4877],
        [ 0.4879],
        [ 0.4879],
        [ 0.4879],
        [ 0.4878],
        [ 0.4877],
        [ 0.4877],
        [ 0.4877],
        [ 0.4877],
        [ 0.4876],
        [ 0.4876],
        [ 0.4876],
        [ 0.4875],
        [ 0.4875],
        [ 0.4875],
        [ 0.4875],
        [ 0.4874],
        [ 0.4876],
        [ 0.4876],
        [ 0.4875],
        [ 0.4873],
        [ 0.4872],
        [ 0.4873],
        [ 0.4872],
        [ 0.4874],
        [ 0.4874],
        [ 0.4872],
        [ 0.4872],
        [ 0.4872],
        [ 0.4871],
        [ 0.4870],
        [ 0.4872],
        [ 0.4872],
        [ 0.4870],
        [ 0.4867],
        [ 0.4868],
        [ 0.4867],
        [ 0.4867],
        [ 0.4866],
        [ 0.4866],
        [ 0.4865],
        [ 0.4866],
        [ 0.4864],
        [ 0.4864],
        [ 0.4864],
        [ 0.4864],
        [ 0.4862],
        [ 0.4861],
        [ 0.4860],
        [ 0.4860],
        [ 0.4859],
        [ 0.4859],
        [ 0.4859],
        [ 0.4858],
        [ 0.4858],
        [ 0.4860],
        [ 0.4859],
        [ 0.4860],
        [ 0.4859],
        [ 0.4859],
        [ 0.4859],
        [ 0.4858],
        [ 0.4858],
        [ 0.4858],
        [ 0.4857],
        [ 0.4858],
        [ 0.4858],
        [ 0.4859],
        [ 0.4859],
        [ 0.4860],
        [ 0.4861],
        [ 0.4861],
        [ 0.4863],
        [ 0.4863],
        [ 0.4863],
        [ 0.4864],
        [ 0.4863],
        [ 0.4864],
        [ 0.4869],
        [ 0.4867],
        [ 0.4867],
        [ 0.4871],
        [ 0.4869],
        [ 0.4870],
        [ 0.4867],
        [ 0.4874],
        [ 0.4871],
        [ 0.4872],
        [ 0.4871],
        [ 0.4876],
        [ 0.4874],
        [ 0.4874],
        [ 0.4873],
        [ 0.4874],
        [ 0.4874],
        [ 0.4875],
        [ 0.4875],
        [ 0.4874],
        [ 0.4874],
        [ 0.4874],
        [ 0.4875],
        [ 0.4876],
        [ 0.4875],
        [ 0.4874],
        [ 0.4874],
        [ 0.4873],
        [ 0.4875],
        [ 0.4883],
        [ 0.4879],
        [ 0.4878],
        [ 0.4877],
        [ 0.4875],
        [ 0.4875],
        [ 0.4875],
        [ 0.4876],
        [ 0.4876],
        [ 0.4876],
        [ 0.4876],
        [ 0.4876],
        [ 0.4876],
        [ 0.4877],
        [ 0.4876],
        [ 0.4878],
        [ 0.4880],
        [ 0.4879],
        [ 0.4877],
        [ 0.4879],
        [ 0.4877],
        [ 0.4878],
        [ 0.4878],
        [ 0.4876],
        [ 0.4876],
        [ 0.4878],
        [ 0.4879],
        [ 0.4880],
        [ 0.4879],
        [ 0.4879],
        [ 0.4878],
        [ 0.4877],
        [ 0.4881],
        [ 0.4879],
        [ 0.4886],
        [ 0.4901],
        [ 0.4918]], device='cuda:0', grad_fn=<CatBackward>)]
Traceback (most recent call last):
  File "train_ball_trajectory_depth_jointly_decumulate.py", line 691, in <module>
    optimizer=optimizer, epoch=epoch, n_epochs=n_epochs, vis_signal=vis_signal, width=width, height=height)
  File "train_ball_trajectory_depth_jointly_decumulate.py", line 382, in train
    output_train_depth, input_trajectory_train_uv = cumsum_decumulate_trajectory(depth=output_train_depth, uv=input_trajectory_train_gt[..., :-1], trajectory_startpos=input_trajectory_train_startpos, lengths=input_trajectory_train_lengths, eot=input_trajectory_train_gt[..., -1].unsqueeze(dim=-1), projection_matrix=projection_matrix, camera_to_world_matrix=camera_to_world_matrix, width=width, height=height)
  File "train_ball_trajectory_depth_jointly_decumulate.py", line 344, in cumsum_decumulate_trajectory
    depth_cumsum = [split_cumsum(reset_idx=reset_idx[i][0], lengths=lengths, reset_depth=reset_depth[i], depth=depth[i]) for i in range(trajectory_startpos.shape[0])]
  File "train_ball_trajectory_depth_jointly_decumulate.py", line 344, in <listcomp>
    depth_cumsum = [split_cumsum(reset_idx=reset_idx[i][0], lengths=lengths, reset_depth=reset_depth[i], depth=depth[i]) for i in range(trajectory_startpos.shape[0])]
  File "train_ball_trajectory_depth_jointly_decumulate.py", line 313, in split_cumsum
    depth_chunk_cumsum = [pt.cumsum(each_depth_chunk) for each_depth_chunk in depth_chunk]
  File "train_ball_trajectory_depth_jointly_decumulate.py", line 313, in <listcomp>
    depth_chunk_cumsum = [pt.cumsum(each_depth_chunk) for each_depth_chunk in depth_chunk]
TypeError: cumsum() received an invalid combination of arguments - got (Tensor), but expected one of:
 * (Tensor input, name dim, torch.dtype dtype, Tensor out)
 * (Tensor input, int dim, torch.dtype dtype, Tensor out)

