[%]GPU Enabled
/home/puntawat/Mint/Work/Vision/BallTrajectory/UnityDataset//RealWorld/Unity/Mixed/NormalScaled/No_noise_old/train_set
Mixed:   0%|                                                                                                | 0/1 [00:00<?, ?it/s]Mixed: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.92it/s]
===============================Dataset shape===============================
Mixed : (2035,)
===========================================================================
Mixed:   0%|                                                                                                | 0/2 [00:00<?, ?it/s]Mixed: 100%|████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 20.28it/s]
===============================Dataset shape===============================
Mixed : (2000,)
===========================================================================
======================================================Summary Batch (batch_size = 128)=========================================================================
Input batch [0] : batch=torch.Size([128, 904, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 904, 3]), initial position=torch.Size([128, 1, 4])
Output batch [0] : batch=torch.Size([128, 904, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 905, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [1] : batch=torch.Size([128, 869, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 869, 3]), initial position=torch.Size([128, 1, 4])
Output batch [1] : batch=torch.Size([128, 869, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 870, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [2] : batch=torch.Size([128, 918, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 918, 3]), initial position=torch.Size([128, 1, 4])
Output batch [2] : batch=torch.Size([128, 918, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 919, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [3] : batch=torch.Size([128, 879, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 879, 3]), initial position=torch.Size([128, 1, 4])
Output batch [3] : batch=torch.Size([128, 879, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 880, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [4] : batch=torch.Size([128, 845, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 845, 3]), initial position=torch.Size([128, 1, 4])
Output batch [4] : batch=torch.Size([128, 845, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 846, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [5] : batch=torch.Size([128, 834, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 834, 3]), initial position=torch.Size([128, 1, 4])
Output batch [5] : batch=torch.Size([128, 834, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 835, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [6] : batch=torch.Size([128, 869, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 869, 3]), initial position=torch.Size([128, 1, 4])
Output batch [6] : batch=torch.Size([128, 869, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 870, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [7] : batch=torch.Size([128, 960, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 960, 3]), initial position=torch.Size([128, 1, 4])
Output batch [7] : batch=torch.Size([128, 960, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 961, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [8] : batch=torch.Size([128, 908, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 908, 3]), initial position=torch.Size([128, 1, 4])
Output batch [8] : batch=torch.Size([128, 908, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 909, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [9] : batch=torch.Size([128, 951, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 951, 3]), initial position=torch.Size([128, 1, 4])
Output batch [9] : batch=torch.Size([128, 951, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 952, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [10] : batch=torch.Size([128, 860, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 860, 3]), initial position=torch.Size([128, 1, 4])
Output batch [10] : batch=torch.Size([128, 860, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 861, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [11] : batch=torch.Size([128, 888, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 888, 3]), initial position=torch.Size([128, 1, 4])
Output batch [11] : batch=torch.Size([128, 888, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 889, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [12] : batch=torch.Size([128, 792, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 792, 3]), initial position=torch.Size([128, 1, 4])
Output batch [12] : batch=torch.Size([128, 792, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 793, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [13] : batch=torch.Size([128, 941, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 941, 3]), initial position=torch.Size([128, 1, 4])
Output batch [13] : batch=torch.Size([128, 941, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 942, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [14] : batch=torch.Size([128, 928, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 928, 3]), initial position=torch.Size([128, 1, 4])
Output batch [14] : batch=torch.Size([128, 928, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 929, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
===>No model checkpoint
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - EOT #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(2, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
####### Model - Depth #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(3, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
===> [Minibatch 1/15].........tensor([[[0.1840],
         [0.1825],
         [0.1821],
         ...,
         [0.1832],
         [0.1840],
         [0.1826]],

        [[0.1870],
         [0.1864],
         [0.1860],
         ...,
         [0.0764],
         [0.0764],
         [0.0764]],

        [[0.1890],
         [0.1893],
         [0.1888],
         ...,
         [0.0764],
         [0.0764],
         [0.0764]],

        ...,

        [[0.1825],
         [0.1820],
         [0.1825],
         ...,
         [0.0764],
         [0.0764],
         [0.0764]],

        [[0.1843],
         [0.1835],
         [0.1833],
         ...,
         [0.0764],
         [0.0764],
         [0.0764]],

        [[0.1820],
         [0.1805],
         [0.1803],
         ...,
         [0.0764],
         [0.0764],
         [0.0764]]], device='cuda:0', grad_fn=<AddBackward0>)
tensor([[[ 996.8277,  404.0448,   53.4355,    0.0000]],

        [[ 697.7075,  439.1896,   54.9592,    0.0000]],

        [[ 731.2977,  624.7137,   65.6589,    0.0000]],

        [[ 930.4506,  696.7296,   71.1591,    0.0000]],

        [[ 979.0391,  377.8607,   52.2611,    0.0000]],

        [[ 509.2816,  295.7253,   48.7541,    0.0000]],

        [[ 842.7451,  407.0427,   53.5104,    0.0000]],

        [[ 837.9141,  630.6365,   66.1344,    0.0000]],

        [[ 847.3439,  503.7763,   58.3306,    0.0000]],

        [[1218.5250,  492.4207,   57.8926,    0.0000]],

        [[1378.3530,   98.5218,   42.4877,    0.0000]],

        [[1016.7760,  392.4824,   52.9210,    0.0000]],

        [[1002.8810,  199.3056,   45.4932,    0.0000]],

        [[ 409.5055,  317.4663,   49.5579,    0.0000]],

        [[ 953.5892,  463.0305,   56.2463,    0.0000]],

        [[ 885.6861,  421.7739,   54.2098,    0.0000]],

        [[ 404.4736,  653.5173,   67.4903,    0.0000]],

        [[ 668.3973,  547.5350,   60.7141,    0.0000]],

        [[ 837.8106,  453.3438,   55.7110,    0.0000]],

        [[ 994.3464,  550.4857,   61.0587,    0.0000]],

        [[ 624.0438,  663.8051,   68.3926,    0.0000]],

        [[ 500.6688,  751.8887,   75.5670,    0.0000]],

        [[ 930.7365,  486.4184,   57.4303,    0.0000]],

        [[ 707.4579,  467.5693,   56.3664,    0.0000]],

        [[ 536.7249,  350.2360,   50.9222,    0.0000]],

        [[ 719.2994,  621.5994,   65.4381,    0.0000]],

        [[ 965.9641,  676.5845,   69.5913,    0.0000]],

        [[ 847.8751,  527.8909,   59.6702,    0.0000]],

        [[ 632.4426,  556.6183,   61.2333,    0.0000]],

        [[ 705.3466,  544.5954,   60.5613,    0.0000]],

        [[ 586.9479,  660.0650,   68.0904,    0.0000]],

        [[ 966.6633,  527.6107,   59.7137,    0.0000]],

        [[ 569.1523,  512.3809,   58.6659,    0.0000]],

        [[1174.5070,  396.2103,   53.1512,    0.0000]],

        [[ 597.4611,  620.1646,   65.2681,    0.0000]],

        [[ 950.1818,  628.3552,   66.0448,    0.0000]],

        [[ 707.0496,  395.0739,   52.9157,    0.0000]],

        [[ 575.5259,  399.4107,   53.0582,    0.0000]],

        [[1298.8230,  472.4083,   56.8794,    0.0000]],

        [[ 756.6311,  650.0313,   67.4630,    0.0000]],

        [[ 799.3829,  517.7079,   59.0735,    0.0000]],

        [[ 663.0417,  394.9746,   52.8940,    0.0000]],

        [[ 771.0132,  299.0816,   48.9692,    0.0000]],

        [[ 812.4330,  532.2341,   59.9002,    0.0000]],

        [[ 827.1284,  550.9464,   60.9988,    0.0000]],

        [[ 713.2805,  617.9543,   65.1871,    0.0000]],

        [[1074.6851,  589.9315,   63.5422,    0.0000]],

        [[1071.1840,  597.6965,   64.0469,    0.0000]],

        [[ 659.6512,  438.0990,   54.8906,    0.0000]],

        [[ 732.9211,  461.5231,   56.0728,    0.0000]],

        [[1044.4010,  361.3818,   51.5755,    0.0000]],

        [[ 879.6461,  687.4943,   70.3858,    0.0000]],

        [[1202.2200,  629.3911,   66.2715,    0.0000]],

        [[ 705.0089,  363.8438,   51.5553,    0.0000]],

        [[1088.0730,  411.0098,   53.7850,    0.0000]],

        [[ 395.4915,  259.2787,   47.3727,    0.0000]],

        [[ 913.5931,  423.3369,   54.2948,    0.0000]],

        [[ 770.9313,  772.8167,   77.7527,    0.0000]],

        [[ 993.5151,  636.5072,   66.6442,    0.0000]],

        [[1104.1110,  642.9430,   67.1727,    0.0000]],

        [[ 932.3340,  574.9736,   62.5173,    0.0000]],

        [[ 912.0699,  427.0932,   54.4714,    0.0000]],

        [[ 803.5098,  655.3774,   67.8851,    0.0000]],

        [[1070.3040,  438.7244,   55.0951,    0.0000]],

        [[ 606.6635,  501.9331,   58.1154,    0.0000]],

        [[ 805.0643,  631.9651,   66.2052,    0.0000]],

        [[ 941.8289,  614.9784,   65.1206,    0.0000]],

        [[ 959.9127,  614.2132,   65.0792,    0.0000]],

        [[1095.3730,  407.2678,   53.6212,    0.0000]],

        [[ 880.9244,  631.2950,   66.2073,    0.0000]],

        [[1037.6150,  490.9451,   57.7310,    0.0000]],

        [[ 799.8845,  455.7877,   55.8157,    0.0000]],

        [[1033.2560,  453.9542,   55.8266,    0.0000]],

        [[ 701.3984,  644.1182,   67.0035,    0.0000]],

        [[1176.8070,  590.7812,   63.6577,    0.0000]],

        [[ 982.0437,  533.3291,   60.0487,    0.0000]],

        [[ 737.6327,  669.5701,   68.9014,    0.0000]],

        [[ 790.7426,  590.8779,   63.4451,    0.0000]],

        [[1046.8760,  710.6603,   72.3882,    0.0000]],

        [[1148.6470,  495.0016,   58.0000,    0.0000]],

        [[1065.1270,  587.0410,   63.3523,    0.0000]],

        [[ 959.7060,  503.4941,   58.3690,    0.0000]],

        [[ 622.8451,  661.3629,   68.2101,    0.0000]],

        [[ 696.6182,  381.0233,   52.2912,    0.0000]],

        [[ 758.7837,  481.9687,   57.1290,    0.0000]],

        [[ 633.4950,  148.6724,   43.7811,    0.0000]],

        [[ 837.2421,  491.0504,   57.6431,    0.0000]],

        [[ 887.8787,  417.5153,   54.0118,    0.0000]],

        [[ 693.1155,  347.9699,   50.8835,    0.0000]],

        [[ 794.8238,  549.1795,   60.8773,    0.0000]],

        [[ 923.6105,  533.5184,   60.0300,    0.0000]],

        [[ 780.3199,  397.3183,   53.0443,    0.0000]],

        [[ 921.8354,  643.0795,   67.0680,    0.0000]],

        [[ 858.2074,  555.5288,   61.2885,    0.0000]],

        [[ 859.3808,  476.1804,   56.8753,    0.0000]],

        [[ 935.6258,  557.8286,   61.4677,    0.0000]],

        [[ 872.8761,  584.7416,   63.0985,    0.0000]],

        [[ 772.6404,  423.8951,   54.2627,    0.0000]],

        [[ 891.6581,  586.3585,   63.2127,    0.0000]],

        [[1119.2460,  378.5576,   52.3443,    0.0000]],

        [[ 984.2757,  420.8270,   54.2061,    0.0000]],

        [[ 735.9229,  420.0292,   54.0666,    0.0000]],

        [[ 643.4115,  589.2686,   63.2591,    0.0000]],

        [[ 664.3919,  335.5399,   50.3562,    0.0000]],

        [[ 639.3583,  753.8344,   75.8547,    0.0000]],

        [[ 980.5153,  593.9943,   63.7537,    0.0000]],

        [[1107.8950,  447.0928,   55.5197,    0.0000]],

        [[ 964.7086,  553.5753,   61.2276,    0.0000]],

        [[ 852.7363,  624.5308,   65.7206,    0.0000]],

        [[ 848.0294,  535.7026,   60.1175,    0.0000]],

        [[1206.6470,  591.7000,   63.7337,    0.0000]],

        [[ 895.5742,  439.9655,   55.0808,    0.0000]],

        [[1021.4400,  668.7825,   69.0317,    0.0000]],

        [[ 680.6705,  360.9357,   51.4221,    0.0000]],

        [[ 609.1674,  497.9593,   57.9036,    0.0000]],

        [[ 325.9003,  530.4031,   59.5492,    0.0000]],

        [[ 834.8936,  343.7192,   50.7626,    0.0000]],

        [[1043.4120,  426.3565,   54.4912,    0.0000]],

        [[ 669.7030,  225.7428,   46.2841,    0.0000]],

        [[ 807.0839,  510.1620,   58.6600,    0.0000]],

        [[ 823.0063,  515.6458,   58.9704,    0.0000]],

        [[ 859.8473,  596.4391,   63.8412,    0.0000]],

        [[ 992.4136,  616.5223,   65.2559,    0.0000]],

        [[ 623.2853,  514.6603,   58.8186,    0.0000]],

        [[1001.2630,  375.1635,   52.1522,    0.0000]],

        [[1002.4220,  629.2824,   66.1408,    0.0000]],

        [[1006.9240,  590.6968,   63.5558,    0.0000]],

        [[1035.0410,  271.4727,   48.0202,    0.0000]]], device='cuda:0')
tensor([[[-9.9070e-02,  0.0000e+00],
         [-9.7310e-02,  0.0000e+00],
         [-9.5570e-02,  0.0000e+00],
         ...,
         [-2.3100e-03,  0.0000e+00],
         [-5.7000e-04,  0.0000e+00],
         [ 1.1900e-03,  1.0000e+00]],

        [[ 1.6653e-01,  0.0000e+00],
         [ 1.6595e-01,  0.0000e+00],
         [ 1.6504e-01,  0.0000e+00],
         ...,
         [ 0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00]],

        [[-9.2370e-02,  0.0000e+00],
         [-9.1240e-02,  0.0000e+00],
         [-9.0060e-02,  0.0000e+00],
         ...,
         [ 0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00]],

        ...,

        [[-1.1750e-01,  0.0000e+00],
         [-1.1574e-01,  0.0000e+00],
         [-1.1400e-01,  0.0000e+00],
         ...,
         [ 0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00]],

        [[-8.9450e-02,  0.0000e+00],
         [-8.8970e-02,  0.0000e+00],
         [-8.8150e-02,  0.0000e+00],
         ...,
         [ 0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00]],

        [[ 1.0523e-01,  0.0000e+00],
         [ 1.0392e-01,  0.0000e+00],
         [ 1.0285e-01,  0.0000e+00],
         ...,
         [ 0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00],
         [ 0.0000e+00,  0.0000e+00]]], device='cuda:0')
tensor([[[ 53.4355],
         [ 53.6195],
         [ 53.8020],
         ...,
         [140.7775],
         [140.9614],
         [141.1440]],

        [[ 54.9592],
         [ 55.1462],
         [ 55.3327],
         ...,
         [165.7766],
         [165.8531],
         [165.9295]],

        [[ 65.6589],
         [ 65.8479],
         [ 66.0373],
         ...,
         [143.8391],
         [143.9155],
         [143.9920]],

        ...,

        [[ 66.1408],
         [ 66.3232],
         [ 66.5052],
         ...,
         [146.3541],
         [146.4306],
         [146.5070]],

        [[ 63.5558],
         [ 63.7401],
         [ 63.9236],
         ...,
         [131.3576],
         [131.4340],
         [131.5105]],

        [[ 48.0202],
         [ 48.2022],
         [ 48.3827],
         ...,
         [155.7113],
         [155.7878],
         [155.8642]]], device='cuda:0', grad_fn=<StackBackward>)
tensor([[[  1.5238],
         [  1.5268],
         [  1.5307],
         ...,
         [ 24.9992],
         [ 24.8917],
         [ 24.7855]],

        [[ 10.6997],
         [ 10.7017],
         [ 10.7046],
         ...,
         [-21.9376],
         [-21.9376],
         [-21.9376]],

        [[  5.5001],
         [  5.4942],
         [  5.4878],
         ...,
         [ -4.7267],
         [ -4.7267],
         [ -4.7267]],

        ...,

        [[ 13.9885],
         [ 13.9889],
         [ 13.9902],
         ...,
         [ 14.4777],
         [ 14.4777],
         [ 14.4777]],

        [[ -2.5850],
         [ -2.5831],
         [ -2.5816],
         ...,
         [-14.9966],
         [-14.9966],
         [-14.9966]],

        [[-15.5356],
         [-15.5379],
         [-15.5409],
         ...,
         [ 24.3538],
         [ 24.3538],
         [ 24.3538]]], device='cuda:0', grad_fn=<SubBackward0>)
torch.Size([128, 908, 1])
torch.Size([128, 907, 2])
