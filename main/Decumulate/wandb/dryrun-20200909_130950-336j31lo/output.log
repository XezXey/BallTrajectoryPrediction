[%]GPU Enabled
/home/puntawat/Mint/Work/Vision/BallTrajectory/UnityDataset//RealWorld/Unity/Mixed/NormalScaled/No_noise_old/train_set
Mixed:   0%|                                                                                                                               | 0/1 [00:00<?, ?it/s]Mixed: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.83it/s]
===============================Dataset shape===============================
Mixed : (2035,)
===========================================================================
Mixed:   0%|                                                                                                                               | 0/2 [00:00<?, ?it/s]Mixed: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 15.26it/s]Mixed: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 15.23it/s]
===============================Dataset shape===============================
Mixed : (2000,)
===========================================================================
======================================================Summary Batch (batch_size = 128)=========================================================================
Input batch [0] : batch=torch.Size([128, 758, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 758, 3]), initial position=torch.Size([128, 1, 4])
Output batch [0] : batch=torch.Size([128, 759, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 759, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [1] : batch=torch.Size([128, 951, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 951, 3]), initial position=torch.Size([128, 1, 4])
Output batch [1] : batch=torch.Size([128, 952, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 952, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [2] : batch=torch.Size([128, 839, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 839, 3]), initial position=torch.Size([128, 1, 4])
Output batch [2] : batch=torch.Size([128, 840, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 840, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [3] : batch=torch.Size([128, 911, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 911, 3]), initial position=torch.Size([128, 1, 4])
Output batch [3] : batch=torch.Size([128, 912, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 912, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [4] : batch=torch.Size([128, 918, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 918, 3]), initial position=torch.Size([128, 1, 4])
Output batch [4] : batch=torch.Size([128, 919, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 919, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [5] : batch=torch.Size([128, 796, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 796, 3]), initial position=torch.Size([128, 1, 4])
Output batch [5] : batch=torch.Size([128, 797, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 797, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [6] : batch=torch.Size([128, 830, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 830, 3]), initial position=torch.Size([128, 1, 4])
Output batch [6] : batch=torch.Size([128, 831, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 831, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [7] : batch=torch.Size([128, 845, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 845, 3]), initial position=torch.Size([128, 1, 4])
Output batch [7] : batch=torch.Size([128, 846, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 846, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [8] : batch=torch.Size([128, 869, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 869, 3]), initial position=torch.Size([128, 1, 4])
Output batch [8] : batch=torch.Size([128, 870, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 870, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [9] : batch=torch.Size([128, 895, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 895, 3]), initial position=torch.Size([128, 1, 4])
Output batch [9] : batch=torch.Size([128, 896, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 896, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [10] : batch=torch.Size([128, 820, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 820, 3]), initial position=torch.Size([128, 1, 4])
Output batch [10] : batch=torch.Size([128, 821, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 821, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [11] : batch=torch.Size([128, 907, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 907, 3]), initial position=torch.Size([128, 1, 4])
Output batch [11] : batch=torch.Size([128, 908, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 908, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [12] : batch=torch.Size([128, 960, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 960, 3]), initial position=torch.Size([128, 1, 4])
Output batch [12] : batch=torch.Size([128, 961, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 961, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [13] : batch=torch.Size([128, 941, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 941, 3]), initial position=torch.Size([128, 1, 4])
Output batch [13] : batch=torch.Size([128, 942, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 942, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [14] : batch=torch.Size([128, 851, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 851, 3]), initial position=torch.Size([128, 1, 4])
Output batch [14] : batch=torch.Size([128, 852, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 852, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
===>No model checkpoint
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - EOT #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(2, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
####### Model - Depth #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(3, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
train_ball_trajectory_depth_jointly_decumulate.py:249: RuntimeWarning:

invalid value encountered in long_scalars

===> [Minibatch 1/15].........Train Loss : 51552.305, Val Loss : 6920.939
======> Trajectory Loss : 5141.269, Gravity Loss : 179.193, EndOfTrajectory Loss : 1.378
===> [Minibatch 2/15].........Train Loss : 14459.250, Val Loss : 23639.205
======> Trajectory Loss : 1432.062, Gravity Loss : 87.492, EndOfTrajectory Loss : 1.377
===> [Minibatch 3/15].........Train Loss : 45689.363, Val Loss : 142.772
======> Trajectory Loss : 4555.042, Gravity Loss : 166.342, EndOfTrajectory Loss : 1.373
===> [Minibatch 4/15].........Train Loss : 783.446, Val Loss : 4879.966
======> Trajectory Loss : 64.589, Gravity Loss : 60.338, EndOfTrajectory Loss : 1.370
===> [Minibatch 5/15].........Train Loss : 8778.142, Val Loss : 4579.875
======> Trajectory Loss : 864.156, Gravity Loss : 86.409, EndOfTrajectory Loss : 1.357
===> [Minibatch 6/15].........Train Loss : 7867.173, Val Loss : 2029.143
======> Trajectory Loss : 773.267, Gravity Loss : 107.643, EndOfTrajectory Loss : 1.334
===> [Minibatch 7/15].........Train Loss : 3665.529, Val Loss : 480.986
======> Trajectory Loss : 353.484, Gravity Loss : 109.631, EndOfTrajectory Loss : 1.296
===> [Minibatch 8/15].........Train Loss : 2352.693, Val Loss : 1452.174
======> Trajectory Loss : 222.790, Gravity Loss : 98.893, EndOfTrajectory Loss : 1.238
===> [Minibatch 9/15].........Train Loss : 4948.771, Val Loss : 761.638
======> Trajectory Loss : 483.418, Gravity Loss : 110.004, EndOfTrajectory Loss : 1.135
===> [Minibatch 10/15].........Train Loss : 2275.142, Val Loss : 309.739
======> Trajectory Loss : 217.204, Gravity Loss : 111.012, EndOfTrajectory Loss : 1.020
===> [Minibatch 11/15].........Train Loss : 731.552, Val Loss : 759.722
======> Trajectory Loss : 64.125, Gravity Loss : 93.115, EndOfTrajectory Loss : 0.894
===> [Minibatch 12/15].........Train Loss : 1059.683, Val Loss : 1198.779
======> Trajectory Loss : 98.499, Gravity Loss : 88.654, EndOfTrajectory Loss : 0.738
===> [Minibatch 13/15].........Train Loss : 1769.647, Val Loss : 1148.192
======> Trajectory Loss : 170.085, Gravity Loss : 88.746, EndOfTrajectory Loss : 0.679
===> [Minibatch 14/15].........Train Loss : 1740.596, Val Loss : 690.589
======> Trajectory Loss : 168.067, Gravity Loss : 85.819, EndOfTrajectory Loss : 0.591
===> [Minibatch 15/15].........Train Loss : 1326.546, Val Loss : 290.719
======> Trajectory Loss : 124.729, Gravity Loss : 86.854, EndOfTrajectory Loss : 0.784
[#]Finish Epoch : 1/100000.........Train loss : 9933.323, Val loss : 3285.629
[+++]Saving the best model checkpoint : Prev loss 20000000000.000 > Curr loss 3285.629
[+++]Saving the best model checkpoint to :  ../../model_checkpoints/test/decumulate_jointly//decumulate_jointly_best.pth
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 2/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
===> [Minibatch 1/15].........Train Loss : 927.348, Val Loss : 334.286
======> Trajectory Loss : 86.707, Gravity Loss : 78.707, EndOfTrajectory Loss : 0.595
===> [Minibatch 2/15].........Train Loss : 1105.363, Val Loss : 426.943
======> Trajectory Loss : 104.769, Gravity Loss : 83.838, EndOfTrajectory Loss : 0.568
===> [Minibatch 3/15].........Train Loss : 1129.745, Val Loss : 335.014
======> Trajectory Loss : 107.634, Gravity Loss : 77.102, EndOfTrajectory Loss : 0.526
===> [Minibatch 4/15].........Train Loss : 940.975, Val Loss : 156.530
======> Trajectory Loss : 88.716, Gravity Loss : 79.647, EndOfTrajectory Loss : 0.530
===> [Minibatch 5/15].........Train Loss : 262.256, Val Loss : 171.857
======> Trajectory Loss : 21.942, Gravity Loss : 85.956, EndOfTrajectory Loss : 0.420
===> [Minibatch 6/15].........Train Loss : 176.350, Val Loss : 288.762
======> Trajectory Loss : 12.542, Gravity Loss : 81.200, EndOfTrajectory Loss : 0.501
===> [Minibatch 7/15].........Train Loss : 340.478, Val Loss : 314.047
======> Trajectory Loss : 29.297, Gravity Loss : 102.363, EndOfTrajectory Loss : 0.465
===> [Minibatch 8/15].........Train Loss : 376.019, Val Loss : 261.712
======> Trajectory Loss : 33.214, Gravity Loss : 108.309, EndOfTrajectory Loss : 0.428
===> [Minibatch 9/15].........Train Loss : 328.521, Val Loss : 223.446
======> Trajectory Loss : 29.810, Gravity Loss : 114.260, EndOfTrajectory Loss : 0.293
===> [Minibatch 10/15].........Train Loss : 345.801, Val Loss : 221.445
======> Trajectory Loss : 32.101, Gravity Loss : 123.564, EndOfTrajectory Loss : 0.236
===> [Minibatch 11/15].........Train Loss : 480.129, Val Loss : 225.616
======> Trajectory Loss : 46.008, Gravity Loss : 124.409, EndOfTrajectory Loss : 0.188
===> [Minibatch 12/15].........Train Loss : 430.074, Val Loss : 199.428
======> Trajectory Loss : 40.991, Gravity Loss : 118.815, EndOfTrajectory Loss : 0.190
===> [Minibatch 13/15].........Train Loss : 309.695, Val Loss : 176.674
======> Trajectory Loss : 27.985, Gravity Loss : 111.900, EndOfTrajectory Loss : 0.287
===> [Minibatch 14/15].........Train Loss : 193.293, Val Loss : 181.527
======> Trajectory Loss : 18.019, Gravity Loss : 109.059, EndOfTrajectory Loss : 0.120
===> [Minibatch 15/15].........Train Loss : 137.937, Val Loss : 174.714
======> Trajectory Loss : 11.981, Gravity Loss : 96.751, EndOfTrajectory Loss : 0.172
[#]Finish Epoch : 2/100000.........Train loss : 498.932, Val loss : 246.133
[+++]Saving the best model checkpoint : Prev loss 3285.629 > Curr loss 246.133
[+++]Saving the best model checkpoint to :  ../../model_checkpoints/test/decumulate_jointly//decumulate_jointly_best.pth
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 3/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
===> [Minibatch 1/15].........Train Loss : 161.922, Val Loss : 143.265
======> Trajectory Loss : 14.855, Gravity Loss : 85.182, EndOfTrajectory Loss : 0.125
tensor([[[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]],

        ...,

        [[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]]], device='cuda:0')
tensor([[[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        ...,

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]]], device='cuda:0')
tensor([[[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]],

        ...,

        [[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]],

        [[0.],
         [0.],
         [0.],
         ...,
         [0.],
         [0.],
         [0.]]], device='cuda:0')
tensor([[[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        ...,

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]]], device='cuda:0')
Opening in existing browser session.
[0909/201103.836744:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
Opening in existing browser session.
[0909/201104.455757:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
===> [Minibatch 2/15].........Train Loss : 101.188, Val Loss : 124.400
======> Trajectory Loss : 9.112, Gravity Loss : 89.444, EndOfTrajectory Loss : 0.092
===> [Minibatch 3/15].........Train Loss : 63.995, Val Loss : 113.780
======> Trajectory Loss : 5.402, Gravity Loss : 79.591, EndOfTrajectory Loss : 0.092
===> [Minibatch 4/15].........Train Loss : 90.092, Val Loss : 107.807
======> Trajectory Loss : 8.156, Gravity Loss : 83.177, EndOfTrajectory Loss : 0.077
===> [Minibatch 5/15].........Train Loss : 78.336, Val Loss : 108.731
======> Trajectory Loss : 7.049, Gravity Loss : 74.456, EndOfTrajectory Loss : 0.071
===> [Minibatch 6/15].........Train Loss : 132.790, Val Loss : 107.339
======> Trajectory Loss : 12.325, Gravity Loss : 73.757, EndOfTrajectory Loss : 0.088
===> [Minibatch 7/15].........Train Loss : 147.303, Val Loss : 104.525
======> Trajectory Loss : 14.266, Gravity Loss : 74.853, EndOfTrajectory Loss : 0.039
===> [Minibatch 8/15].........Train Loss : 107.605, Val Loss : 110.355
======> Trajectory Loss : 10.255, Gravity Loss : 73.298, EndOfTrajectory Loss : 0.043
===> [Minibatch 9/15].........Train Loss : 105.565, Val Loss : 113.389
======> Trajectory Loss : 10.294, Gravity Loss : 77.784, EndOfTrajectory Loss : 0.018
===> [Minibatch 10/15].........Train Loss : 106.186, Val Loss : 108.968
======> Trajectory Loss : 10.302, Gravity Loss : 71.067, EndOfTrajectory Loss : 0.025
===> [Minibatch 11/15].........Train Loss : 102.902, Val Loss : 104.944
======> Trajectory Loss : 10.063, Gravity Loss : 76.481, EndOfTrajectory Loss : 0.015
===> [Minibatch 12/15].........Train Loss : 66.908, Val Loss : 105.839
======> Trajectory Loss : 6.348, Gravity Loss : 74.749, EndOfTrajectory Loss : 0.027
