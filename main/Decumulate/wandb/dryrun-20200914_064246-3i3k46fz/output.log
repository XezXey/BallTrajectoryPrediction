[%]GPU Enabled
/home/puntawat/Mint/Work/Vision/BallTrajectory/UnityDataset//RealWorld/Unity/Mixed/NormalScaled/No_noise_old/train_set
Mixed:   0%|                                                                                                                 | 0/1 [00:00<?, ?it/s]Mixed: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.26it/s]
===============================Dataset shape===============================
Mixed : (2035,)
===========================================================================
Mixed:   0%|                                                                                                                 | 0/2 [00:00<?, ?it/s]Mixed: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 19.55it/s]Mixed: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 19.50it/s]
===============================Dataset shape===============================
Mixed : (2000,)
===========================================================================
======================================================Summary Batch (batch_size = 128)=========================================================================
Input batch [0] : batch=torch.Size([128, 941, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 941, 3]), initial position=torch.Size([128, 1, 4])
Output batch [0] : batch=torch.Size([128, 941, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 942, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [1] : batch=torch.Size([128, 904, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 904, 3]), initial position=torch.Size([128, 1, 4])
Output batch [1] : batch=torch.Size([128, 904, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 905, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [2] : batch=torch.Size([128, 854, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 854, 3]), initial position=torch.Size([128, 1, 4])
Output batch [2] : batch=torch.Size([128, 854, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 855, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [3] : batch=torch.Size([128, 800, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 800, 3]), initial position=torch.Size([128, 1, 4])
Output batch [3] : batch=torch.Size([128, 800, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 801, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [4] : batch=torch.Size([128, 888, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 888, 3]), initial position=torch.Size([128, 1, 4])
Output batch [4] : batch=torch.Size([128, 888, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 889, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [5] : batch=torch.Size([128, 734, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 734, 3]), initial position=torch.Size([128, 1, 4])
Output batch [5] : batch=torch.Size([128, 734, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 735, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [6] : batch=torch.Size([128, 869, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 869, 3]), initial position=torch.Size([128, 1, 4])
Output batch [6] : batch=torch.Size([128, 869, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 870, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [7] : batch=torch.Size([128, 895, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 895, 3]), initial position=torch.Size([128, 1, 4])
Output batch [7] : batch=torch.Size([128, 895, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 896, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [8] : batch=torch.Size([128, 951, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 951, 3]), initial position=torch.Size([128, 1, 4])
Output batch [8] : batch=torch.Size([128, 951, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 952, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [9] : batch=torch.Size([128, 918, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 918, 3]), initial position=torch.Size([128, 1, 4])
Output batch [9] : batch=torch.Size([128, 918, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 919, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [10] : batch=torch.Size([128, 960, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 960, 3]), initial position=torch.Size([128, 1, 4])
Output batch [10] : batch=torch.Size([128, 960, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 961, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [11] : batch=torch.Size([128, 838, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 838, 3]), initial position=torch.Size([128, 1, 4])
Output batch [11] : batch=torch.Size([128, 838, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 839, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [12] : batch=torch.Size([128, 796, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 796, 3]), initial position=torch.Size([128, 1, 4])
Output batch [12] : batch=torch.Size([128, 796, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 797, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [13] : batch=torch.Size([128, 928, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 928, 3]), initial position=torch.Size([128, 1, 4])
Output batch [13] : batch=torch.Size([128, 928, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 929, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [14] : batch=torch.Size([128, 907, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 907, 3]), initial position=torch.Size([128, 1, 4])
Output batch [14] : batch=torch.Size([128, 907, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 908, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
===>No model checkpoint
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - EOT #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(2, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
####### Model - Depth #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(3, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
===> [Minibatch 1/15].........torch.Size([287])
tensor([ 9.0586e-03,  1.8117e-03,  3.6232e-04,  7.2472e-05,  1.4461e-05,
         2.8741e-06,  5.7114e-07,  7.3197e-08, -3.5085e-08, -5.2966e-08,
        -7.3579e-08, -3.1537e-10, -2.0680e-08, -4.0549e-08, -5.9175e-08,
        -7.5815e-08,  7.1352e-09, -2.8379e-08, -5.9920e-08,  1.1606e-08,
        -4.2890e-09, -1.1740e-08, -4.3777e-08, -6.7619e-08,  1.2351e-08,
        -1.9935e-08, -4.3777e-08, -8.5004e-08, -1.3478e-08, -5.4953e-08,
        -7.8795e-08, -2.4902e-08, -4.8744e-08, -9.0467e-08, -1.8942e-08,
        -4.2784e-08, -6.6626e-08,  4.9000e-09, -1.8942e-08, -4.2784e-08,
        -6.6626e-08,  4.9000e-09, -1.8942e-08, -4.2784e-08, -6.6626e-08,
         4.9000e-09, -1.8942e-08, -4.2784e-08, -6.6626e-08,  4.9000e-09,
        -1.8942e-08, -4.2784e-08, -6.6626e-08,  4.9000e-09, -1.8942e-08,
        -4.2784e-08, -6.6626e-08,  4.9000e-09, -1.8942e-08, -4.2784e-08,
        -6.6626e-08,  4.9000e-09, -1.8942e-08, -4.2784e-08, -6.6626e-08,
         4.9000e-09, -1.8942e-08, -4.2784e-08, -6.6626e-08,  4.9000e-09,
        -1.8942e-08, -4.2784e-08, -6.6626e-08,  4.9000e-09, -1.8942e-08,
        -4.2784e-08, -6.6626e-08,  4.9000e-09, -1.8942e-08, -4.2784e-08,
        -6.6626e-08,  4.9000e-09, -1.8942e-08, -4.2784e-08, -6.6626e-08,
         4.9000e-09, -1.8942e-08, -4.2784e-08, -6.6626e-08,  4.9000e-09,
        -1.8942e-08, -4.2784e-08, -6.6626e-08,  4.9000e-09, -1.8942e-08,
        -4.2784e-08, -6.6626e-08,  4.9000e-09, -1.8942e-08, -4.2784e-08,
        -6.6626e-08,  4.9000e-09, -1.8942e-08, -4.2784e-08, -6.6626e-08,
         4.9001e-09, -1.8942e-08, -4.2784e-08, -6.6626e-08,  6.8869e-09,
        -1.4968e-08, -4.0548e-08, -6.4390e-08,  7.1352e-09, -1.6707e-08,
        -4.0548e-08, -6.2652e-08,  7.3836e-09, -1.7948e-08, -4.0300e-08,
        -6.2652e-08,  7.3836e-09, -1.4968e-08, -4.0052e-08, -6.3894e-08,
         7.6319e-09, -1.6210e-08, -3.8810e-08, -6.1410e-08,  1.0115e-08,
        -1.2485e-08, -3.7568e-08, -6.1410e-08,  1.1109e-08, -1.2733e-08,
        -3.6575e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.8562e-08,
        -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,
         1.0860e-08, -1.2981e-08, -3.6823e-08, -5.9920e-08,  1.1606e-08,
        -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08,
        -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08,
        -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,
         1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08,
        -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08,
        -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08,
        -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,
         1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08,
        -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08,
        -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08,
        -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,
         1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08,
        -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08,
        -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08,
        -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,
         1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08,
        -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08,
        -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08,
        -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,
         1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08,
        -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08,
        -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08,
        -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,
         1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08,
        -1.3726e-08, -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08,
        -3.7568e-08, -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08,
        -6.1410e-08,  1.0115e-08, -1.3726e-08, -3.7568e-08, -6.1410e-08,
         1.0115e-08, -1.3726e-08], device='cuda:0')
Traceback (most recent call last):
  File "train_ball_trajectory_depth_jointly_decumulate.py", line 731, in <module>
    optimizer=optimizer, epoch=epoch, n_epochs=n_epochs, vis_signal=vis_signal, width=width, height=height)
  File "train_ball_trajectory_depth_jointly_decumulate.py", line 417, in train
    train_gravity_loss = GravityLoss(output=output_train_xyz, trajectory_gt=output_trajectory_train_xyz[..., :-1], mask=output_trajectory_train_mask[..., :-1], lengths=output_trajectory_train_lengths)
  File "train_ball_trajectory_depth_jointly_decumulate.py", line 166, in GravityLoss
    print(trajectory_gt_yaxis_2nd_finite_difference.shape[i][:, :lengths[i]+1])
TypeError: 'int' object is not subscriptable
