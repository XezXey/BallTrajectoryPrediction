==============================================Features==============================================
Prediction = depth, Environment = unity
Available features :  ['x-0', 'y-1', 'z-2', 'u-3', 'v-4', 'd-5', 'eot-6', 'og-7', 'rad-8', 'f_sin-9', 'f_cos-10', 'g-11']
Selected features :  [6]
1. input_col =  [3, 4, 6]
2. input_startpos_col =  [3, 4, 5, 6]
3. gt_col =  [5, 6]
4. gt_startpos_col =  [0, 1, 2, 6]
5. gt_xyz_col =  [0, 1, 2, 6]
====================================================================================================
[#]Training : Trajectory Estimation
Mixed:   0%|                                                                   | 0/1 [00:00<?, ?it/s]===============================Dataset shape===============================
Mixed: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 48.13it/s]
Mixed : (724,)
===========================================================================
Mixed:   0%|                                                                   | 0/1 [00:00<?, ?it/s]===============================Dataset shape===============================
Mixed : (1841,)
===========================================================================
Mixed: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 23.81it/s]
======================================================Summary Batch (batch_size = 128)=========================================================================
Input batch [0] : batch=torch.Size([128, 1699, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1699, 3]), initial position=torch.Size([128, 1, 4])
gt batch [0] : batch=torch.Size([128, 1699, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1700, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [1] : batch=torch.Size([128, 1754, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1754, 3]), initial position=torch.Size([128, 1, 4])
gt batch [1] : batch=torch.Size([128, 1754, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1755, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [2] : batch=torch.Size([128, 1997, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1997, 3]), initial position=torch.Size([128, 1, 4])
gt batch [2] : batch=torch.Size([128, 1997, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1998, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [3] : batch=torch.Size([128, 1810, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1810, 3]), initial position=torch.Size([128, 1, 4])
gt batch [3] : batch=torch.Size([128, 1810, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1811, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [4] : batch=torch.Size([128, 1806, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1806, 3]), initial position=torch.Size([128, 1, 4])
gt batch [4] : batch=torch.Size([128, 1806, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1807, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
{'flag': {'input_size': 2, 'output_size': 1, 'hidden_dim': 32, 'n_layers': 1, 'n_stack': 4, 'recurrent_stacked': [2, 32, 32, 32, 32], 'fc_size': [32, 32, 16, 8, 4, 1]}, 'depth': {'input_size': 3, 'output_size': 2, 'hidden_dim': 32, 'n_layers': 1, 'n_stack': 4, 'recurrent_stacked': [3, 32, 32, 32, 32], 'fc_size': [32, 32, 16, 8, 4, 2]}}
===>No model checkpoint
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - EOT #######
BiLSTMResidualTrainableInit(
  (recurrent_blocks): ModuleList(
    (0): LSTM(2, 32, batch_first=True)
    (1): LSTM(32, 32, batch_first=True)
    (2): LSTM(32, 32, batch_first=True)
    (3): LSTM(32, 32, batch_first=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
      (1): Sigmoid()
    )
  )
)
####### Model - Depth #######
BiLSTMResidualTrainableInit(
  (recurrent_blocks): ModuleList(
    (0): LSTM(3, 32, batch_first=True)
    (1): LSTM(32, 32, batch_first=True)
    (2): LSTM(32, 32, batch_first=True)
    (3): LSTM(32, 32, batch_first=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=32, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=2, bias=True)
    )
  )
)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
===> [Minibatch 1/5].........Train Loss : 1001.646, Val Loss : 721.066
======> Trajectory Loss : 862.058, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.396, BelowGroundPenalize Loss : 0.000
Opening in existing browser session.
[1021/210450.489315:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
Opening in existing browser session.
[1021/210450.767952:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
Opening in existing browser session.
[1021/210451.101776:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
===> [Minibatch 2/5].........Train Loss : 732.854, Val Loss : 492.765
======> Trajectory Loss : 593.716, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.391, BelowGroundPenalize Loss : 0.000
===> [Minibatch 3/5].........Train Loss : 464.909, Val Loss : 239.169
======> Trajectory Loss : 326.396, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.385, BelowGroundPenalize Loss : 0.006
===> [Minibatch 4/5].........Train Loss : 240.290, Val Loss : 347.085
======> Trajectory Loss : 102.203, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.380, BelowGroundPenalize Loss : 0.072
===> [Minibatch 5/5].........Train Loss : 319.863, Val Loss : 244.733
======> Trajectory Loss : 157.764, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.379, BelowGroundPenalize Loss : 24.151
[#]Finish Epoch : 1/100000.........Train loss : 551.913, Val loss : 408.964
[+++]Saving the best model checkpoint : Prev loss 20000000000.000 > Curr loss 408.964
[+++]Saving the best model checkpoint to :  ../../model_checkpoints/test_trainable/Test//Test_best.pth
[#]Saving the lastest checkpoint to :  ../../model_checkpoints/test_trainable/Test//Test_lastest.pth
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 2/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
===> [Minibatch 1/5].........Train Loss : 225.091, Val Loss : 163.436
======> Trajectory Loss : 77.133, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.377, BelowGroundPenalize Loss : 10.225
Opening in existing browser session.
[1021/210502.122562:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
Opening in existing browser session.
[1021/210502.301066:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
Opening in existing browser session.
[1021/210502.646498:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
===> [Minibatch 2/5].........Train Loss : 164.837, Val Loss : 170.419
======> Trajectory Loss : 24.835, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.373, BelowGroundPenalize Loss : 2.653
===> [Minibatch 3/5].........Train Loss : 178.210, Val Loss : 167.185
======> Trajectory Loss : 40.055, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.377, BelowGroundPenalize Loss : 0.495
===> [Minibatch 4/5].........Train Loss : 168.292, Val Loss : 160.297
======> Trajectory Loss : 30.897, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.367, BelowGroundPenalize Loss : 0.667
===> [Minibatch 5/5].........Train Loss : 165.459, Val Loss : 156.797
======> Trajectory Loss : 28.626, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.358, BelowGroundPenalize Loss : 1.065
[#]Finish Epoch : 2/100000.........Train loss : 180.378, Val loss : 163.627
[+++]Saving the best model checkpoint : Prev loss 408.964 > Curr loss 163.627
[+++]Saving the best model checkpoint to :  ../../model_checkpoints/test_trainable/Test//Test_best.pth
[#]Saving the lastest checkpoint to :  ../../model_checkpoints/test_trainable/Test//Test_lastest.pth
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 3/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
===> [Minibatch 1/5].........Train Loss : 163.256, Val Loss : 160.190
======> Trajectory Loss : 27.346, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.338, BelowGroundPenalize Loss : 2.093
Opening in existing browser session.
[1021/210513.857867:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
Opening in existing browser session.
[1021/210514.199041:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
Opening in existing browser session.
[1021/210514.514422:ERROR:nacl_helper_linux.cc(308)] NaCl helper process running without a sandbox!
Most likely you need to configure your SUID sandbox correctly
===> [Minibatch 2/5].........Train Loss : 163.676, Val Loss : 150.283
======> Trajectory Loss : 24.843, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.366, BelowGroundPenalize Loss : 2.204
===> [Minibatch 3/5].........Train Loss : 151.645, Val Loss : 145.727
======> Trajectory Loss : 22.490, Gravity Loss : 0.000, EndOfTrajectory Loss : 1.264, BelowGroundPenalize Loss : 2.719
