==============================================Features==============================================
Prediction = depth, Environment = unity
Available features :  ['x-0', 'y-1', 'z-2', 'u-3', 'v-4', 'd-5', 'eot-6', 'og-7', 'rad-8', 'f_sin-9', 'f_cos-10', 'g-11']
Selected features :  [6]
1. input_col =  [3, 4, 6]
2. input_startpos_col =  [3, 4, 5, 6]
3. gt_col =  [5, 6]
4. gt_startpos_col =  [0, 1, 2, 6]
5. gt_xyz_col =  [0, 1, 2, 6]
====================================================================================================
[#]Training : Trajectory Estimation
Mixed:   0%|                                                                   | 0/1 [00:00<?, ?it/s]Mixed: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 53.74it/s]
===============================Dataset shape===============================
Mixed : (724,)
===========================================================================
Mixed:   0%|                                                                   | 0/1 [00:00<?, ?it/s]Mixed: 100%|███████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 23.64it/s]
===============================Dataset shape===============================
Mixed : (1841,)
===========================================================================
======================================================Summary Batch (batch_size = 128)=========================================================================
Input batch [0] : batch=torch.Size([128, 1820, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1820, 3]), initial position=torch.Size([128, 1, 4])
gt batch [0] : batch=torch.Size([128, 1820, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1821, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [1] : batch=torch.Size([128, 1806, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1806, 3]), initial position=torch.Size([128, 1, 4])
gt batch [1] : batch=torch.Size([128, 1806, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1807, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [2] : batch=torch.Size([128, 1647, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1647, 3]), initial position=torch.Size([128, 1, 4])
gt batch [2] : batch=torch.Size([128, 1647, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1648, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [3] : batch=torch.Size([128, 1997, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1997, 3]), initial position=torch.Size([128, 1, 4])
gt batch [3] : batch=torch.Size([128, 1997, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1998, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [4] : batch=torch.Size([128, 1713, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1713, 3]), initial position=torch.Size([128, 1, 4])
gt batch [4] : batch=torch.Size([128, 1713, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1714, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
{'flag': {'input_size': 2, 'output_size': 1, 'hidden_dim': 32, 'n_layers': 1, 'n_stack': 4, 'recurrent_stacked': [2, 32, 32, 32, 32], 'fc_size': [64, 32, 16, 8, 4, 1]}, 'depth': {'input_size': 3, 'output_size': 2, 'hidden_dim': 32, 'n_layers': 1, 'n_stack': 4, 'recurrent_stacked': [3, 32, 32, 32, 32], 'fc_size': [64, 32, 16, 8, 4, 2]}}
===>No model checkpoint
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - EOT #######
BiLSTMResidualTrainableInit(
  (recurrent_blocks): ModuleList(
    (0): LSTM(2, 32, batch_first=True, bidirectional=True)
    (1): LSTM(64, 32, batch_first=True, bidirectional=True)
    (2): LSTM(64, 32, batch_first=True, bidirectional=True)
    (3): LSTM(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
      (1): Sigmoid()
    )
  )
)
####### Model - Depth #######
BiLSTMResidualTrainableInit(
  (recurrent_blocks): ModuleList(
    (0): LSTM(3, 32, batch_first=True, bidirectional=True)
    (1): LSTM(64, 32, batch_first=True, bidirectional=True)
    (2): LSTM(64, 32, batch_first=True, bidirectional=True)
    (3): LSTM(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=2, bias=True)
    )
  )
)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
===> [Minibatch 1/5].........torch.Size([617])
torch.Size([265])
torch.Size([402])
torch.Size([621])
torch.Size([156])
torch.Size([525])
torch.Size([457])
torch.Size([1463])
torch.Size([115])
torch.Size([1645])
torch.Size([1409])
torch.Size([849])
torch.Size([612])
torch.Size([1323])
torch.Size([271])
torch.Size([1067])
torch.Size([1181])
torch.Size([1685])
torch.Size([1349])
torch.Size([1668])
torch.Size([134])
torch.Size([291])
torch.Size([103])
torch.Size([1247])
torch.Size([487])
torch.Size([644])
torch.Size([711])
torch.Size([697])
torch.Size([370])
torch.Size([402])
torch.Size([1297])
torch.Size([493])
torch.Size([399])
torch.Size([314])
torch.Size([585])
torch.Size([586])
torch.Size([231])
torch.Size([368])
torch.Size([150])
torch.Size([245])
torch.Size([686])
torch.Size([1201])
torch.Size([509])
torch.Size([1127])
torch.Size([1067])
torch.Size([1123])
torch.Size([565])
torch.Size([238])
torch.Size([931])
torch.Size([1558])
torch.Size([430])
torch.Size([343])
torch.Size([978])
torch.Size([762])
torch.Size([1147])
torch.Size([251])
torch.Size([871])
torch.Size([640])
torch.Size([215])
torch.Size([566])
torch.Size([1013])
torch.Size([433])
torch.Size([1364])
torch.Size([994])
torch.Size([987])
torch.Size([699])
torch.Size([717])
torch.Size([1074])
torch.Size([594])
torch.Size([441])
torch.Size([426])
torch.Size([929])
torch.Size([665])
torch.Size([810])
torch.Size([185])
torch.Size([829])
torch.Size([1207])
torch.Size([1036])
torch.Size([521])
torch.Size([1218])
torch.Size([340])
torch.Size([1537])
torch.Size([657])
torch.Size([156])
torch.Size([1323])
torch.Size([419])
torch.Size([133])
torch.Size([804])
torch.Size([151])
torch.Size([311])
torch.Size([149])
torch.Size([370])
torch.Size([1359])
torch.Size([948])
torch.Size([687])
torch.Size([1062])
torch.Size([685])
torch.Size([139])
torch.Size([144])
torch.Size([810])
torch.Size([742])
torch.Size([1123])
torch.Size([910])
torch.Size([338])
torch.Size([885])
torch.Size([1099])
torch.Size([1466])
torch.Size([953])
torch.Size([868])
torch.Size([246])
torch.Size([1040])
torch.Size([847])
torch.Size([148])
torch.Size([29])
torch.Size([1166])
torch.Size([674])
torch.Size([1037])
torch.Size([1158])
torch.Size([1700])
torch.Size([119])
torch.Size([1607])
torch.Size([1356])
torch.Size([1498])
torch.Size([1296])
torch.Size([1377])
torch.Size([629])
torch.Size([1022])
torch.Size([908])
torch.Size([128, 1700, 3])
tensor([[10.0000],
        [ 9.9854],
        [ 9.9708],
        [ 9.9562],
        [ 9.9416],
        [ 9.9269],
        [ 9.9123],
        [ 9.8977],
        [ 9.8831],
        [ 9.8685],
        [ 9.8539],
        [ 9.8393],
        [ 9.8247],
        [ 9.8101],
        [ 9.7955],
        [ 9.7808],
        [ 9.7662],
        [ 9.7516],
        [ 9.7370],
        [ 9.7224],
        [ 9.7078],
        [ 9.6932],
        [ 9.6786],
        [ 9.6640],
        [ 9.6494],
        [ 9.6347],
        [ 9.6201],
        [ 9.6055],
        [ 9.5909],
        [ 9.5763],
        [ 9.5617],
        [ 9.5471],
        [ 9.5325],
        [ 9.5179],
        [ 9.5032],
        [ 9.4886],
        [ 9.4740],
        [ 9.4594],
        [ 9.4448],
        [ 9.4302],
        [ 9.4156],
        [ 9.4010],
        [ 9.3864],
        [ 9.3718],
        [ 9.3571],
        [ 9.3425],
        [ 9.3279],
        [ 9.3133],
        [ 9.2987],
        [ 9.2841],
        [ 9.2695],
        [ 9.2549],
        [ 9.2403],
        [ 9.2256],
        [ 9.2110],
        [ 9.1964],
        [ 9.1818],
        [ 9.1672],
        [ 9.1526],
        [ 9.1380],
        [ 9.1234],
        [ 9.1088],
        [ 9.0942],
        [ 9.0795],
        [ 9.0649],
        [ 9.0503],
        [ 9.0357],
        [ 9.0211],
        [ 9.0065],
        [ 8.9919],
        [ 8.9773],
        [ 8.9627],
        [ 8.9481],
        [ 8.9334],
        [ 8.9188],
        [ 8.9042],
        [ 8.8896],
        [ 8.8750],
        [ 8.8604],
        [ 8.8458],
        [ 8.8312],
        [ 8.8166],
        [ 8.8019],
        [ 8.7873],
        [ 8.7727],
        [ 8.7581],
        [ 8.7435],
        [ 8.7289],
        [ 8.7143],
        [ 8.6997],
        [ 8.6851],
        [ 8.6705],
        [ 8.6558],
        [ 8.6412],
        [ 8.6266],
        [ 8.6120],
        [ 8.5974],
        [ 8.5828],
        [ 8.5682],
        [ 8.5536],
        [ 8.5390],
        [ 8.5244],
        [ 8.5097],
        [ 8.4951],
        [ 8.4805],
        [ 8.4659],
        [ 8.4513],
        [ 8.4367],
        [ 8.4221],
        [ 8.4075],
        [ 8.3929],
        [ 8.3782],
        [ 8.3636],
        [ 8.3490],
        [ 8.3344],
        [ 8.3198],
        [ 8.3052],
        [ 8.2906],
        [ 8.2760],
        [ 8.2614],
        [ 8.2468],
        [ 8.2321],
        [ 8.2175],
        [ 8.2029],
        [ 8.1883],
        [ 8.1737],
        [ 8.1591],
        [ 8.1445],
        [ 8.1299],
        [ 8.1153],
        [ 8.1006],
        [ 8.0860],
        [ 8.0714],
        [ 8.0568],
        [ 8.0422],
        [ 8.0276],
        [ 8.0130],
        [ 7.9984],
        [ 7.9838],
        [ 7.9692],
        [ 7.9545],
        [ 7.9399],
        [ 7.9253],
        [ 7.9107],
        [ 7.8961],
        [ 7.8815],
        [ 7.8669],
        [ 7.8523],
        [ 7.8377],
        [ 7.8231],
        [ 7.8084],
        [ 7.7938],
        [ 7.7792],
        [ 7.7646],
        [ 7.7500],
        [ 7.7354],
        [ 7.7208],
        [ 7.7062],
        [ 7.6916],
        [ 7.6769],
        [ 7.6623],
        [ 7.6477],
        [ 7.6331],
        [ 7.6185],
        [ 7.6039],
        [ 7.5893],
        [ 7.5747],
        [ 7.5601],
        [ 7.5455],
        [ 7.5308],
        [ 7.5162],
        [ 7.5016],
        [ 7.4870],
        [ 7.4724],
        [ 7.4578],
        [ 7.4432],
        [ 7.4286],
        [ 7.4140],
        [ 7.3994],
        [ 7.3847],
        [ 7.3701],
        [ 7.3555],
        [ 7.3409],
        [ 7.3263],
        [ 7.3117],
        [ 7.2971],
        [ 7.2825],
        [ 7.2679],
        [ 7.2532],
        [ 7.2386],
        [ 7.2240],
        [ 7.2094],
        [ 7.1948],
        [ 7.1802],
        [ 7.1656],
        [ 7.1510],
        [ 7.1364],
        [ 7.1218],
        [ 7.1071],
        [ 7.0925],
        [ 7.0779],
        [ 7.0633],
        [ 7.0487],
        [ 7.0341],
        [ 7.0195],
        [ 7.0049],
        [ 6.9903],
        [ 6.9756],
        [ 6.9610],
        [ 6.9464],
        [ 6.9318],
        [ 6.9172],
        [ 6.9026],
        [ 6.8880],
        [ 6.8734],
        [ 6.8588],
        [ 6.8442],
        [ 6.8295],
        [ 6.8149],
        [ 6.8003],
        [ 6.7857],
        [ 6.7711],
        [ 6.7565],
        [ 6.7419],
        [ 6.7273],
        [ 6.7127],
        [ 6.6981],
        [ 6.6834],
        [ 6.6688],
        [ 6.6542],
        [ 6.6396],
        [ 6.6250],
        [ 6.6104],
        [ 6.5958],
        [ 6.5812],
        [ 6.5666],
        [ 6.5519],
        [ 6.5373],
        [ 6.5227],
        [ 6.5081],
        [ 6.4935],
        [ 6.4789],
        [ 6.4643],
        [ 6.4497],
        [ 6.4351],
        [ 6.4205],
        [ 6.4058],
        [ 6.3912],
        [ 6.3766],
        [ 6.3620],
        [ 6.3474],
        [ 6.3328],
        [ 6.3182],
        [ 6.3036],
        [ 6.2890],
        [ 6.2744],
        [ 6.2597],
        [ 6.2451],
        [ 6.2305],
        [ 6.2159],
        [ 6.2013],
        [ 6.1867],
        [ 6.1721],
        [ 6.1575],
        [ 6.1429],
        [ 6.1282],
        [ 6.1136],
        [ 6.0990],
        [ 6.0844],
        [ 6.0698],
        [ 6.0552],
        [ 6.0406],
        [ 6.0260],
        [ 6.0114],
        [ 5.9968],
        [ 5.9821],
        [ 5.9675],
        [ 5.9529],
        [ 5.9383],
        [ 5.9237],
        [ 5.9091],
        [ 5.8945],
        [ 5.8799],
        [ 5.8653],
        [ 5.8506],
        [ 5.8360],
        [ 5.8214],
        [ 5.8068],
        [ 5.7922],
        [ 5.7776],
        [ 5.7630],
        [ 5.7484],
        [ 5.7338],
        [ 5.7192],
        [ 5.7045],
        [ 5.6899],
        [ 5.6753],
        [ 5.6607],
        [ 5.6461],
        [ 5.6315],
        [ 5.6169],
        [ 5.6023],
        [ 5.5877],
        [ 5.5731],
        [ 5.5584],
        [ 5.5438],
        [ 5.5292],
        [ 5.5146],
        [ 5.5000],
        [ 5.4854],
        [ 5.4708],
        [ 5.4562],
        [ 5.4416],
        [ 5.4269],
        [ 5.4123],
        [ 5.3977],
        [ 5.3831],
        [ 5.3685],
        [ 5.3539],
        [ 5.3393],
        [ 5.3247],
        [ 5.3101],
        [ 5.2955],
        [ 5.2808],
        [ 5.2662],
        [ 5.2516],
        [ 5.2370],
        [ 5.2224],
        [ 5.2078],
        [ 5.1932],
        [ 5.1786],
        [ 5.1640],
        [ 5.1494],
        [ 5.1347],
        [ 5.1201],
        [ 5.1055],
        [ 5.0909],
        [ 5.0763],
        [ 5.0617],
        [ 5.0471],
        [ 5.0325],
        [ 5.0179],
        [ 5.0032],
        [ 4.9886],
        [ 4.9740],
        [ 4.9594],
        [ 4.9448],
        [ 4.9302],
        [ 4.9156],
        [ 4.9010],
        [ 4.8864],
        [ 4.8718],
        [ 4.8571],
        [ 4.8425],
        [ 4.8279],
        [ 4.8133],
        [ 4.7987],
        [ 4.7841],
        [ 4.7695],
        [ 4.7549],
        [ 4.7403],
        [ 4.7256],
        [ 4.7110],
        [ 4.6964],
        [ 4.6818],
        [ 4.6672],
        [ 4.6526],
        [ 4.6380],
        [ 4.6234],
        [ 4.6088],
        [ 4.5942],
        [ 4.5795],
        [ 4.5649],
        [ 4.5503],
        [ 4.5357],
        [ 4.5211],
        [ 4.5065],
        [ 4.4919],
        [ 4.4773],
        [ 4.4627],
        [ 4.4481],
        [ 4.4334],
        [ 4.4188],
        [ 4.4042],
        [ 4.3896],
        [ 4.3750],
        [ 4.3604],
        [ 4.3458],
        [ 4.3312],
        [ 4.3166],
        [ 4.3019],
        [ 4.2873],
        [ 4.2727],
        [ 4.2581],
        [ 4.2435],
        [ 4.2289],
        [ 4.2143],
        [ 4.1997],
        [ 4.1851],
        [ 4.1705],
        [ 4.1558],
        [ 4.1412],
        [ 4.1266],
        [ 4.1120],
        [ 4.0974],
        [ 4.0828],
        [ 4.0682],
        [ 4.0536],
        [ 4.0390],
        [ 4.0244],
        [ 4.0097],
        [ 3.9951],
        [ 3.9805],
        [ 3.9659],
        [ 3.9513],
        [ 3.9367],
        [ 3.9221],
        [ 3.9075],
        [ 3.8929],
        [ 3.8782],
        [ 3.8636],
        [ 3.8490],
        [ 3.8344],
        [ 3.8198],
        [ 3.8052],
        [ 3.7906],
        [ 3.7760],
        [ 3.7614],
        [ 3.7468],
        [ 3.7321],
        [ 3.7175],
        [ 3.7029],
        [ 3.6883],
        [ 3.6737],
        [ 3.6591],
        [ 3.6445],
        [ 3.6299],
        [ 3.6153],
        [ 3.6006],
        [ 3.5860],
        [ 3.5714],
        [ 3.5568],
        [ 3.5422],
        [ 3.5276],
        [ 3.5130],
        [ 3.4984],
        [ 3.4838],
        [ 3.4692],
        [ 3.4545],
        [ 3.4399],
        [ 3.4253],
        [ 3.4107],
        [ 3.3961],
        [ 3.3815],
        [ 3.3669],
        [ 3.3523],
        [ 3.3377],
        [ 3.3231],
        [ 3.3084],
        [ 3.2938],
        [ 3.2792],
        [ 3.2646],
        [ 3.2500],
        [ 3.2354],
        [ 3.2208],
        [ 3.2062],
        [ 3.1916],
        [ 3.1769],
        [ 3.1623],
        [ 3.1477],
        [ 3.1331],
        [ 3.1185],
        [ 3.1039],
        [ 3.0893],
        [ 3.0747],
        [ 3.0601],
        [ 3.0455],
        [ 3.0308],
        [ 3.0162],
        [ 3.0016],
        [ 2.9870],
        [ 2.9724],
        [ 2.9578],
        [ 2.9432],
        [ 2.9286],
        [ 2.9140],
        [ 2.8994],
        [ 2.8847],
        [ 2.8701],
        [ 2.8555],
        [ 2.8409],
        [ 2.8263],
        [ 2.8117],
        [ 2.7971],
        [ 2.7825],
        [ 2.7679],
        [ 2.7532],
        [ 2.7386],
        [ 2.7240],
        [ 2.7094],
        [ 2.6948],
        [ 2.6802],
        [ 2.6656],
        [ 2.6510],
        [ 2.6364],
        [ 2.6218],
        [ 2.6071],
        [ 2.5925],
        [ 2.5779],
        [ 2.5633],
        [ 2.5487],
        [ 2.5341],
        [ 2.5195],
        [ 2.5049],
        [ 2.4903],
        [ 2.4756],
        [ 2.4610],
        [ 2.4464],
        [ 2.4318],
        [ 2.4172],
        [ 2.4026],
        [ 2.3880],
        [ 2.3734],
        [ 2.3588],
        [ 2.3442],
        [ 2.3295],
        [ 2.3149],
        [ 2.3003],
        [ 2.2857],
        [ 2.2711],
        [ 2.2565],
        [ 2.2419],
        [ 2.2273],
        [ 2.2127],
        [ 2.1981],
        [ 2.1834],
        [ 2.1688],
        [ 2.1542],
        [ 2.1396],
        [ 2.1250],
        [ 2.1104],
        [ 2.0958],
        [ 2.0812],
        [ 2.0666],
        [ 2.0519],
        [ 2.0373],
        [ 2.0227],
        [ 2.0081],
        [ 1.9935],
        [ 1.9789],
        [ 1.9643],
        [ 1.9497],
        [ 1.9351],
        [ 1.9205],
        [ 1.9058],
        [ 1.8912],
        [ 1.8766],
        [ 1.8620],
        [ 1.8474],
        [ 1.8328],
        [ 1.8182],
        [ 1.8036],
        [ 1.7890],
        [ 1.7744],
        [ 1.7597],
        [ 1.7451],
        [ 1.7305],
        [ 1.7159],
        [ 1.7013],
        [ 1.6867],
        [ 1.6721],
        [ 1.6575],
        [ 1.6429],
        [ 1.6282],
        [ 1.6136],
        [ 1.5990],
        [ 1.5844],
        [ 1.5698],
        [ 1.5552],
        [ 1.5406],
        [ 1.5260],
        [ 1.5114],
        [ 1.4968],
        [ 1.4821],
        [ 1.4675],
        [ 1.4529],
        [ 1.4383],
        [ 1.4237],
        [ 1.4091],
        [ 1.3945],
        [ 1.3799],
        [ 1.3653],
        [ 1.3506],
        [ 1.3360],
        [ 1.3214],
        [ 1.3068],
        [ 1.2922],
        [ 1.2776],
        [ 1.2630],
        [ 1.2484],
        [ 1.2338],
        [ 1.2192],
        [ 1.2045],
        [ 1.1899],
        [ 1.1753],
        [ 1.1607],
        [ 1.1461],
        [ 1.1315],
        [ 1.1169],
        [ 1.1023],
        [ 1.0877],
        [ 1.0731],
        [ 1.0584],
        [ 1.0438],
        [ 1.0292],
        [ 1.0146],
        [ 1.0000]], device='cuda:0')
tensor([[ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [ True],
        [False],
        [False]], device='cuda:0')
