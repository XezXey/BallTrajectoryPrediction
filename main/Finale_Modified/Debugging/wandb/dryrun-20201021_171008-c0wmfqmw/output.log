==============================================Features==============================================
Prediction = depth, Environment = unity
Available features :  ['x-0', 'y-1', 'z-2', 'u-3', 'v-4', 'd-5', 'eot-6', 'og-7', 'rad-8', 'f_sin-9', 'f_cos-10', 'g-11']
Selected features :  [5]
1. input_col =  [3, 4, 5]
2. input_startpos_col =  [3, 4, 5, 5]
3. gt_col =  [5, 5]
4. gt_startpos_col =  [0, 1, 2, 5]
5. gt_xyz_col =  [0, 1, 2, 5]
====================================================================================================
[#]Training : Trajectory Estimation
Mixed:   0%|                                                                                                                  | 0/1 [00:00<?, ?it/s]Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 51.60it/s]
===============================Dataset shape===============================
Mixed : (724,)
===========================================================================
Mixed:   0%|                                                                                                                  | 0/1 [00:00<?, ?it/s]===============================Dataset shape===============================
Mixed: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 23.99it/s]
Mixed : (1841,)
===========================================================================
======================================================Summary Batch (batch_size = 128)=========================================================================
Input batch [0] : batch=torch.Size([128, 1810, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1810, 3]), initial position=torch.Size([128, 1, 4])
gt batch [0] : batch=torch.Size([128, 1810, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1811, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [1] : batch=torch.Size([128, 1820, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1820, 3]), initial position=torch.Size([128, 1, 4])
gt batch [1] : batch=torch.Size([128, 1820, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1821, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [2] : batch=torch.Size([128, 1997, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1997, 3]), initial position=torch.Size([128, 1, 4])
gt batch [2] : batch=torch.Size([128, 1997, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1998, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [3] : batch=torch.Size([128, 1814, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1814, 3]), initial position=torch.Size([128, 1, 4])
gt batch [3] : batch=torch.Size([128, 1814, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1815, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [4] : batch=torch.Size([128, 1806, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1806, 3]), initial position=torch.Size([128, 1, 4])
gt batch [4] : batch=torch.Size([128, 1806, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1807, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
{'flag': {'input_size': 2, 'output_size': 1, 'hidden_dim': 32, 'n_layers': 1, 'n_stack': 4, 'recurrent_stacked': [2, 32, 32, 32, 32], 'fc_size': [64, 32, 16, 8, 4, 1]}, 'depth': {'input_size': 3, 'output_size': 1, 'hidden_dim': 32, 'n_layers': 1, 'n_stack': 4, 'recurrent_stacked': [3, 32, 32, 32, 32], 'fc_size': [64, 32, 16, 8, 4, 1]}}
===>No model checkpoint
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - Depth #######
BiLSTMResidual(
  (recurrent_blocks): ModuleList(
    (0): LSTM(3, 32, batch_first=True, bidirectional=True)
    (1): LSTM(64, 32, batch_first=True, bidirectional=True)
    (2): LSTM(64, 32, batch_first=True, bidirectional=True)
    (3): LSTM(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.003
===> [Minibatch 1/5].........PackedSequence(data=tensor([[-0.0000,  0.0000, -0.0066],
        [-0.0000, -0.0000, -0.0613],
        [-0.0000,  0.0000, -0.1403],
        ...,
        [-0.0000,  0.0000, -0.0066],
        [-0.0000,  0.0000, -0.0066],
        [-0.0000, -0.0000, -0.0066]], device='cuda:0'), batch_sizes=tensor([128, 128, 128,  ...,   1,   1,   1]), sorted_indices=tensor([ 53, 100,  49, 120,  13, 102,  47,  74,  59, 122,  69,  15,  67,   6,
         68,  33, 127,  39,  56,  79,  89, 106,  95,  45, 104,  64, 105,  65,
        112,  34,  54,  58,  85, 110,  17,   5,  11, 101,  23,  50, 107,  84,
        111,  41,  37,  28, 124,  83,  78,  51,  36,  42,  76,  38, 115,  57,
         12, 118,  96,   2,  77,   7,  72,  87, 125,  66,  26,  63,  90, 117,
         44, 114,  92, 116,  97,   1,  52,  22,  91,  55,  61,  19,   3,  71,
        113,  21,  99,  14,  93,  35,  25,  16,  48,  60,  29, 121, 103,  88,
         30,  62,  18,  24,  31,   8,  75,  32,   9,  94, 119,  82,  27,  81,
          0,  80, 123, 108, 126,  43,  40,   4,  10, 109,  70,  98,  46,  73,
         20,  86], device='cuda:0'), unsorted_indices=tensor([112,  75,  59,  82, 119,  35,  13,  61, 103, 106, 120,  36,  56,   4,
         87,  11,  91,  34, 100,  81, 126,  85,  77,  38, 101,  90,  66, 110,
         45,  94,  98, 102, 105,  15,  29,  89,  50,  44,  53,  17, 118,  43,
         51, 117,  70,  23, 124,   6,  92,   2,  39,  49,  76,   0,  30,  79,
         18,  55,  31,   8,  93,  80,  99,  67,  25,  27,  65,  12,  14,  10,
        122,  83,  62, 125,   7, 104,  52,  60,  48,  19, 113, 111, 109,  47,
         41,  32, 127,  63,  97,  20,  68,  78,  72,  88, 107,  22,  58,  74,
        123,  86,   1,  37,   5,  96,  24,  26,  21,  40, 115, 121,  33,  42,
         28,  84,  71,  54,  73,  69,  57, 108,   3,  95,   9, 114,  46,  64,
        116,  16], device='cuda:0'))
PackedSequence(data=tensor([[ 0.0144,  0.1423,  0.1734,  ...,  0.1511,  0.1466, -0.0172],
        [ 0.0138,  0.1414,  0.1740,  ...,  0.1599,  0.1487, -0.0170],
        [ 0.0130,  0.1400,  0.1748,  ...,  0.1726,  0.1517, -0.0166],
        ...,
        [ 0.0917,  0.4028,  0.3549,  ...,  0.1189,  0.1192,  0.0109],
        [ 0.1004,  0.3996,  0.3522,  ...,  0.0992,  0.1018,  0.0119],
        [ 0.1160,  0.3932,  0.3458,  ...,  0.0605,  0.0691,  0.0107]],
       device='cuda:0', grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([128, 128, 128,  ...,   1,   1,   1]), sorted_indices=tensor([ 53, 100,  49, 120,  13, 102,  47,  74,  59, 122,  69,  15,  67,   6,
         68,  33, 127,  39,  56,  79,  89, 106,  95,  45, 104,  64, 105,  65,
        112,  34,  54,  58,  85, 110,  17,   5,  11, 101,  23,  50, 107,  84,
        111,  41,  37,  28, 124,  83,  78,  51,  36,  42,  76,  38, 115,  57,
         12, 118,  96,   2,  77,   7,  72,  87, 125,  66,  26,  63,  90, 117,
         44, 114,  92, 116,  97,   1,  52,  22,  91,  55,  61,  19,   3,  71,
        113,  21,  99,  14,  93,  35,  25,  16,  48,  60,  29, 121, 103,  88,
         30,  62,  18,  24,  31,   8,  75,  32,   9,  94, 119,  82,  27,  81,
          0,  80, 123, 108, 126,  43,  40,   4,  10, 109,  70,  98,  46,  73,
         20,  86], device='cuda:0'), unsorted_indices=tensor([112,  75,  59,  82, 119,  35,  13,  61, 103, 106, 120,  36,  56,   4,
         87,  11,  91,  34, 100,  81, 126,  85,  77,  38, 101,  90,  66, 110,
         45,  94,  98, 102, 105,  15,  29,  89,  50,  44,  53,  17, 118,  43,
         51, 117,  70,  23, 124,   6,  92,   2,  39,  49,  76,   0,  30,  79,
         18,  55,  31,   8,  93,  80,  99,  67,  25,  27,  65,  12,  14,  10,
        122,  83,  62, 125,   7, 104,  52,  60,  48,  19, 113, 111, 109,  47,
         41,  32, 127,  63,  97,  20,  68,  78,  72,  88, 107,  22,  58,  74,
        123,  86,   1,  37,   5,  96,  24,  26,  21,  40, 115, 121,  33,  42,
         28,  84,  71,  54,  73,  69,  57, 108,   3,  95,   9, 114,  46,  64,
        116,  16], device='cuda:0'))
tensor([[[ 1.5039e-02,  1.4334e-01,  1.7268e-01,  ...,  1.4132e-01,
           1.4424e-01, -1.7479e-02],
         [ 3.6723e-02,  2.4782e-01,  2.5549e-01,  ...,  1.3192e-01,
           1.3972e-01, -6.5932e-03],
         [ 5.5109e-02,  3.1703e-01,  2.9756e-01,  ...,  1.2625e-01,
           1.3819e-01,  1.6647e-03],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01]],

        [[ 1.3740e-02,  1.4122e-01,  1.7406e-01,  ...,  1.6130e-01,
           1.4900e-01, -1.6966e-02],
         [ 3.4435e-02,  2.4379e-01,  2.5697e-01,  ...,  1.5225e-01,
           1.4392e-01, -7.2837e-03],
         [ 5.2205e-02,  3.1152e-01,  2.9851e-01,  ...,  1.4679e-01,
           1.4220e-01,  1.7823e-04],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01]],

        [[ 1.3358e-02,  1.4060e-01,  1.7445e-01,  ...,  1.6702e-01,
           1.5037e-01, -1.6804e-02],
         [ 3.3764e-02,  2.4261e-01,  2.5738e-01,  ...,  1.5808e-01,
           1.4513e-01, -7.4658e-03],
         [ 5.1354e-02,  3.0990e-01,  2.9876e-01,  ...,  1.5267e-01,
           1.4336e-01, -2.3118e-04],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01]],

        ...,

        [[ 1.3139e-02,  1.4025e-01,  1.7467e-01,  ...,  1.7028e-01,
           1.5115e-01, -1.6709e-02],
         [ 3.3379e-02,  2.4193e-01,  2.5762e-01,  ...,  1.6139e-01,
           1.4583e-01, -7.5659e-03],
         [ 5.0866e-02,  3.0897e-01,  2.9890e-01,  ...,  1.5602e-01,
           1.4402e-01, -4.6055e-04],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01]],

        [[ 1.3947e-02,  1.4156e-01,  1.7384e-01,  ...,  1.5818e-01,
           1.4825e-01, -1.7051e-02],
         [ 3.4798e-02,  2.4443e-01,  2.5674e-01,  ...,  1.4908e-01,
           1.4326e-01, -7.1814e-03],
         [ 5.2665e-02,  3.1239e-01,  2.9837e-01,  ...,  1.4358e-01,
           1.4157e-01,  4.0469e-04],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01]],

        [[ 1.4733e-02,  1.4284e-01,  1.7301e-01,  ...,  1.4611e-01,
           1.4538e-01, -1.7363e-02],
         [ 3.6183e-02,  2.4686e-01,  2.5585e-01,  ...,  1.3679e-01,
           1.4072e-01, -6.7658e-03],
         [ 5.4423e-02,  3.1573e-01,  2.9780e-01,  ...,  1.3117e-01,
           1.3915e-01,  1.3012e-03],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01,  ..., -1.0000e+01,
          -1.0000e+01, -1.0000e+01]]], device='cuda:0',
       grad_fn=<IndexSelectBackward>)
