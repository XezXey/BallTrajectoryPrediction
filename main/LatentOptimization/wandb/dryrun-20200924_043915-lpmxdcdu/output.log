[%]GPU Enabled
/home/puntawat/Mint/Work/Vision/BallTrajectory/UnityDataset//RealWorld/Unity/Mixed/NormalScaled/No_noise/train_set
Mixed:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]Mixed:  67%|███████████████████████████████████████████████████▎                         | 2/3 [00:00<00:00, 13.25it/s]Mixed: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 12.09it/s]
===============================Dataset shape===============================
Mixed : (7434,)
===========================================================================
Mixed:   0%|                                                                                     | 0/2 [00:00<?, ?it/s]Mixed: 100%|█████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 15.82it/s]Mixed: 100%|█████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 15.80it/s]
===============================Dataset shape===============================
Mixed : (2000,)
===========================================================================
[[ 2.15445100e+00 -4.27382100e-08 -2.08326500e+00 ... -3.42505700e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.51590000e-02  1.11173543e-01 -5.05010000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.51590000e-02  1.08448600e-01 -5.05010000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-8.60500000e-03 -6.03706000e-03  4.26200000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.60400000e-03 -8.76206900e-03  4.26300000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.43100000e-03 -7.59098600e-03  3.68100000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[-6.6922720e+00  2.3326850e-04  1.6867470e+00 ... -4.8595420e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.6732700e-01 -1.8666590e-04 -7.2825000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.6567200e-01 -3.7277747e-05 -7.1587000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-5.1650000e-03 -2.3841860e-08  8.0800000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-5.0430000e-03  7.1525584e-08  7.8920000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-4.9220000e-03 -2.3841864e-08  7.7020000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[ 4.20378400e+00 -2.17457500e-08 -1.76247400e+01 ...  4.02543800e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.92410000e-02  1.94202922e-01  6.06300000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.92410000e-02  1.91478000e-01  6.06300000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 7.00000000e-03 -2.38418600e-08  6.68400000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.83000000e-03 -2.38418600e-08  6.52300000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.66000000e-03  7.15255810e-08  6.36600000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 1.09032100e+01 -9.07235900e-09 -1.99222600e+01 ...  5.63813500e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.95800000e-02  1.32256509e-01  8.78600000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.95900000e-02  1.29531500e-01  8.78700000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-8.45000000e-03 -2.38418581e-08 -4.53000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.25200000e-03 -2.38418700e-08 -4.43000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.05400000e-03 -2.38418600e-08 -4.32000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 1.28333100e+01 -5.13435800e-08 -1.01412900e+01 ...  5.02711200e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.95300000e-02  1.12493751e-01  7.84300000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.95200000e-02  1.09768800e-01  7.84380000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-5.93300000e-03 -4.51763000e-03 -4.42700000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.93200000e-03 -7.24263700e-03 -4.42600000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.19900000e-03 -7.87918600e-03 -3.88000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[-9.9727700e+00  4.3623270e-04 -1.2477200e+01 ...  1.0030530e+01
   0.0000000e+00 -9.8100000e+00]
 [ 1.4062400e-01 -3.4894953e-04  1.6135000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.3920300e-01 -6.9832810e-05  1.5980000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 6.3280000e-03 -2.3841857e-08  7.2650000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 6.1750000e-03 -2.5331980e-08  7.0900000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 6.0260000e-03 -2.3841870e-08  6.9200000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[ 1.1648120e+00 -6.3974020e-08 -5.6482060e+00 ... -1.3697380e+01
   0.0000000e+00 -9.8100000e+00]
 [ 1.3640200e-01  7.1525583e-08 -2.1805500e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.3596100e-01 -2.3841863e-08 -2.1608000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 5.4870000e-03  7.2767350e-08 -8.0100000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 5.3560000e-03 -2.5083630e-08 -7.8100000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 5.2300000e-03 -2.3841860e-08 -7.6400000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
======================================================Summary Batch (batch_size = 128)=========================================================================
[[ 3.4821940e+00 -7.6606670e-09 -6.0726670e+00 ...  1.2645840e+01
   0.0000000e+00 -9.8100000e+00]
 [-2.1236000e-01 -2.3841863e-08  2.0209000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-2.1104200e-01 -2.3841860e-08  2.0070700e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-7.0900000e-03 -2.3096802e-08  6.7300000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-6.9100000e-03 -1.0182458e-08  6.5800000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-6.7500000e-03 -4.9918900e-08  6.4200000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[ 7.4829430e+00  6.0287190e-04 -1.4991900e+01 ...  1.0304480e+01
   0.0000000e+00 -9.8100000e+00]
 [-1.8801300e-01 -4.8232090e-04  1.6422000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.8635600e-01 -9.6416480e-05  1.6280000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 8.1110000e-03 -2.3841862e-08 -5.4930000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.9150000e-03 -2.3841860e-08 -5.3610000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.7300000e-03 -2.3841860e-08 -5.2360000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[ 8.0101400e+00  1.1633010e-03 -1.9680810e+01 ...  8.5956770e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.2021300e-01 -9.3061980e-04  1.3602000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.1866900e-01 -1.8618108e-04  1.3413000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 7.1800000e-03 -3.1461443e-04  6.5471000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.0100000e-03 -6.2965610e-05  6.3909000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 6.8400000e-03 -1.2496366e-05  6.2347000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[ 9.51298700e+00 -4.32171500e-08 -8.81710100e+00 ...  3.09734600e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.47250000e-02  1.15796943e-01  5.71470000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.47260000e-02  1.13071900e-01  5.71470000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-6.82300000e-03 -2.38418600e-08  6.83300000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.65900000e-03  7.15255800e-08  6.66800000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.49900000e-03 -2.38418600e-08  6.50800000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]][[ 1.01126100e+01 -3.15135700e-08 -1.27759600e+01 ...  3.36590200e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.21200000e-02  1.04515332e-01  4.99400000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.21100000e-02  1.01790400e-01  4.99300000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-5.37300000e-03 -2.75671500e-08  7.96850000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.24800000e-03  7.10288800e-08  7.78280000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.12200000e-03 -2.55803300e-08  7.59530000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]

[[-7.0681300e+00  2.3816200e-08 -5.9656390e+00 ... -9.5876990e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.1059200e-01 -2.3841863e-08 -1.6489300e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.0958700e-01 -3.3030907e-08 -1.6327000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 7.1510000e-03 -5.5083600e-03 -7.9490000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.1420000e-03 -8.2123010e-03 -7.9380000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 6.2300000e-03 -1.6424417e-03 -6.9250000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[-7.84048700e+00  9.11074500e-03 -1.25852200e+01 ...  3.38023600e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.52740000e-02  1.17352955e-01  5.30400000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.52750000e-02  1.14628000e-01  5.30300000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 5.23100000e-03 -3.31348000e-03  5.51800000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 5.23100000e-03 -6.03848000e-03  5.51900000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 5.23000000e-03 -8.76348700e-03  5.51800000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 9.829555e+00 -2.507976e-08 -1.188713e+01 ...  8.551424e+00
   0.000000e+00 -9.810000e+00]
 [-9.990400e-02 -2.384186e-08  1.351000e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-9.867900e-02 -2.384186e-08  1.336400e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 ...
 [ 4.994000e-03 -5.400850e-03  4.120000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 4.993000e-03 -8.125857e-03  4.130000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 4.366000e-03 -7.323762e-03  3.610000e-03 ...  0.000000e+00
   1.000000e+00 -9.810000e+00]]
[[-8.94178400e+00 -1.24568900e-08 -5.17660300e+00 ... -3.11210700e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.67860000e-02  1.79164712e-01 -4.64450000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.67860000e-02  1.76439800e-01 -4.64440000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-8.42100000e-03 -2.38418600e-08  4.72200000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.21800000e-03  7.15255800e-08  4.60700000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.02000000e-03 -2.38418600e-08  4.49800000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 6.07079600e+00 -4.41907800e-10 -2.36906500e+00 ... -6.43403100e+00
   0.00000000e+00 -9.81000000e+00]
 [-1.65657000e-01 -2.38418622e-08 -9.74420000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-1.64461000e-01 -2.38418600e-08 -9.57130000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 6.68522000e-03 -2.53319800e-08  7.07100000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.52440000e-03 -2.53319800e-08  6.90100000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.37220000e-03 -2.28484500e-08  6.74000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 1.5578780e+01 -6.4873450e-08 -3.4191520e+00 ... -1.2673310e+01
   0.0000000e+00 -9.8100000e+00]
 [-1.7375000e-01  7.1525587e-08 -2.0392600e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.7244000e-01 -2.3841867e-08 -2.0253100e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-8.9600000e-03  7.1525580e-08  3.6900000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-8.7460000e-03 -2.3841860e-08  3.5900000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-8.5340000e-03 -2.3841860e-08  3.5000000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[-7.53180800e+00  1.15700400e-03 -7.95534500e+00 ...  8.09425900e+00
   0.00000000e+00 -9.81000000e+00]
 [ 1.27220000e-01 -9.25688700e-04  1.29933000e-01 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 1.25436000e-01 -1.85045420e-04  1.28284000e-01 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 8.16000000e-03 -2.38418600e-08 -5.22700000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.96300000e-03  7.15255865e-08 -5.10100000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.77100000e-03 -2.38418665e-08 -4.97800000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 1.64967100e+01  7.58044000e-04  7.04590900e-01 ... -4.53338000e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.75200000e-02  1.51883256e-01 -7.14393000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.75200000e-02  1.49158300e-01 -7.14393000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-4.10500000e-03 -2.41336000e-03  2.66800000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-4.10600000e-03 -5.13836000e-03  2.66800000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-4.10500000e-03 -7.86336700e-03  2.66900000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 4.114690e-01 -1.863681e-08 -3.871692e+00 ... -1.188124e+01
   0.000000e+00 -9.810000e+00]
 [ 1.819892e-01 -2.458692e-08 -1.891160e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 1.813293e-01 -2.483527e-08 -1.871040e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 ...
 [-3.301700e-03 -2.566050e-03  4.952000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-3.301700e-03 -5.291040e-03  4.951000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-3.301700e-03 -8.016054e-03  4.952000e-03 ...  0.000000e+00
   1.000000e+00 -9.810000e+00]]
[[ 2.34448500e+00 -6.16062600e-08 -2.80274300e+00 ... -4.27706000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.52580000e-02  1.19961562e-01 -6.49810000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.52580000e-02  1.17236500e-01 -6.49810000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-8.53200000e-03 -2.38418600e-08  4.68100000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.32800000e-03  7.15255880e-08  4.57000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.13300000e-03 -2.38418580e-08  4.46300000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 6.35948800e+00 -4.51017000e-09 -8.65633900e+00 ...  4.38993500e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.91530000e-02  1.55353305e-01  6.66080000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.91540000e-02  1.52628300e-01  6.66070000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 4.53800000e-03  2.33472000e-03 -3.86600000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 4.53800000e-03 -3.90280000e-04 -3.86700000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 4.53800000e-03 -3.11527000e-03 -3.86600000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[-4.906366e+00  4.210478e-04 -8.530399e-01 ... -6.600111e+00
   0.000000e+00 -9.810000e+00]
 [ 1.313740e-01 -3.368629e-04 -1.133734e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 1.294640e-01 -6.735004e-05 -1.123787e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 ...
 [ 6.270000e-03 -4.993640e-03  6.531000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 6.280000e-03 -7.718652e-03  6.530000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 5.490000e-03 -7.961964e-03  5.718000e-03 ...  0.000000e+00
   1.000000e+00 -9.810000e+00]]
[[ 8.11832000e+00  1.03264700e-03 -1.11263200e+01 ...  3.21854800e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.57490000e-02  1.78555253e-01  5.04900000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.57490000e-02  1.75830200e-01  5.04800000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 3.76500000e-03 -2.33521000e-03 -6.16000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 3.76400000e-03 -5.06021000e-03 -6.16000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 3.76400000e-03 -7.78520700e-03 -6.16000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 1.5690220e+01  2.1179430e-09  2.5159290e+00 ... -9.6087790e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.2325000e-01 -2.6077033e-08 -1.5331500e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.2194000e-01 -2.4586920e-08 -1.5191600e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-7.8990000e-03 -2.2600099e-08  5.8120000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.7090000e-03 -2.2600100e-08  5.6730000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.5290000e-03 -2.6573740e-08  5.5400000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[ 2.2573030e+00  3.2706860e-04 -5.3003200e+00 ... -7.3441700e+00
   0.0000000e+00 -9.8100000e+00]
 [ 2.1233600e-01 -2.6171211e-04 -1.1496000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 2.1072000e-01 -5.2285200e-05 -1.1363000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-6.1940000e-03 -2.3841866e-08  7.4990000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-6.0460000e-03 -2.3841860e-08  7.3190000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-5.9040000e-03 -2.3841860e-08  7.1470000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[-3.5527480e+00  1.1433420e-03 -6.4973940e+00 ...  5.8043210e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.0723800e-01 -9.1466630e-04  9.7096000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.0524800e-01 -1.8291480e-04  9.5688000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 6.9610000e-03 -2.3841860e-08 -6.5970000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 6.8000000e-03  7.1525581e-08 -6.4430000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 6.6350000e-03 -2.3841861e-08 -6.2880000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[-8.20665700e+00 -3.88594500e-08 -6.77892000e+00 ...  4.92614900e+00
   0.00000000e+00 -9.81000000e+00]
 [ 8.44380000e-02  1.28546639e-01  8.58710000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 8.44380000e-02  1.25821600e-01  8.58710000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-7.98400000e-03 -1.71363370e-08 -5.40000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.79200000e-03 -2.11099830e-08 -5.26900000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.60500000e-03 -2.26001000e-08 -5.14300000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[-1.49054100e+00  1.08389400e-03  1.11871100e+01 ... -2.39567500e+00
   0.00000000e+00 -9.81000000e+00]
 [ 4.46280000e-02  1.58183906e-01 -3.29000000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 4.46280000e-02  1.55458900e-01 -3.28900000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-7.74650000e-03  7.12772369e-08 -5.82700000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.55990000e-03 -2.43385669e-08 -5.68700000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.37820000e-03 -2.30968000e-08 -5.55100000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[-1.5552530e+00  2.4584350e-09 -8.1187400e+00 ...  5.8716630e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.6456100e-01 -2.3841865e-08  1.0522500e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.6248600e-01 -2.2351740e-08  1.0493000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-3.1340000e-03 -4.9679500e-03 -5.1100000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-3.1340000e-03 -7.6929500e-03 -5.1200000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-2.7440000e-03 -7.8091860e-03 -4.4800000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[-1.8196370e+01  1.0589650e-03 -2.4753690e+01 ...  3.8305480e+00
   0.0000000e+00 -9.8100000e+00]
 [ 3.0470000e-02  8.7707695e-02  6.0630000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 3.0480000e-02  8.4982740e-02  6.0630000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 4.0960000e-03 -2.2573600e-03  3.3345900e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 4.0960000e-03 -4.9823700e-03  3.3345800e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 4.0960000e-03 -7.7073640e-03  3.3345900e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[-2.2916710e+00  5.1047050e-07 -5.0361640e+00 ... -3.6906440e+00
   0.0000000e+00 -9.8100000e+00]
 [ 4.9651000e-02  1.0864089e-01 -6.8952000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 4.9651000e-02  1.0591580e-01 -6.8952000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-5.2929000e-03 -2.6252800e-03  4.6100000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-5.2930000e-03 -5.3502800e-03  4.6200000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-5.2929000e-03 -8.0752860e-03  4.6200000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[ 2.08267400e+00  2.09703200e-03 -2.13442600e+00 ... -2.59456700e+00
   0.00000000e+00 -9.81000000e+00]
 [ 4.02050000e-02  1.96121968e-01 -4.06140000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 4.02060000e-02  1.93397000e-01 -4.06150000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-8.45800000e-03 -2.38418600e-08  4.57100000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.26100000e-03  7.15255791e-08  4.46400000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.06200000e-03 -2.38418591e-08  4.35600000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]][[ 1.7216050e+00  3.5676560e-09 -1.6983330e+00 ... -5.7728180e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.4378200e-01 -2.3841866e-08 -1.0254900e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.4213700e-01 -2.1606690e-08 -1.0157000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-6.1550000e-03 -2.4835270e-08  7.5758000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-6.0070000e-03  7.4754169e-08  7.3934000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-5.8670000e-03 -2.1606689e-08  7.2210000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]

Input batch [0] : batch=torch.Size([128, 953, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 953, 4]), initial position=torch.Size([128, 1, 4])
Output batch [0] : batch=torch.Size([128, 953, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 954, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.85067900e+01 -1.44587100e-08  5.12277900e+00 ... -4.70377000e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.80600000e-02  1.98312514e-01 -7.24970000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.80500000e-02  1.95587500e-01 -7.24960000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-7.27600000e-03 -2.23517400e-08  6.51600000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.10200000e-03 -2.53319800e-08  6.36000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.93000000e-03  6.82969970e-08  6.20700000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [1] : batch=torch.Size([128, 891, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 891, 4]), initial position=torch.Size([128, 1, 4])
Output batch [1] : batch=torch.Size([128, 891, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 892, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.4417350e+01  1.0605450e-03  9.5016650e+00 ... -1.0550190e+01
   0.0000000e+00 -9.8100000e+00]
 [-1.1675000e-01 -8.4841310e-04 -1.6731300e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.1537000e-01 -1.6968255e-04 -1.6537000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-7.6820000e-03 -4.8375140e-05 -6.0140000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.4970000e-03 -9.6522240e-06 -5.8690000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.3160000e-03 -1.9073493e-06 -5.7280000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [2] : batch=torch.Size([128, 942, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 942, 4]), initial position=torch.Size([128, 1, 4])
Output batch [2] : batch=torch.Size([128, 942, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 943, 4]), initial position=torch.Size([128, 1, 4])
[[-7.9828810e+00  8.9730590e-03 -2.6930520e+00 ... -5.3635530e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.6439100e-01 -7.1784260e-03 -8.5212000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.5914800e-01 -1.4356969e-03 -8.2447000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 6.5800000e-03 -2.3841870e-08  6.9590000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 6.4300000e-03  7.1525590e-08  6.7970000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 6.2700000e-03 -2.3841870e-08  6.6340000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [3] : batch=torch.Size([128, 849, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 849, 4]), initial position=torch.Size([128, 1, 4])
Output batch [3] : batch=torch.Size([128, 849, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 850, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.1658030e+01  0.0000000e+00 -1.7694270e+01 ...  8.4440990e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.0568000e-01 -2.3841860e-08  1.4464000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.0466000e-01 -2.3841860e-08  1.4300000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-7.0210000e-03 -2.1358340e-08  6.8011100e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-6.8520000e-03  7.4257469e-08  6.6373340e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-6.6870000e-03 -2.4586919e-08  6.4776690e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [4] : batch=torch.Size([128, 869, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 869, 4]), initial position=torch.Size([128, 1, 4])
Output batch [4] : batch=torch.Size([128, 869, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 870, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.69144400e+01  3.97658400e-04 -1.17446200e+01 ...  3.40531800e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.92400000e-02  1.78108642e-01  5.27500000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.92400000e-02  1.75383600e-01  5.27400000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-7.32500000e-03 -7.18670000e-03 -8.14000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.73100000e-03 -8.64507800e-03 -7.49000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.25400000e-03 -1.72894080e-03 -6.94000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [5] : batch=torch.Size([128, 914, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 914, 4]), initial position=torch.Size([128, 1, 4])
Output batch [5] : batch=torch.Size([128, 914, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 915, 4]), initial position=torch.Size([128, 1, 4])
[[-1.98763700e-01 -5.56511400e-08  2.48749800e-01 ... -7.31323800e+00
   0.00000000e+00 -9.81000000e+00]
 [ 1.54443030e-01 -2.28484400e-08 -1.29097400e-01 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 1.52415670e-01  7.40091130e-08 -1.28548453e-01 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-7.06000000e-03 -2.50836270e-08  6.73720000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.88900000e-03 -2.43385600e-08  6.57500000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.72900000e-03 -2.33451600e-08  6.42180000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [6] : batch=torch.Size([128, 912, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 912, 4]), initial position=torch.Size([128, 1, 4])
Output batch [6] : batch=torch.Size([128, 912, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 913, 4]), initial position=torch.Size([128, 1, 4])
[[-1.3864450e+01  7.3650900e-03 -2.2434920e+01 ...  4.5089090e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.0010000e-02  2.0918771e-01  7.0520000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.0000000e-02  2.0646280e-01  7.0510000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-7.2050000e-03 -2.2103400e-08 -6.6530000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.0310000e-03 -2.7318800e-08 -6.4920000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-6.8670000e-03  7.3015701e-08 -6.3410000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [7] : batch=torch.Size([128, 844, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 844, 4]), initial position=torch.Size([128, 1, 4])
Output batch [7] : batch=torch.Size([128, 844, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 845, 4]), initial position=torch.Size([128, 1, 4])
[[ 9.57171200e+00  1.73039300e-03 -1.34974400e+01 ...  4.26027700e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.28780000e-02  1.68462807e-01  6.68200000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.28780000e-02  1.65737700e-01  6.68100000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 3.68900000e-03 -2.98501000e-03 -6.28000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 3.68800000e-03 -5.71001000e-03 -6.29000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 3.27200000e-03 -7.18236200e-03 -5.57000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [8] : batch=torch.Size([128, 801, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 801, 4]), initial position=torch.Size([128, 1, 4])
Output batch [8] : batch=torch.Size([128, 801, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 802, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.57990700e+00  3.57391600e-09 -1.17408300e+01 ...  3.76142400e+00
   0.00000000e+00 -9.81000000e+00]
 [ 5.24110000e-02  1.86720596e-01  5.54400000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 5.24120000e-02  1.83995500e-01  5.54400000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-5.75200000e-03 -5.45846000e-03 -5.06000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.75200000e-03 -8.18345600e-03 -5.06000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.02800000e-03 -7.14705000e-03 -4.42000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [9] : batch=torch.Size([128, 829, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 829, 4]), initial position=torch.Size([128, 1, 4])
Output batch [9] : batch=torch.Size([128, 829, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 830, 4]), initial position=torch.Size([128, 1, 4])
[[ 5.45736700e+00 -6.39038500e-08 -1.31995400e+01 ...  5.60612600e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.58510000e-02  2.16745164e-01  9.98500000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.58510000e-02  2.14020100e-01  9.98600000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 6.26000000e-03  6.40750000e-08 -7.35500000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.11100000e-03 -2.38418600e-08 -7.17800000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 5.96200000e-03 -1.68879900e-08 -7.00500000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [10] : batch=torch.Size([128, 879, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 879, 4]), initial position=torch.Size([128, 1, 4])
Output batch [10] : batch=torch.Size([128, 879, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 880, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.144188e+01 -8.251780e-08 -3.088175e+00 ... -1.118029e+01
   0.000000e+00 -9.810000e+00]
 [-1.877000e-01  7.152558e-08 -1.811590e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-1.862000e-01 -2.384186e-08 -1.799580e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 ...
 [ 6.384000e-03 -6.147230e-03  6.495000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 6.383000e-03 -8.872219e-03  6.494000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 5.508000e-03 -6.852079e-03  5.605000e-03 ...  0.000000e+00
   1.000000e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [11] : batch=torch.Size([128, 885, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 885, 4]), initial position=torch.Size([128, 1, 4])
Output batch [11] : batch=torch.Size([128, 885, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 886, 4]), initial position=torch.Size([128, 1, 4])
[[ 4.988305e+00 -3.234801e-08 -7.693312e+00 ...  9.099254e+00
   0.000000e+00 -9.810000e+00]
 [-1.233170e-01 -2.384187e-08  1.439320e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-1.220430e-01 -2.384186e-08  1.425110e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 ...
 [ 5.173000e-03 -2.564760e-03 -2.823000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 5.172000e-03 -5.289760e-03 -2.823000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 5.173000e-03 -8.014758e-03 -2.824000e-03 ...  0.000000e+00
   1.000000e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [12] : batch=torch.Size([128, 811, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 811, 4]), initial position=torch.Size([128, 1, 4])
[[-3.22253200e-01 -7.16693200e-08 -3.58112600e+00 ... -9.54213000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 1.48950400e-01  7.15255843e-08 -1.61173000e-01 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 1.47811760e-01 -2.63253943e-08 -1.59628000e-01 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-5.68900000e-03  7.15255800e-08  7.79000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.55200000e-03 -2.38418600e-08  7.60200000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.41800000e-03 -2.38418600e-08  7.42000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Output batch [12] : batch=torch.Size([128, 811, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 812, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [13] : batch=torch.Size([128, 919, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 919, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.52692100e+00 -5.77338400e-08 -2.22812200e+00 ... -4.24069200e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.91720000e-02  9.59458877e-02 -6.29130000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.91730000e-02  9.32208700e-02 -6.29130000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-6.97300000e-03 -3.33786098e-07  6.83700000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.80400000e-03 -2.53319820e-08  6.67200000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.64700000e-03 -2.53319700e-08  6.51700000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Output batch [13] : batch=torch.Size([128, 919, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 920, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [14] : batch=torch.Size([128, 817, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 817, 4]), initial position=torch.Size([128, 1, 4])
Output batch [14] : batch=torch.Size([128, 817, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 818, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.3892230e+01  8.5754670e-04 -1.4034400e+01 ...  6.4425750e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.9570000e-02 -6.8609730e-04  1.0120000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.8100000e-02 -1.3718603e-04  9.9430000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-7.1739000e-03 -5.8764900e-03  7.9000000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.1739000e-03 -8.6014830e-03  7.9000000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-6.2475000e-03 -2.2933503e-03  6.8800000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [15] : batch=torch.Size([128, 878, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 878, 4]), initial position=torch.Size([128, 1, 4])
Output batch [15] : batch=torch.Size([128, 878, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 879, 4]), initial position=torch.Size([128, 1, 4])
[[-5.24932800e+00 -6.97256000e-08 -8.12642500e+00 ...  9.58508500e+00
   0.00000000e+00 -9.81000000e+00]
 [ 1.18814000e-01  7.15255820e-08  1.53048000e-01 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 1.17516000e-01 -2.38418620e-08  1.51640000e-01 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 6.75000000e-03 -3.83853940e-06 -6.91000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.59000000e-03 -7.62939500e-07 -6.74000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.44000000e-03 -1.90734931e-07 -6.58000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [16] : batch=torch.Size([128, 967, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 967, 4]), initial position=torch.Size([128, 1, 4])
Output batch [16] : batch=torch.Size([128, 967, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 968, 4]), initial position=torch.Size([128, 1, 4])
[[ 6.50735500e+00 -7.60063400e-08 -4.48812600e+00 ... -3.73933100e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.77230000e-02  1.18159076e-01 -5.59220000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.77230000e-02  1.15434000e-01 -5.59220000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 6.35660000e-03 -2.30968100e-08  7.44400000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.20350000e-03 -2.40902100e-08  7.26600000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.05900000e-03  7.20222900e-08  7.09700000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [17] : batch=torch.Size([128, 901, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 901, 4]), initial position=torch.Size([128, 1, 4])
Output batch [17] : batch=torch.Size([128, 901, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 902, 4]), initial position=torch.Size([128, 1, 4])
[[ 7.53619900e+00 -5.13104200e-10  4.19900700e+00 ... -3.68495600e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.17800000e-02  1.22415601e-01 -5.53360000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.17800000e-02  1.19690500e-01 -5.53360000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 6.61700000e-03 -2.38418660e-08 -7.12000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.45800000e-03 -2.38418600e-08 -6.96000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.30700000e-03 -2.38418600e-08 -6.79000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [18] : batch=torch.Size([128, 904, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 904, 4]), initial position=torch.Size([128, 1, 4])
Output batch [18] : batch=torch.Size([128, 904, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 905, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.9228850e+00 -6.8319860e-08  8.9473840e-01 ... -1.0405470e+01
   0.0000000e+00 -9.8100000e+00]
 [ 1.3020000e-01  7.1277231e-08 -1.6306130e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.2962600e-01 -2.3345161e-08 -1.6107800e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-4.7495000e-03 -2.5290600e-03  2.8400000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-4.7494000e-03 -5.2540700e-03  2.8410000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-4.7495000e-03 -7.9790600e-03  2.8400000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [19] : batch=torch.Size([128, 850, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 850, 4]), initial position=torch.Size([128, 1, 4])
Output batch [19] : batch=torch.Size([128, 850, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 851, 4]), initial position=torch.Size([128, 1, 4])
[[-3.5884030e+00 -7.7684280e-09  1.1302590e-01 ... -8.6063190e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.2349900e-01 -2.5580332e-08 -1.3282225e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.2277500e-01 -2.6325390e-08 -1.3089125e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-7.2740000e-03 -2.3841865e-08  6.5830000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.0990000e-03 -1.7384690e-08  6.4230000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-6.9330000e-03 -1.7633040e-08  6.2750000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [20] : batch=torch.Size([128, 750, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 750, 4]), initial position=torch.Size([128, 1, 4])
Output batch [20] : batch=torch.Size([128, 750, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 751, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.376840e+01 -1.319227e-08 -1.999522e+01 ...  8.378140e+00
   0.000000e+00 -9.810000e+00]
 [-1.221200e-01 -2.384186e-08  1.325200e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-1.207600e-01 -2.384186e-08  1.311700e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 ...
 [-4.750000e-03 -2.483210e-03  4.739000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-4.740000e-03 -5.208220e-03  4.739000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-4.740000e-03 -7.933208e-03  4.738000e-03 ...  0.000000e+00
   1.000000e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [21] : batch=torch.Size([128, 847, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 847, 4]), initial position=torch.Size([128, 1, 4])
Output batch [21] : batch=torch.Size([128, 847, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 848, 4]), initial position=torch.Size([128, 1, 4])
[[-2.313154e+00 -2.906941e-08 -3.803036e-01 ... -9.548493e+00
   0.000000e+00 -9.810000e+00]
 [ 1.978470e-01 -2.409021e-08 -1.513872e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 1.963840e-01 -2.433857e-08 -1.501595e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 ...
 [-7.749000e-03 -5.970790e-03  3.976580e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-7.748000e-03 -8.695788e-03  3.976570e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-6.762000e-03 -6.464122e-03  3.470200e-03 ...  0.000000e+00
   1.000000e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [22] : batch=torch.Size([128, 919, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 919, 4]), initial position=torch.Size([128, 1, 4])
Output batch [22] : batch=torch.Size([128, 919, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 920, 4]), initial position=torch.Size([128, 1, 4])
[[-1.8724580e+00 -8.0158190e-08 -2.2720450e+00 ... -9.5915590e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.0965800e-01  7.1525586e-08 -1.5328100e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.0839200e-01 -2.3841866e-08 -1.5184200e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-7.7110000e-03 -2.3841870e-08  5.8200000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.5260000e-03 -2.3841860e-08  5.6790000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.3450000e-03  7.5250873e-08  5.5420000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [23] : batch=torch.Size([128, 918, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 918, 4]), initial position=torch.Size([128, 1, 4])
Output batch [23] : batch=torch.Size([128, 918, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 919, 4]), initial position=torch.Size([128, 1, 4])
[[ 9.1471640e+00 -7.2920290e-08  6.0317100e-01 ... -1.3538900e+01
   0.0000000e+00 -9.8100000e+00]
 [-1.2500000e-01  7.1028882e-08 -2.1710820e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.2397400e-01 -2.3345152e-08 -2.1549810e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 6.2100000e-03 -2.4586920e-08  7.3515000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 6.0600000e-03 -2.6573740e-08  7.1802000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 5.9200000e-03  6.9290408e-08  7.0073000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [24] : batch=torch.Size([128, 928, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 928, 4]), initial position=torch.Size([128, 1, 4])
Output batch [24] : batch=torch.Size([128, 928, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 929, 4]), initial position=torch.Size([128, 1, 4])
[[ 6.64909900e+00 -6.99765900e-09  3.58130000e+00 ... -4.41063700e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.95180000e-02  1.79211507e-01 -6.58800000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.95180000e-02  1.76486500e-01 -6.58800000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 6.85300000e-03 -2.38418600e-08  6.97400000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.68700000e-03 -2.38418600e-08  6.80500000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.53200000e-03  7.15255800e-08  6.64800000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [25] : batch=torch.Size([128, 755, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 755, 4]), initial position=torch.Size([128, 1, 4])
[[-9.533389e+00 -2.773441e-08 -1.652110e+01 ...  1.042739e+01
   0.000000e+00 -9.810000e+00]
 [ 1.135580e-01 -2.384186e-08  1.663800e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 1.123650e-01 -2.384186e-08  1.648800e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 ...
 [ 8.080000e-03 -5.732100e-03  4.739000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 8.080000e-03 -8.457103e-03  4.739000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 7.060000e-03 -5.900503e-03  4.136000e-03 ...  0.000000e+00
   1.000000e+00 -9.810000e+00]]
Output batch [25] : batch=torch.Size([128, 755, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 756, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [26] : batch=torch.Size([128, 859, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 859, 4]), initial position=torch.Size([128, 1, 4])
Output batch [26] : batch=torch.Size([128, 859, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 860, 4]), initial position=torch.Size([128, 1, 4])
[[-4.33174600e+00 -6.64623500e-08 -1.26885800e+01 ...  4.91619500e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.18540000e-02  1.79548466e-01  7.52400000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.18540000e-02  1.76823500e-01  7.52500000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-6.71800000e-03 -2.86029000e-03 -5.15400000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.71700000e-03 -5.58529000e-03 -5.15400000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.71800000e-03 -8.31028700e-03 -5.15500000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [27] : batch=torch.Size([128, 874, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 874, 4]), initial position=torch.Size([128, 1, 4])
Output batch [27] : batch=torch.Size([128, 874, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 875, 4]), initial position=torch.Size([128, 1, 4])
[[-6.78105300e+00  7.34244900e-04 -9.34930200e+00 ...  4.76818400e+00
   0.00000000e+00 -9.81000000e+00]
 [ 8.47620000e-02  1.49035855e-01  8.22500000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 8.47620000e-02  1.46311000e-01  8.22510000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-5.35500000e-03 -2.38418610e-08 -7.98200000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.23000000e-03 -2.38418600e-08 -7.79600000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.10400000e-03 -2.38418600e-08 -7.60900000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [28] : batch=torch.Size([128, 854, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 854, 4]), initial position=torch.Size([128, 1, 4])
Output batch [28] : batch=torch.Size([128, 854, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 855, 4]), initial position=torch.Size([128, 1, 4])
[[ 3.1766190e+00 -4.3962540e-08 -8.7743680e+00 ...  1.2909720e+01
   0.0000000e+00 -9.8100000e+00]
 [-1.5144300e-01 -2.3841860e-08  2.2141900e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.5033700e-01  7.1525583e-08  2.1986500e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 5.8692000e-03 -2.3096808e-08 -7.7380000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 5.7280000e-03 -2.3841860e-08 -7.5510000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 5.5944000e-03 -2.3841860e-08 -7.3760000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [29] : batch=torch.Size([128, 892, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 892, 4]), initial position=torch.Size([128, 1, 4])
Output batch [29] : batch=torch.Size([128, 892, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 893, 4]), initial position=torch.Size([128, 1, 4])
[[ 2.19097600e+00 -5.55414600e-08  2.50167600e+00 ... -2.74872600e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.73260000e-02  1.08338156e-01 -3.79620000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.73270000e-02  1.05613100e-01 -3.79630000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-5.51800000e-03 -2.38418600e-08 -7.93000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.38600000e-03 -2.38418600e-08 -7.74000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.25600000e-03  7.15255830e-08 -7.55000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [30] : batch=torch.Size([128, 905, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 905, 4]), initial position=torch.Size([128, 1, 4])
Output batch [30] : batch=torch.Size([128, 905, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 906, 4]), initial position=torch.Size([128, 1, 4])
[[ 9.2560210e+00  4.3789820e-04 -3.9672000e-01 ... -1.1283840e+01
   0.0000000e+00 -9.8100000e+00]
 [-1.2069700e-01 -3.5033429e-04 -1.8817550e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.1972900e-01 -7.0115440e-05 -1.8629710e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 7.3030000e-03 -2.3841860e-08  6.2100000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.1330000e-03 -2.3841860e-08  6.0660000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 6.9610000e-03  7.1525585e-08  5.9190000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [31] : batch=torch.Size([128, 937, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 937, 4]), initial position=torch.Size([128, 1, 4])
Output batch [31] : batch=torch.Size([128, 937, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 938, 4]), initial position=torch.Size([128, 1, 4])
[[-9.89503600e+00  2.33806900e-09 -9.37449100e+00 ...  2.66843600e+00
   0.00000000e+00 -9.81000000e+00]
 [ 3.78980000e-02  1.01433298e-01  3.83480000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 3.78980000e-02  9.87083000e-02  3.83490000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 7.72000000e-03 -2.61111000e-03 -4.56000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.71000000e-03 -5.33611000e-03 -4.56000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.72000000e-03 -8.06110700e-03 -4.56000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [32] : batch=torch.Size([128, 817, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 817, 4]), initial position=torch.Size([128, 1, 4])
Output batch [32] : batch=torch.Size([128, 817, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 818, 4]), initial position=torch.Size([128, 1, 4])
[[ 4.8655980e-01  6.0802210e-09 -6.6103660e+00 ...  9.7174800e+00
   0.0000000e+00 -9.8100000e+00]
 [ 9.2773600e-02 -2.2600101e-08  1.6680000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 9.1956800e-02 -2.3841860e-08  1.6507100e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-4.8430000e-03 -2.3841860e-08 -8.3310000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-4.7270000e-03 -2.3841860e-08 -8.1320000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-4.6130000e-03  7.1525585e-08 -7.9350000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [33] : batch=torch.Size([128, 920, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 920, 4]), initial position=torch.Size([128, 1, 4])
Output batch [33] : batch=torch.Size([128, 920, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 921, 4]), initial position=torch.Size([128, 1, 4])
[[ 6.35488500e+00  3.42557800e-04 -7.56939700e+00 ...  2.95213400e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.57170000e-02  1.36799642e-01  5.46690000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.57170000e-02  1.34074700e-01  5.46700000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 7.94800000e-03  6.87937050e-08 -5.41020000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.76400000e-03 -2.21033950e-08 -5.28420000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.57600000e-03 -2.50836200e-08 -5.15690000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [34] : batch=torch.Size([128, 839, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 839, 4]), initial position=torch.Size([128, 1, 4])
Output batch [34] : batch=torch.Size([128, 839, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 840, 4]), initial position=torch.Size([128, 1, 4])
[[ 9.2639230e+00  1.6419860e-03 -7.8401140e+00 ...  2.4900450e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.2487000e-02  7.8191544e-02  3.7328000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.2487000e-02  7.5466570e-02  3.7327000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 3.7930000e-03 -5.6422600e-03 -8.9300000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 3.7930000e-03 -8.3672670e-03 -8.9300000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 3.3130000e-03 -6.5396550e-03 -7.8000000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [35] : batch=torch.Size([128, 829, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 829, 4]), initial position=torch.Size([128, 1, 4])
Output batch [35] : batch=torch.Size([128, 829, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 830, 4]), initial position=torch.Size([128, 1, 4])
[[-8.3909520e+00  4.2976760e-04 -1.1581690e+01 ...  5.6972920e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.3520800e-01 -3.4379960e-04  8.9270000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.3346000e-01 -6.8759930e-05  8.8110000e-02 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 7.6840000e-03  7.1028877e-08  5.8492000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.4990000e-03 -2.2600097e-08  5.7084000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.3180000e-03 -2.4338570e-08  5.5711000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [36] : batch=torch.Size([128, 888, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 888, 4]), initial position=torch.Size([128, 1, 4])
Output batch [36] : batch=torch.Size([128, 888, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 889, 4]), initial position=torch.Size([128, 1, 4])
[[ 5.6710030e+00  1.1104330e-03 -1.5314170e+01 ...  8.5363180e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.6689400e-01 -8.8837190e-04  1.3255000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.6526300e-01 -1.7769343e-04  1.3074000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 7.7290000e-03 -2.6822097e-08  5.9060000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.5420000e-03 -2.3841860e-08  5.7640000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.3660000e-03 -2.0861630e-08  5.6300000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [37] : batch=torch.Size([128, 907, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 907, 4]), initial position=torch.Size([128, 1, 4])
Output batch [37] : batch=torch.Size([128, 907, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 908, 4]), initial position=torch.Size([128, 1, 4])
[[ 5.34004800e+00  4.00637700e-04 -7.82048400e+00 ...  4.87158000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.18100000e-02  1.24840562e-01  7.37290000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-8.18100000e-02  1.22115500e-01  7.37290000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 5.63500000e-03 -2.38418600e-08 -7.88000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 5.49900000e-03 -2.65737500e-08 -7.68900000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 5.36700000e-03  7.42574700e-08 -7.50500000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [38] : batch=torch.Size([128, 872, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 872, 4]), initial position=torch.Size([128, 1, 4])
Output batch [38] : batch=torch.Size([128, 872, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 873, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [39] : batch=torch.Size([128, 866, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 866, 4]), initial position=torch.Size([128, 1, 4])
Output batch [39] : batch=torch.Size([128, 866, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 867, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [40] : batch=torch.Size([128, 834, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 834, 4]), initial position=torch.Size([128, 1, 4])
Output batch [40] : batch=torch.Size([128, 834, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 835, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [41] : batch=torch.Size([128, 925, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 925, 4]), initial position=torch.Size([128, 1, 4])
Output batch [41] : batch=torch.Size([128, 925, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 926, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [42] : batch=torch.Size([128, 939, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 939, 4]), initial position=torch.Size([128, 1, 4])
Output batch [42] : batch=torch.Size([128, 939, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 940, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [43] : batch=torch.Size([128, 829, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 829, 4]), initial position=torch.Size([128, 1, 4])
Output batch [43] : batch=torch.Size([128, 829, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 830, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [44] : batch=torch.Size([128, 835, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 835, 4]), initial position=torch.Size([128, 1, 4])
Output batch [44] : batch=torch.Size([128, 835, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 836, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [45] : batch=torch.Size([128, 823, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 823, 4]), initial position=torch.Size([128, 1, 4])
Output batch [45] : batch=torch.Size([128, 823, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 824, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [46] : batch=torch.Size([128, 882, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 882, 4]), initial position=torch.Size([128, 1, 4])
Output batch [46] : batch=torch.Size([128, 882, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 883, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [47] : batch=torch.Size([128, 876, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 876, 4]), initial position=torch.Size([128, 1, 4])
Output batch [47] : batch=torch.Size([128, 876, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 877, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [48] : batch=torch.Size([128, 849, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 849, 4]), initial position=torch.Size([128, 1, 4])
Output batch [48] : batch=torch.Size([128, 849, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 850, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [49] : batch=torch.Size([128, 870, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 870, 4]), initial position=torch.Size([128, 1, 4])
Output batch [49] : batch=torch.Size([128, 870, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 871, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [50] : batch=torch.Size([128, 786, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 786, 4]), initial position=torch.Size([128, 1, 4])
Output batch [50] : batch=torch.Size([128, 786, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 787, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [51] : batch=torch.Size([128, 831, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 831, 4]), initial position=torch.Size([128, 1, 4])
Output batch [51] : batch=torch.Size([128, 831, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 832, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [52] : batch=torch.Size([128, 883, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 883, 4]), initial position=torch.Size([128, 1, 4])
Output batch [52] : batch=torch.Size([128, 883, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 884, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [53] : batch=torch.Size([128, 846, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 846, 4]), initial position=torch.Size([128, 1, 4])
Output batch [53] : batch=torch.Size([128, 846, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 847, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [54] : batch=torch.Size([128, 932, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 932, 4]), initial position=torch.Size([128, 1, 4])
Output batch [54] : batch=torch.Size([128, 932, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 933, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [55] : batch=torch.Size([128, 776, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 776, 4]), initial position=torch.Size([128, 1, 4])
Output batch [55] : batch=torch.Size([128, 776, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 777, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [56] : batch=torch.Size([128, 875, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 875, 4]), initial position=torch.Size([128, 1, 4])
Output batch [56] : batch=torch.Size([128, 875, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 876, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [57] : batch=torch.Size([128, 799, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 799, 4]), initial position=torch.Size([128, 1, 4])
Output batch [57] : batch=torch.Size([128, 799, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 800, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
===>No model checkpoint
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - EOT #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(2, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
####### Model - Depth #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(4, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
[[ 3.2212810e+00  3.9214840e-04 -1.7833110e+01 ...  6.8523110e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.3460000e-01 -3.1378276e-04  1.0647000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.3306700e-01 -6.2704090e-05  1.0505000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 4.2210000e-03 -2.9680700e-03  6.3220000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 4.2200000e-03 -5.6930700e-03  6.3220000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 4.2210000e-03 -8.4180730e-03  6.3220000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[-7.4372960e+00 -2.3015050e-09 -7.3605610e-01 ... -7.8533010e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.3385400e-01 -2.4835275e-08 -1.2293580e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.3248300e-01 -2.5828680e-08 -1.2161000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 4.7300000e-03  2.1710200e-03  4.4700000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 4.7200000e-03 -5.5397000e-04  4.4700000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 4.7300000e-03 -3.2789800e-03  4.4800000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[ 4.11613800e+00  1.44416500e-03 -7.19848600e+00 ...  3.86262900e+00
   0.00000000e+00 -9.81000000e+00]
 [-4.08740000e-02  1.28588435e-01  6.80110000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-4.08750000e-02  1.25863400e-01  6.80120000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 6.94300000e-03 -2.38418570e-08 -6.61700000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.78000000e-03 -2.38418700e-08 -6.46400000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 6.61700000e-03 -2.38418600e-08 -6.30700000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 8.10765000e+00 -5.54382300e-08 -6.66244800e+00 ...  5.15400200e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.54760000e-02  1.45028455e-01  8.11650000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-7.54760000e-02  1.42303400e-01  8.11650000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 8.42300000e-03 -5.21496000e-03 -5.52500000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 8.42200000e-03 -7.93996300e-03 -5.52600000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.36700000e-03 -7.32691500e-03 -4.83400000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]][[-5.36179800e+00 -7.11893800e-08  6.02989100e+00 ... -4.58478000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.02670000e-02  1.27930571e-01 -6.86540000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 7.02680000e-02  1.25205600e-01 -6.86540000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-6.74580000e-03 -1.98682100e-08  6.98300000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.58330000e-03 -2.88089200e-08  6.81400000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.42990000e-03  6.92904080e-08  6.65500000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]

[[-5.56907700e+00  7.14460200e-04  1.46643600e+00 ... -3.76713200e+00
   0.00000000e+00 -9.81000000e+00]
 [ 5.49680000e-02  9.96633398e-02 -5.79550000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 5.49690000e-02  9.69384000e-02 -5.79560000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-4.07700000e-03 -2.58286800e-08  8.84600000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.97800000e-03 -3.05473900e-08  8.63200000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-3.88600000e-03  6.13431200e-08  8.43200000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 1.63479300e+01 -2.19138700e-08  5.53352500e+00 ... -2.66687200e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.27200000e-02  1.13697722e-01 -3.83050000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.27200000e-02  1.10972800e-01 -3.83060000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-6.92600000e-03 -2.38418580e-08 -6.88000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.75900000e-03 -1.71363400e-08 -6.71000000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.59700000e-03 -2.38418700e-08 -6.55000000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[-7.5042210e-02 -4.9930580e-08 -3.8207160e+00 ... -1.0443280e+01
   0.0000000e+00 -9.8100000e+00]
 [ 2.1748201e-01 -2.4586910e-08 -1.8019300e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 2.1593540e-01  7.3015694e-08 -1.7906900e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-7.7610000e-03 -2.5111900e-03  5.0710000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.7600000e-03 -5.2362100e-03  5.0720000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.7610000e-03 -7.9611980e-03  5.0710000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[-1.4139790e+00  1.3294170e-08  2.0552250e-01 ... -1.2821880e+01
   0.0000000e+00 -9.8100000e+00]
 [ 2.0626100e-01 -2.3096805e-08 -2.1914003e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 2.0494100e-01 -2.4090215e-08 -2.1776337e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-8.6640000e-03 -2.3841860e-08  4.4700000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-8.4560000e-03  7.1525588e-08  4.3500000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-8.2580000e-03 -2.3841858e-08  4.2600000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[ 3.890958e+00 -3.578350e-08 -6.455005e+00 ...  6.999980e+00
   0.000000e+00 -9.810000e+00]
 [-1.239910e-01 -2.384186e-08  1.101960e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-1.225240e-01  7.152558e-08  1.089760e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 ...
 [ 5.644000e-03 -2.780090e-03 -4.989000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 5.644000e-03 -5.505090e-03 -4.989000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 5.643000e-03 -8.228998e-03 -4.989000e-03 ...  0.000000e+00
   1.000000e+00 -9.810000e+00]]
[[ 6.4032710e+00 -4.7926820e-08 -5.5545250e+00 ... -6.5593910e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.1041200e-01 -2.3841860e-08 -1.0359100e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.0893400e-01  7.1525582e-08 -1.0238000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [ 7.8200000e-03 -2.3841860e-08  5.5360000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.6300000e-03 -2.3841860e-08  5.4070000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 7.4600000e-03  7.1525582e-08  5.2760000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]][[-1.3416950e+00  8.6983080e-04 -8.2363670e+00 ...  8.4005830e+00
   0.0000000e+00 -9.8100000e+00]
 [ 9.8414000e-02 -6.9592000e-04  1.4046000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 9.6870000e-02 -1.3916276e-04  1.3873700e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-7.8500000e-03 -1.9868220e-08 -5.4920000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.6660000e-03  6.7800300e-08 -5.3640000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.4820000e-03 -2.3841870e-08 -5.2350000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]

[[-7.880195e+00 -1.339641e-08 -4.190384e+00 ... -9.858935e+00
   0.000000e+00 -9.810000e+00]
 [ 2.008650e-01 -2.384187e-08 -1.696510e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 1.988860e-01 -2.384186e-08 -1.690380e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 ...
 [-5.197100e-03 -3.147280e-03  4.320000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-5.197100e-03 -5.872270e-03  4.330000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-5.197100e-03 -8.597280e-03  4.330000e-03 ...  0.000000e+00
   1.000000e+00 -9.810000e+00]]
[[ 1.2544990e+01  1.0314940e-03 -1.5180760e+01 ...  9.1795850e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.4698000e-01 -8.2523810e-04  1.4507000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-1.4528000e-01 -1.6500954e-04  1.4342000e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-8.3110000e-03 -8.2939240e-03  7.0020000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.2650000e-03 -7.6309140e-03  6.1210000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.0810000e-03 -1.5261863e-03  5.9650000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]][[-8.51835400e+00 -5.50407900e-08 -2.38013700e+00 ... -4.73592900e+00
   0.00000000e+00 -9.81000000e+00]
 [ 5.95130000e-02  1.98535455e-01 -7.24620000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 5.95130000e-02  1.95810400e-01 -7.24620000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-6.63700000e-03 -5.55447000e-03  6.69500000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.63700000e-03 -8.27946700e-03  6.69600000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.79200000e-03 -4.53894200e-03  5.84300000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]

[[ 4.87453400e+00  7.16388900e-04 -6.18442500e+00 ...  2.85610900e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.33490000e-02  1.34450311e-01  5.17710000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-5.33490000e-02  1.31725400e-01  5.17720000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [ 8.71700000e-03 -2.60770300e-08 -4.39200000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 8.50800000e-03 -2.53319800e-08 -4.28650000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [ 8.30900000e-03  7.30157000e-08 -4.18640000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 1.6613030e+00  6.8148010e-09 -3.3938710e+00 ... -9.8821360e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.3146900e-01 -2.3841861e-08 -1.5515800e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.3091000e-01 -2.3841860e-08 -1.5313100e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-5.9990000e-03 -2.3841860e-08  7.7100000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-5.8540000e-03 -3.4272680e-08  7.5240000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-5.7180000e-03  6.4075010e-08  7.3490000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[ 1.28812800e+01  3.52976400e-04  4.05550500e+00 ... -4.80790100e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.61700000e-02  1.00773124e-01 -7.54740000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.61600000e-02  9.80481000e-02 -7.54740000e-02 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 ...
 [-6.61800000e-03 -1.66396300e-08  7.16900000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.45900000e-03 -2.38418600e-08  6.99700000e-03 ...  0.00000000e+00
   0.00000000e+00 -9.81000000e+00]
 [-6.30900000e-03  7.84794600e-08  6.83400000e-03 ...  0.00000000e+00
   1.00000000e+00 -9.81000000e+00]]
[[ 5.742757e+00 -6.382832e-08  5.449726e+00 ... -8.540428e+00
   0.000000e+00 -9.810000e+00]
 [-1.544680e-01  7.152558e-08 -1.478800e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [-1.530550e-01 -2.384186e-08 -1.465990e-01 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 ...
 [ 7.751000e-03 -2.384186e-08 -5.920000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 7.564000e-03  7.152558e-08 -5.780000e-03 ...  0.000000e+00
   0.000000e+00 -9.810000e+00]
 [ 7.389000e-03 -2.384186e-08 -5.650000e-03 ...  0.000000e+00
   1.000000e+00 -9.810000e+00]]
[[-1.0793480e+00 -5.0990810e-08 -2.3926710e+00 ... -1.0649260e+01
   0.0000000e+00 -9.8100000e+00]
 [ 1.6396740e-01 -2.4338560e-08 -1.6993500e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 1.6262060e-01  7.1773935e-08 -1.6858400e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-5.3060000e-03  7.1525580e-08  8.2120000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-5.1790000e-03 -2.3841860e-08  8.0140000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-5.0590000e-03 -2.3841870e-08  7.8280000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
[[-1.2105600e-01 -1.5754760e-08 -9.9212230e+00 ...  9.7683210e+00
   0.0000000e+00 -9.8100000e+00]
 [ 2.1046535e-01 -2.3593510e-08  1.5333800e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [ 2.0906135e-01 -2.3841870e-08  1.5202500e-01 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 ...
 [-7.2090000e-03  7.1525586e-08 -6.4050000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-7.0360000e-03 -2.3841866e-08 -6.2520000e-03 ...  0.0000000e+00
   0.0000000e+00 -9.8100000e+00]
 [-6.8660000e-03 -2.3841860e-08 -6.1000000e-03 ...  0.0000000e+00
   1.0000000e+00 -9.8100000e+00]]
===> [Minibatch 1/58].........tensor([[[ 1.0368e+01, -3.4340e+00,  9.4640e-02,  1.8030e-03],
         [-1.1445e-01, -3.3870e+00,  9.3630e-02,  1.7776e-03],
         [-1.1445e-01, -3.3400e+00,  9.2620e-02,  1.7527e-03],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01]],

        [[ 1.1146e+01,  2.3317e+00, -1.0459e-01, -1.3383e-03],
         [-1.1655e-01,  2.3155e+00, -1.0357e-01, -1.3282e-03],
         [-1.1487e-01,  2.2997e+00, -1.0254e-01, -1.3189e-03],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01]],

        [[ 1.3024e+01, -3.6360e+00, -7.3530e-02, -9.4710e-04],
         [-1.5354e-01, -3.6030e+00, -7.3170e-02, -9.2430e-04],
         [-1.2224e-01, -3.5780e+00, -7.2590e-02, -9.1480e-04],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01]],

        ...,

        [[ 7.2656e+00,  7.2190e-01, -1.1812e-01,  4.5420e-04],
         [-1.1732e-01,  7.2610e-01, -1.1636e-01,  4.1740e-04],
         [-1.1556e-01,  7.3000e-01, -1.1460e-01,  3.8040e-04],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01]],

        [[ 9.4199e+00,  6.3840e-01, -7.0360e-02,  2.9308e-03],
         [-1.5485e-01,  6.4540e-01, -6.8610e-02,  2.8983e-03],
         [-1.5456e-01,  6.5250e-01, -6.6850e-02,  2.8653e-03],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01]],

        [[ 1.3230e+01,  3.5173e+00, -9.7790e-02, -1.4944e-03],
         [-1.2175e-01,  3.4972e+00, -9.7020e-02, -1.4831e-03],
         [-1.1590e-01,  3.4783e+00, -9.6210e-02, -1.4744e-03],
         ...,
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01],
         [-1.0000e+01, -1.0000e+01, -1.0000e+01, -1.0000e+01]]],
       device='cuda:0')
