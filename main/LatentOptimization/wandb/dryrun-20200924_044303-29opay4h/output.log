[%]GPU Enabled
/home/puntawat/Mint/Work/Vision/BallTrajectory/UnityDataset//RealWorld/Unity/Mixed/NormalScaled/Latent/train_set
Mixed:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]===============================Dataset shape===============================
Mixed : (5668,)
===========================================================================
Mixed: 100%|█████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 34.88it/s]
Mixed:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]Mixed: 100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.80it/s]
===============================Dataset shape===============================
Mixed : (1850,)
===========================================================================
[[ 2.317762e+02  1.871605e+02  4.487831e+01 ...  1.000000e+00
   3.743678e+00 -9.810000e+00]
 [ 6.479500e+00  2.894200e+00  9.504000e-02 ...  1.000000e+00
   3.743678e+00 -9.810000e+00]
 [ 6.397300e+00  2.856000e+00  9.420000e-02 ...  1.000000e+00
   3.743678e+00 -9.810000e+00]
 ...
 [-1.975000e-01 -6.170000e-02 -3.450000e-03 ...  1.000000e+00
   4.962403e-01 -9.810000e+00]
 [-1.927000e-01 -6.020000e-02 -3.360000e-03 ...  1.000000e+00
   4.962403e-01 -9.810000e+00]
 [-1.881000e-01 -5.890000e-02 -3.280000e-03 ...  1.000000e+00
   4.962403e-01 -9.810000e+00]]
[[ 8.545427e+02  5.843925e+02  6.306683e+01 ...  1.000000e+00
   7.680233e-01 -9.810000e+00]
 [-1.528500e+00  1.439500e+00 -1.564400e-01 ...  1.000000e+00
   7.680233e-01 -9.810000e+00]
 [-1.537100e+00  1.404700e+00 -1.546800e-01 ...  0.000000e+00
   7.680233e-01 -9.810000e+00]
 ...
 [ 7.700000e-02 -3.120000e-02 -1.500000e-03 ...  1.000000e+00
   2.445340e+00 -9.810000e+00]
 [ 7.600000e-02 -3.050000e-02 -1.450000e-03 ...  1.000000e+00
   2.445340e+00 -9.810000e+00]
 [ 7.300000e-02 -2.970000e-02 -1.420000e-03 ...  1.000000e+00
   2.445340e+00 -9.810000e+00]]
[[ 9.757884e+02  6.640549e+02  6.864381e+01 ...  1.000000e+00
   1.041603e+00 -9.810000e+00]
 [-5.176000e-01  9.023000e-01 -1.266100e-01 ...  1.000000e+00
   1.041603e+00 -9.810000e+00]
 [-5.235000e-01  8.651000e-01 -1.248600e-01 ...  0.000000e+00
   1.041603e+00 -9.810000e+00]
 ...
 [ 1.344000e-01 -9.120000e-02 -5.370000e-03 ...  1.000000e+00
   2.321098e+00 -9.810000e+00]
 [ 1.314000e-01 -8.910000e-02 -5.240000e-03 ...  1.000000e+00
   2.321098e+00 -9.810000e+00]
 [ 1.282000e-01 -8.700000e-02 -5.120000e-03 ...  1.000000e+00
   2.321098e+00 -9.810000e+00]]
[[ 6.137875e+02  5.022282e+02  5.813572e+01 ...  1.000000e+00
   3.861633e+00 -9.810000e+00]
 [ 3.803000e+00  1.712200e+00  9.430000e-02 ...  1.000000e+00
   3.861633e+00 -9.810000e+00]
 [ 3.764000e+00  1.680900e+00  9.289000e-02 ...  1.000000e+00
   3.861633e+00 -9.810000e+00]
 ...
 [ 1.384000e-01 -1.179000e-01 -6.050000e-03 ...  1.000000e+00
   2.136676e+00 -9.810000e+00]
 [ 1.350000e-01 -1.151000e-01 -5.910000e-03 ...  1.000000e+00
   2.136676e+00 -9.810000e+00]
 [ 1.319000e-01 -1.125000e-01 -5.770000e-03 ...  1.000000e+00
   2.136676e+00 -9.810000e+00]]
[[ 9.727496e+02  4.660882e+02  5.640964e+01 ...  1.000000e+00
   5.604550e+00 -9.810000e+00]
 [-4.030700e+00  1.908700e+00  9.528000e-02 ...  1.000000e+00
   5.604550e+00 -9.810000e+00]
 [-3.991500e+00  1.874500e+00  9.387000e-02 ...  1.000000e+00
   5.604550e+00 -9.810000e+00]
 ...
 [-1.021000e-01 -9.230000e-02 -5.240000e-03 ...  1.000000e+00
   9.194285e-01 -9.810000e+00]
 [-9.980000e-02 -9.010000e-02 -5.110000e-03 ...  1.000000e+00
   9.194285e-01 -9.810000e+00]
 [-9.730000e-02 -8.780000e-02 -4.980000e-03 ...  1.000000e+00
   9.194285e-01 -9.810000e+00]]
[[ 7.738643e+02  5.291201e+02  5.970315e+01 ...  1.000000e+00
   2.553582e+00 -9.810000e+00]
 [ 2.180700e+00 -1.147900e+00 -6.413000e-02 ...  1.000000e+00
   2.553582e+00 -9.810000e+00]
 [ 2.143400e+00 -1.142400e+00 -6.371000e-02 ...  1.000000e+00
   2.553582e+00 -9.810000e+00]
 ...
 [-8.850000e-02  4.750000e-02  3.490000e-03 ...  1.000000e+00
   5.588716e+00 -9.810000e+00]
 [-8.630000e-02  4.630000e-02  3.400000e-03 ...  1.000000e+00
   5.588716e+00 -9.810000e+00]
 [-8.440000e-02  4.540000e-02  3.320000e-03 ...  1.000000e+00
   5.588716e+00 -9.810000e+00]]
[[ 8.106427e+02  4.972984e+02  5.796371e+01 ...  1.000000e+00
   3.952682e+00 -9.810000e+00]
 [ 1.732100e+00  1.115400e+00  6.068000e-02 ...  1.000000e+00
   3.952682e+00 -9.810000e+00]
 [ 1.700200e+00  1.093200e+00  5.960000e-02 ...  1.000000e+00
   3.952682e+00 -9.810000e+00]
 ...
 [-1.861000e-01 -7.650000e-02 -3.850000e-03 ...  1.000000e+00
   6.064392e-01 -9.810000e+00]
 [-1.817000e-01 -7.460000e-02 -3.750000e-03 ...  1.000000e+00
   6.064392e-01 -9.810000e+00]
 [-1.775000e-01 -7.270000e-02 -3.670000e-03 ...  1.000000e+00
   6.064392e-01 -9.810000e+00]]
[[ 6.384307e+02  5.753087e+02  6.237728e+01 ...  1.000000e+00
   2.641685e+00 -9.810000e+00]
 [ 3.509000e+00 -1.262400e+00 -7.638000e-02 ...  1.000000e+00
   2.641685e+00 -9.810000e+00]
 [ 3.487000e+00 -1.252800e+00 -7.560000e-02 ...  1.000000e+00
   2.641685e+00 -9.810000e+00]
 ...
 [ 1.249000e-01 -1.032000e-01 -4.820000e-03 ...  1.000000e+00
   2.223785e+00 -9.810000e+00]
 [ 1.219000e-01 -1.009000e-01 -4.710000e-03 ...  1.000000e+00
   2.223785e+00 -9.810000e+00]
 [ 1.190000e-01 -9.850000e-02 -4.600000e-03 ...  1.000000e+00
   2.223785e+00 -9.810000e+00]]
======================================================Summary Batch (batch_size = 128)=========================================================================
[[ 9.033761e+02  3.526928e+02  5.115946e+01 ...  1.000000e+00
   5.446312e+00 -9.810000e+00]
 [-1.558400e+00  3.833900e+00 -4.351000e-02 ...  1.000000e+00
   5.446312e+00 -9.810000e+00]
 [-1.563900e+00  3.796500e+00 -4.175000e-02 ...  0.000000e+00
   5.446312e+00 -9.810000e+00]
 ...
 [ 1.020000e-01 -3.560000e-02 -1.900000e-03 ...  1.000000e+00
   2.631697e+00 -9.810000e+00]
 [ 9.960000e-02 -3.480000e-02 -1.860000e-03 ...  1.000000e+00
   2.631697e+00 -9.810000e+00]
 [ 9.720000e-02 -3.400000e-02 -1.820000e-03 ...  1.000000e+00
   2.631697e+00 -9.810000e+00]]
[[ 1.033507e+03  4.420693e+02  5.524182e+01 ...  1.000000e+00
   5.387127e+00 -9.810000e+00]
 [-3.816000e+00  2.955300e+00  1.426600e-01 ...  1.000000e+00
   5.387127e+00 -9.810000e+00]
 [-3.764000e+00  2.917500e+00  1.415400e-01 ...  1.000000e+00
   5.387127e+00 -9.810000e+00]
 ...
 [-1.813000e-01  7.580000e-02  4.110000e-03 ...  1.000000e+00
   5.694490e+00 -9.810000e+00]
 [-1.769000e-01  7.400000e-02  4.010000e-03 ...  1.000000e+00
   5.694490e+00 -9.810000e+00]
 [-1.727000e-01  7.230000e-02  3.920000e-03 ...  1.000000e+00
   5.694490e+00 -9.810000e+00]]
[[ 9.520266e+02  5.879154e+02  6.334608e+01 ...  1.000000e+00
   7.762727e-01 -9.810000e+00]
 [-2.785400e+00 -1.729100e+00 -1.121000e-01 ...  1.000000e+00
   7.762727e-01 -9.810000e+00]
 [-2.768700e+00 -1.720100e+00 -1.111100e-01 ...  1.000000e+00
   7.762727e-01 -9.810000e+00]
 ...
 [-1.351000e-01 -9.060000e-02 -5.440000e-03 ...  1.000000e+00
   8.258720e-01 -9.810000e+00]
 [-1.318000e-01 -8.840000e-02 -5.310000e-03 ...  1.000000e+00
   8.258720e-01 -9.810000e+00]
 [-1.288000e-01 -8.650000e-02 -5.180000e-03 ...  1.000000e+00
   8.258720e-01 -9.810000e+00]]
[[ 8.276803e+02  4.053313e+02  5.342633e+01 ...  1.000000e+00
   3.840416e+00 -9.810000e+00]
 [ 1.478700e+00  2.823200e+00 -4.285000e-02 ...  1.000000e+00
   3.840416e+00 -9.810000e+00]
 [ 1.480600e+00  2.784000e+00 -4.110000e-02 ...  0.000000e+00
   3.840416e+00 -9.810000e+00]
 ...
 [ 1.810000e-01  6.020000e-02  3.140000e-03 ...  1.000000e+00
   3.604078e+00 -9.810000e+00]
 [ 1.770000e-01  5.870000e-02  3.070000e-03 ...  1.000000e+00
   3.604078e+00 -9.810000e+00]
 [ 1.720000e-01  5.730000e-02  2.990000e-03 ...  1.000000e+00
   3.604078e+00 -9.810000e+00]]
[[ 9.676439e+02  5.687977e+02  6.215356e+01 ...  1.000000e+00
   9.175271e-01 -9.810000e+00]
 [-5.556000e-01  1.681300e+00 -1.438600e-01 ...  1.000000e+00
   9.175271e-01 -9.810000e+00]
 [-5.626000e-01  1.646800e+00 -1.421000e-01 ...  0.000000e+00
   9.175271e-01 -9.810000e+00]
 ...
 [-9.820000e-02  5.930000e-02  3.460000e-03 ...  1.000000e+00
   5.659652e+00 -9.810000e+00]
 [-9.570000e-02  5.820000e-02  3.380000e-03 ...  1.000000e+00
   5.659652e+00 -9.810000e+00]
 [-9.340000e-02  5.670000e-02  3.290000e-03 ...  1.000000e+00
   5.659652e+00 -9.810000e+00]]
[[ 8.040948e+02  4.330846e+02  5.471120e+01 ...  1.000000e+00
   3.925488e+00 -9.810000e+00]
 [ 3.074900e+00  1.862200e+00  9.039000e-02 ...  1.000000e+00
   3.925488e+00 -9.810000e+00]
 [ 3.037800e+00  1.831000e+00  8.917000e-02 ...  1.000000e+00
   3.925488e+00 -9.810000e+00]
 ...
 [-1.216000e-01  8.960000e-02  5.370000e-03 ...  1.000000e+00
   5.526877e+00 -9.810000e+00]
 [-1.186000e-01  8.750000e-02  5.230000e-03 ...  1.000000e+00
   5.526877e+00 -9.810000e+00]
 [-1.158000e-01  8.530000e-02  5.110000e-03 ...  1.000000e+00
   5.526877e+00 -9.810000e+00]]
[[ 8.946830e+02  6.250206e+02  6.577981e+01 ...  1.000000e+00
   6.033621e-01 -9.810000e+00]
 [-1.100000e+00  1.401300e+00 -1.064700e-01 ...  1.000000e+00
   6.033621e-01 -9.810000e+00]
 [-1.105500e+00  1.364400e+00 -1.047100e-01 ...  0.000000e+00
   6.033621e-01 -9.810000e+00]
 ...
 [ 1.090000e-01 -8.740000e-02 -3.110000e-03 ...  1.000000e+00
   2.362435e+00 -9.810000e+00]
 [ 1.070000e-01 -8.510000e-02 -3.030000e-03 ...  1.000000e+00
   2.362435e+00 -9.810000e+00]
 [ 1.040000e-01 -8.320000e-02 -2.970000e-03 ...  1.000000e+00
   2.362435e+00 -9.810000e+00]]
[[ 1.089808e+03  3.311123e+02  5.033994e+01 ...  1.000000e+00
   5.789375e+00 -9.810000e+00]
 [-3.955000e+00  1.498100e+00  5.925000e-02 ...  1.000000e+00
   5.789375e+00 -9.810000e+00]
 [-3.902000e+00  1.475600e+00  5.849000e-02 ...  1.000000e+00
   5.789375e+00 -9.810000e+00]
 ...
 [-7.510000e-02  8.430000e-02  5.170000e-03 ...  1.000000e+00
   5.202247e+00 -9.810000e+00]
 [-7.330000e-02  8.220000e-02  5.060000e-03 ...  1.000000e+00
   5.202247e+00 -9.810000e+00]
 [-7.140000e-02  8.020000e-02  4.920000e-03 ...  1.000000e+00
   5.202247e+00 -9.810000e+00]][[ 1.229850e+03  6.503978e+02  6.779552e+01 ...  1.000000e+00
   1.083974e+00 -9.810000e+00]
 [ 4.640000e-01  2.603600e+00 -2.190000e-01 ...  1.000000e+00
   1.083974e+00 -9.810000e+00]
 [ 4.560000e-01  2.579500e+00 -2.172400e-01 ...  0.000000e+00
   1.083974e+00 -9.810000e+00]
 ...
 [-1.135000e-01  6.560000e-02  2.970000e-03 ...  1.000000e+00
   5.590257e+00 -9.810000e+00]
 [-1.109000e-01  6.410000e-02  2.900000e-03 ...  1.000000e+00
   5.590257e+00 -9.810000e+00]
 [-1.082000e-01  6.260000e-02  2.830000e-03 ...  1.000000e+00
   5.590257e+00 -9.810000e+00]]

[[ 1.178310e+03  6.098373e+02  6.491516e+01 ...  1.000000e+00
   7.176818e-01 -9.810000e+00]
 [-3.402000e+00 -2.074700e+00 -1.412200e-01 ...  1.000000e+00
   7.176818e-01 -9.810000e+00]
 [-3.394000e+00 -2.070000e+00 -1.402900e-01 ...  1.000000e+00
   7.176818e-01 -9.810000e+00]
 ...
 [-9.650000e-02  5.950000e-02  4.060000e-03 ...  1.000000e+00
   5.493181e+00 -9.810000e+00]
 [-9.430000e-02  5.800000e-02  3.950000e-03 ...  1.000000e+00
   5.493181e+00 -9.810000e+00]
 [-9.190000e-02  5.660000e-02  3.860000e-03 ...  1.000000e+00
   5.493181e+00 -9.810000e+00]]
[[ 1.072790e+03  3.215678e+02  4.995096e+01 ...  1.000000e+00
   5.441826e+00 -9.810000e+00]
 [-4.163000e+00  3.134800e+00  1.236600e-01 ...  1.000000e+00
   5.441826e+00 -9.810000e+00]
 [-4.106000e+00  3.092200e+00  1.225800e-01 ...  1.000000e+00
   5.441826e+00 -9.810000e+00]
 ...
 [-6.200000e-02  4.140000e-02  3.870000e-03 ...  1.000000e+00
   5.503541e+00 -9.810000e+00]
 [-6.060000e-02  4.040000e-02  3.780000e-03 ...  1.000000e+00
   5.503541e+00 -9.810000e+00]
 [-5.910000e-02  3.940000e-02  3.680000e-03 ...  1.000000e+00
   5.503541e+00 -9.810000e+00]]
[[ 8.613613e+02  4.688690e+02  5.650125e+01 ...  1.000000e+00
   5.461960e+00 -9.810000e+00]
 [-4.392700e+00  3.251700e+00  1.641600e-01 ...  1.000000e+00
   5.461960e+00 -9.810000e+00]
 [-4.336000e+00  3.213100e+00  1.631600e-01 ...  1.000000e+00
   5.461960e+00 -9.810000e+00]
 ...
 [ 1.014000e-01 -9.950000e-02 -6.080000e-03 ...  1.000000e+00
   2.206486e+00 -9.810000e+00]
 [ 9.910000e-02 -9.710000e-02 -5.940000e-03 ...  1.000000e+00
   2.206486e+00 -9.810000e+00]
 [ 9.670000e-02 -9.490000e-02 -5.790000e-03 ...  1.000000e+00
   2.206486e+00 -9.810000e+00]]
[[ 6.355124e+02  5.628125e+02  6.160936e+01 ...  1.000000e+00
   2.359574e+00 -9.810000e+00]
 [ 2.277700e+00 -1.410400e+00 -8.410000e-02 ...  1.000000e+00
   2.359574e+00 -9.810000e+00]
 [ 2.270600e+00 -1.390100e+00 -8.264000e-02 ...  1.000000e+00
   2.359574e+00 -9.810000e+00]
 ...
 [ 8.700000e-02  2.510000e-02  1.790000e-03 ...  1.000000e+00
   3.654309e+00 -9.810000e+00]
 [ 8.600000e-02  2.470000e-02  1.740000e-03 ...  1.000000e+00
   3.654309e+00 -9.810000e+00]
 [ 8.300000e-02  2.400000e-02  1.700000e-03 ...  1.000000e+00
   3.654309e+00 -9.810000e+00]]
[[ 8.177886e+02  5.115472e+02  5.874131e+01 ...  1.000000e+00
   3.934726e+00 -9.810000e+00]
 [ 1.445700e+00  3.745500e+00 -6.417000e-02 ...  1.000000e+00
   3.934726e+00 -9.810000e+00]
 [ 1.448700e+00  3.710700e+00 -6.241000e-02 ...  0.000000e+00
   3.934726e+00 -9.810000e+00]
 ...
 [-7.270000e-02 -7.030000e-02 -4.170000e-03 ...  1.000000e+00
   9.509501e-01 -9.810000e+00]
 [-7.110000e-02 -6.880000e-02 -4.080000e-03 ...  1.000000e+00
   9.509501e-01 -9.810000e+00]
 [-6.920000e-02 -6.700000e-02 -3.980000e-03 ...  1.000000e+00
   9.509501e-01 -9.810000e+00]]
[[ 9.507859e+02  3.600053e+02  5.148433e+01 ...  1.000000e+00
   5.230030e+00 -9.810000e+00]
 [-1.149400e+00  3.782800e+00 -2.967000e-02 ...  1.000000e+00
   5.230030e+00 -9.810000e+00]
 [-1.155100e+00  3.743300e+00 -2.791000e-02 ...  0.000000e+00
   5.230030e+00 -9.810000e+00]
 ...
 [ 1.311000e-01 -9.250000e-02 -5.480000e-03 ...  1.000000e+00
   2.303960e+00 -9.810000e+00]
 [ 1.280000e-01 -9.040000e-02 -5.350000e-03 ...  1.000000e+00
   2.303960e+00 -9.810000e+00]
 [ 1.249000e-01 -8.830000e-02 -5.230000e-03 ...  1.000000e+00
   2.303960e+00 -9.810000e+00]]
[[ 8.901664e+02  6.129608e+02  6.495483e+01 ...  1.000000e+00
   5.638369e-01 -9.810000e+00]
 [-1.158500e+00  1.194800e+00 -9.842000e-02 ...  1.000000e+00
   5.638369e-01 -9.810000e+00]
 [-1.163800e+00  1.156800e+00 -9.666000e-02 ...  0.000000e+00
   5.638369e-01 -9.810000e+00]
 ...
 [ 8.130000e-02 -6.770000e-02 -2.780000e-03 ...  1.000000e+00
   2.378729e+00 -9.810000e+00]
 [ 7.920000e-02 -6.560000e-02 -2.700000e-03 ...  1.000000e+00
   2.378729e+00 -9.810000e+00]
 [ 7.720000e-02 -6.410000e-02 -2.650000e-03 ...  1.000000e+00
   2.378729e+00 -9.810000e+00]]
[[ 7.634551e+02  5.487576e+02  6.083604e+01 ...  1.000000e+00
   2.269690e+00 -9.810000e+00]
 [ 1.783700e+00 -1.425900e+00 -8.319000e-02 ...  1.000000e+00
   2.269690e+00 -9.810000e+00]
 [ 1.764700e+00 -1.410500e+00 -8.204000e-02 ...  1.000000e+00
   2.269690e+00 -9.810000e+00]
 ...
 [-1.523000e-01  8.260000e-02  4.700000e-03 ...  1.000000e+00
   5.593780e+00 -9.810000e+00]
 [-1.486000e-01  8.070000e-02  4.590000e-03 ...  1.000000e+00
   5.593780e+00 -9.810000e+00]
 [-1.452000e-01  7.870000e-02  4.470000e-03 ...  1.000000e+00
   5.593780e+00 -9.810000e+00]]
[[ 7.027921e+02  5.238666e+02  5.937064e+01 ...  1.000000e+00
   3.999716e+00 -9.810000e+00]
 [ 5.773000e-01  2.962400e+00 -6.048000e-02 ...  1.000000e+00
   3.999716e+00 -9.810000e+00]
 [ 5.820000e-01  2.925600e+00 -5.873000e-02 ...  0.000000e+00
   3.999716e+00 -9.810000e+00]
 ...
 [ 1.590000e-01 -5.230000e-02 -2.950000e-03 ...  1.000000e+00
   2.599432e+00 -9.810000e+00]
 [ 1.560000e-01 -5.100000e-02 -2.880000e-03 ...  1.000000e+00
   2.599432e+00 -9.810000e+00]
 [ 1.520000e-01 -4.980000e-02 -2.810000e-03 ...  1.000000e+00
   2.599432e+00 -9.810000e+00]]
[[ 8.370267e+02  4.684312e+02  5.646807e+01 ...  1.000000e+00
   3.882283e+00 -9.810000e+00]
 [ 8.366000e-01  1.884400e+00 -3.360000e-02 ...  1.000000e+00
   3.882283e+00 -9.810000e+00]
 [ 8.370000e-01  1.843300e+00 -3.184000e-02 ...  0.000000e+00
   3.882283e+00 -9.810000e+00]
 ...
 [-2.152000e-01 -6.660000e-02 -3.240000e-03 ...  1.000000e+00
   4.644721e-01 -9.810000e+00]
 [-2.101000e-01 -6.500000e-02 -3.160000e-03 ...  1.000000e+00
   4.644721e-01 -9.810000e+00]
 [-2.051000e-01 -6.340000e-02 -3.080000e-03 ...  1.000000e+00
   4.644721e-01 -9.810000e+00]][[ 8.342728e+02  5.429150e+02  6.052930e+01 ...  1.000000e+00
   2.219049e+00 -9.810000e+00]
 [ 1.130900e+00  4.367000e-01 -1.314500e-01 ...  1.000000e+00
   2.219049e+00 -9.810000e+00]
 [ 1.135400e+00  3.960000e-01 -1.296800e-01 ...  0.000000e+00
   2.219049e+00 -9.810000e+00]
 ...
 [-1.239000e-01  9.430000e-02  5.490000e-03 ...  1.000000e+00
   5.428933e+00 -9.810000e+00]
 [-1.211000e-01  9.210000e-02  5.370000e-03 ...  1.000000e+00
   5.428933e+00 -9.810000e+00]
 [-1.181000e-01  9.000000e-02  5.240000e-03 ...  1.000000e+00
   5.428933e+00 -9.810000e+00]]

[[ 6.998797e+02  3.448489e+02  5.076025e+01 ...  1.000000e+00
   3.917058e+00 -9.810000e+00]
 [ 4.177900e+00  2.746600e+00  1.147000e-01 ...  1.000000e+00
   3.917058e+00 -9.810000e+00]
 [ 4.122900e+00  2.709700e+00  1.136700e-01 ...  1.000000e+00
   3.917058e+00 -9.810000e+00]
 ...
 [-9.790000e-02  8.230000e-02  5.960000e-03 ...  1.000000e+00
   5.401319e+00 -9.810000e+00]
 [-9.560000e-02  8.020000e-02  5.810000e-03 ...  1.000000e+00
   5.401319e+00 -9.810000e+00]
 [-9.320000e-02  7.820000e-02  5.670000e-03 ...  1.000000e+00
   5.401319e+00 -9.810000e+00]]
[[ 1.063149e+03  5.463018e+02  6.084665e+01 ...  1.000000e+00
   6.256133e-01 -9.810000e+00]
 [-2.774000e+00 -1.148900e+00 -6.925000e-02 ...  1.000000e+00
   6.256133e-01 -9.810000e+00]
 [-2.762000e+00 -1.128400e+00 -6.787000e-02 ...  1.000000e+00
   6.256133e-01 -9.810000e+00]
 ...
 [-6.520000e-02  3.260000e-02  1.990000e-03 ...  1.000000e+00
   5.476648e+00 -9.810000e+00]
 [-6.360000e-02  3.190000e-02  1.930000e-03 ...  1.000000e+00
   5.476648e+00 -9.810000e+00]
 [-6.210000e-02  3.110000e-02  1.900000e-03 ...  1.000000e+00
   5.476648e+00 -9.810000e+00]]
[[ 5.627710e+02  5.680854e+02  6.189129e+01 ...  1.000000e+00
   2.141739e+00 -9.810000e+00]
 [ 1.257000e-01  1.447400e+00 -1.345400e-01 ...  1.000000e+00
   2.141739e+00 -9.810000e+00]
 [ 1.334000e-01  1.411400e+00 -1.327600e-01 ...  0.000000e+00
   2.141739e+00 -9.810000e+00]
 ...
 [ 1.314000e-01  9.860000e-02  5.510000e-03 ...  1.000000e+00
   4.052906e+00 -9.810000e+00]
 [ 1.282000e-01  9.620000e-02  5.380000e-03 ...  1.000000e+00
   4.052906e+00 -9.810000e+00]
 [ 1.250000e-01  9.390000e-02  5.260000e-03 ...  1.000000e+00
   4.052906e+00 -9.810000e+00]][[ 6.424149e+02  4.765530e+02  5.679615e+01 ...  1.000000e+00
   3.693403e+00 -9.810000e+00]
 [ 1.250900e+00  2.638500e+00 -5.058000e-02 ...  1.000000e+00
   3.693403e+00 -9.810000e+00]
 [ 1.258300e+00  2.599700e+00 -4.882000e-02 ...  0.000000e+00
   3.693403e+00 -9.810000e+00]
 ...
 [-1.752000e-01 -9.570000e-02 -4.970000e-03 ...  1.000000e+00
   7.284934e-01 -9.810000e+00]
 [-1.711000e-01 -9.340000e-02 -4.860000e-03 ...  1.000000e+00
   7.284934e-01 -9.810000e+00]
 [-1.671000e-01 -9.120000e-02 -4.750000e-03 ...  1.000000e+00
   7.284934e-01 -9.810000e+00]]

[[ 9.760578e+02  4.105614e+02  5.372566e+01 ...  1.000000e+00
   5.731617e+00 -9.810000e+00]
 [-5.032000e+00  2.083300e+00  9.409000e-02 ...  1.000000e+00
   5.731617e+00 -9.810000e+00]
 [-4.976400e+00  2.056700e+00  9.320000e-02 ...  1.000000e+00
   5.731617e+00 -9.810000e+00]
 ...
 [ 1.695000e-01 -1.032000e-01 -4.880000e-03 ...  1.000000e+00
   2.442962e+00 -9.810000e+00]
 [ 1.656000e-01 -1.009000e-01 -4.770000e-03 ...  1.000000e+00
   2.442962e+00 -9.810000e+00]
 [ 1.615000e-01 -9.840000e-02 -4.650000e-03 ...  1.000000e+00
   2.442962e+00 -9.810000e+00]]
[[ 1.072050e+03  4.695138e+02  5.662877e+01 ...  1.000000e+00
   5.713623e+00 -9.810000e+00]
 [-3.708000e+00  1.507900e+00  7.560000e-02 ...  1.000000e+00
   5.713623e+00 -9.810000e+00]
 [-3.658000e+00  1.488200e+00  7.481000e-02 ...  1.000000e+00
   5.713623e+00 -9.810000e+00]
 ...
 [-1.847000e-01 -8.030000e-02 -2.960000e-03 ...  1.000000e+00
   6.810526e-01 -9.810000e+00]
 [-1.804000e-01 -7.820000e-02 -2.890000e-03 ...  1.000000e+00
   6.810526e-01 -9.810000e+00]
 [-1.760000e-01 -7.620000e-02 -2.820000e-03 ...  1.000000e+00
   6.810526e-01 -9.810000e+00]]
Input batch [0] : batch=torch.Size([128, 816, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 816, 4]), initial position=torch.Size([128, 1, 4])
Output batch [0] : batch=torch.Size([128, 816, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 817, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.206585e+03  2.630922e+02  4.776920e+01 ...  1.000000e+00
   5.628713e+00 -9.810000e+00]
 [-1.765000e+00  2.953000e+00 -2.544000e-02 ...  1.000000e+00
   5.628713e+00 -9.810000e+00]
 [-1.780000e+00  2.912400e+00 -2.369000e-02 ...  0.000000e+00
   5.628713e+00 -9.810000e+00]
 ...
 [-1.271000e-01  1.023000e-01  5.730000e-03 ...  1.000000e+00
   5.403436e+00 -9.810000e+00]
 [-1.241000e-01  9.970000e-02  5.600000e-03 ...  1.000000e+00
   5.403436e+00 -9.810000e+00]
 [-1.211000e-01  9.750000e-02  5.470000e-03 ...  1.000000e+00
   5.403436e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [1] : batch=torch.Size([128, 831, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 831, 4]), initial position=torch.Size([128, 1, 4])
Output batch [1] : batch=torch.Size([128, 831, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 832, 4]), initial position=torch.Size([128, 1, 4])
[[ 9.371644e+02  4.836265e+02  5.729809e+01 ...  1.000000e+00
   5.575005e+00 -9.810000e+00]
 [-3.851000e+00  2.144800e+00  1.108000e-01 ...  1.000000e+00
   5.575005e+00 -9.810000e+00]
 [-3.802600e+00  2.118500e+00  1.098700e-01 ...  1.000000e+00
   5.575005e+00 -9.810000e+00]
 ...
 [ 1.077000e-01 -1.092000e-01 -6.190000e-03 ...  1.000000e+00
   2.179602e+00 -9.810000e+00]
 [ 1.052000e-01 -1.066000e-01 -6.050000e-03 ...  1.000000e+00
   2.179602e+00 -9.810000e+00]
 [ 1.026000e-01 -1.041000e-01 -5.910000e-03 ...  1.000000e+00
   2.179602e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [2] : batch=torch.Size([128, 1002, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 1002, 4]), initial position=torch.Size([128, 1, 4])
Output batch [2] : batch=torch.Size([128, 1002, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 1003, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.054473e+03  4.954809e+02  5.798123e+01 ...  1.000000e+00
   5.502826e+00 -9.810000e+00]
 [-1.257000e+00  2.492100e+00 -3.179000e-02 ...  1.000000e+00
   5.502826e+00 -9.810000e+00]
 [-1.265000e+00  2.451800e+00 -3.004000e-02 ...  0.000000e+00
   5.502826e+00 -9.810000e+00]
 ...
 [ 1.350000e-01 -6.880000e-02 -3.100000e-03 ...  1.000000e+00
   2.449363e+00 -9.810000e+00]
 [ 1.320000e-01 -6.700000e-02 -3.030000e-03 ...  1.000000e+00
   2.449363e+00 -9.810000e+00]
 [ 1.290000e-01 -6.530000e-02 -2.950000e-03 ...  1.000000e+00
   2.449363e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [3] : batch=torch.Size([128, 851, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 851, 4]), initial position=torch.Size([128, 1, 4])
Output batch [3] : batch=torch.Size([128, 851, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 852, 4]), initial position=torch.Size([128, 1, 4])
[[ 9.052010e+02  6.100035e+02  6.476518e+01 ...  1.000000e+00
   6.379148e-01 -9.810000e+00]
 [-1.519000e+00  1.939800e+00 -1.743300e-01 ...  1.000000e+00
   6.379148e-01 -9.810000e+00]
 [-1.529500e+00  1.908500e+00 -1.725700e-01 ...  0.000000e+00
   6.379148e-01 -9.810000e+00]
 ...
 [ 1.008000e-01  4.950000e-02  2.710000e-03 ...  1.000000e+00
   3.838102e+00 -9.810000e+00]
 [ 9.840000e-02  4.850000e-02  2.630000e-03 ...  1.000000e+00
   3.838102e+00 -9.810000e+00]
 [ 9.600000e-02  4.730000e-02  2.570000e-03 ...  1.000000e+00
   3.838102e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [4] : batch=torch.Size([128, 823, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 823, 4]), initial position=torch.Size([128, 1, 4])
Output batch [4] : batch=torch.Size([128, 823, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 824, 4]), initial position=torch.Size([128, 1, 4])
[[ 8.754253e+02  5.281804e+02  5.970050e+01 ...  1.000000e+00
   6.466195e-01 -9.810000e+00]
 [-3.173200e+00 -1.317100e+00 -7.640000e-02 ...  1.000000e+00
   6.466195e-01 -9.810000e+00]
 [-3.158100e+00 -1.296800e+00 -7.505000e-02 ...  1.000000e+00
   6.466195e-01 -9.810000e+00]
 ...
 [ 1.027000e-01  8.030000e-02  5.750000e-03 ...  1.000000e+00
   4.045160e+00 -9.810000e+00]
 [ 1.004000e-01  7.830000e-02  5.620000e-03 ...  1.000000e+00
   4.045160e+00 -9.810000e+00]
 [ 9.790000e-02  7.650000e-02  5.480000e-03 ...  1.000000e+00
   4.045160e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [5] : batch=torch.Size([128, 872, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 872, 4]), initial position=torch.Size([128, 1, 4])
Output batch [5] : batch=torch.Size([128, 872, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 873, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.036279e+03  3.988344e+02  5.321480e+01 ...  1.000000e+00
   5.381511e+00 -9.810000e+00]
 [-1.019000e+00  3.853400e+00 -6.222000e-02 ...  1.000000e+00
   5.381511e+00 -9.810000e+00]
 [-1.029000e+00  3.818500e+00 -6.046000e-02 ...  0.000000e+00
   5.381511e+00 -9.810000e+00]
 ...
 [ 9.600000e-02 -3.080000e-02 -1.670000e-03 ...  1.000000e+00
   2.646420e+00 -9.810000e+00]
 [ 9.400000e-02 -3.000000e-02 -1.630000e-03 ...  1.000000e+00
   2.646420e+00 -9.810000e+00]
 [ 9.100000e-02 -2.930000e-02 -1.590000e-03 ...  1.000000e+00
   2.646420e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [6] : batch=torch.Size([128, 845, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 845, 4]), initial position=torch.Size([128, 1, 4])
Output batch [6] : batch=torch.Size([128, 845, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 846, 4]), initial position=torch.Size([128, 1, 4])
[[ 8.096237e+02  4.566444e+02  5.586262e+01 ...  1.000000e+00
   3.743539e+00 -9.810000e+00]
 [ 2.587200e+00  1.151300e+00  5.852000e-02 ...  1.000000e+00
   3.743539e+00 -9.810000e+00]
 [ 2.545900e+00  1.132500e+00  5.770000e-02 ...  1.000000e+00
   3.743539e+00 -9.810000e+00]
 ...
 [-1.433000e-01  7.210000e-02  4.610000e-03 ...  1.000000e+00
   5.675873e+00 -9.810000e+00]
 [-1.399000e-01  7.030000e-02  4.510000e-03 ...  1.000000e+00
   5.675873e+00 -9.810000e+00]
 [-1.367000e-01  6.880000e-02  4.390000e-03 ...  1.000000e+00
   5.675873e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [7] : batch=torch.Size([128, 882, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 882, 4]), initial position=torch.Size([128, 1, 4])
Output batch [7] : batch=torch.Size([128, 882, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 883, 4]), initial position=torch.Size([128, 1, 4])
[[ 8.912244e+02  6.344619e+02  6.643610e+01 ...  1.000000e+00
   8.230655e-01 -9.810000e+00]
 [-1.287100e+00  6.760000e-01 -1.233900e-01 ...  1.000000e+00
   8.230655e-01 -9.810000e+00]
 [-1.293900e+00  6.374000e-01 -1.216200e-01 ...  0.000000e+00
   8.230655e-01 -9.810000e+00]
 ...
 [ 9.620000e-02  5.380000e-02  3.420000e-03 ...  1.000000e+00
   3.917573e+00 -9.810000e+00]
 [ 9.370000e-02  5.270000e-02  3.340000e-03 ...  1.000000e+00
   3.917573e+00 -9.810000e+00]
 [ 9.150000e-02  5.140000e-02  3.250000e-03 ...  1.000000e+00
   3.917573e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [8] : batch=torch.Size([128, 844, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 844, 4]), initial position=torch.Size([128, 1, 4])
Output batch [8] : batch=torch.Size([128, 844, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 845, 4]), initial position=torch.Size([128, 1, 4])
[[ 7.280340e+02  5.082728e+02  5.851840e+01 ...  1.000000e+00
   3.729139e+00 -9.810000e+00]
 [ 3.745200e+00  1.460200e+00  8.171000e-02 ...  1.000000e+00
   3.729139e+00 -9.810000e+00]
 [ 3.700200e+00  1.440600e+00  8.084000e-02 ...  1.000000e+00
   3.729139e+00 -9.810000e+00]
 ...
 [-7.590000e-02 -5.740000e-02 -2.470000e-03 ...  1.000000e+00
   8.470727e-01 -9.810000e+00]
 [-7.370000e-02 -5.550000e-02 -2.400000e-03 ...  1.000000e+00
   8.470727e-01 -9.810000e+00]
 [-7.200000e-02 -5.410000e-02 -2.350000e-03 ...  1.000000e+00
   8.470727e-01 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [9] : batch=torch.Size([128, 928, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 928, 4]), initial position=torch.Size([128, 1, 4])
Output batch [9] : batch=torch.Size([128, 928, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 929, 4]), initial position=torch.Size([128, 1, 4])
[[ 5.275411e+02  6.656590e+02  6.846848e+01 ...  1.000000e+00
   2.472440e+00 -9.810000e+00]
 [ 3.035000e+00 -1.607100e+00 -1.180200e-01 ...  1.000000e+00
   2.472440e+00 -9.810000e+00]
 [ 3.022000e+00 -1.600200e+00 -1.171200e-01 ...  1.000000e+00
   2.472440e+00 -9.810000e+00]
 ...
 [ 9.900000e-02 -8.120000e-02 -2.610000e-03 ...  1.000000e+00
   2.242269e+00 -9.810000e+00]
 [ 9.800000e-02 -7.900000e-02 -2.550000e-03 ...  1.000000e+00
   2.242269e+00 -9.810000e+00]
 [ 9.400000e-02 -7.700000e-02 -2.490000e-03 ...  1.000000e+00
   2.242269e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [10] : batch=torch.Size([128, 990, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 990, 4]), initial position=torch.Size([128, 1, 4])
Output batch [10] : batch=torch.Size([128, 990, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 991, 4]), initial position=torch.Size([128, 1, 4])
[[ 8.707289e+02  4.521501e+02  5.566626e+01 ...  1.000000e+00
   5.381508e+00 -9.810000e+00]
 [-3.493100e+00  2.740500e+00  1.343200e-01 ...  1.000000e+00
   5.381508e+00 -9.810000e+00]
 [-3.462200e+00  2.696400e+00  1.327800e-01 ...  1.000000e+00
   5.381508e+00 -9.810000e+00]
 ...
 [ 1.708000e-01 -1.181000e-01 -5.390000e-03 ...  1.000000e+00
   2.340409e+00 -9.810000e+00]
 [ 1.667000e-01 -1.152000e-01 -5.260000e-03 ...  1.000000e+00
   2.340409e+00 -9.810000e+00]
 [ 1.628000e-01 -1.126000e-01 -5.140000e-03 ...  1.000000e+00
   2.340409e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [11] : batch=torch.Size([128, 868, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 868, 4]), initial position=torch.Size([128, 1, 4])
Output batch [11] : batch=torch.Size([128, 868, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 869, 4]), initial position=torch.Size([128, 1, 4])
[[ 9.173661e+02  4.252896e+02  5.438836e+01 ...  1.000000e+00
   5.248091e+00 -9.810000e+00]
 [-2.144500e+00  2.401100e+00  1.126800e-01 ...  1.000000e+00
   5.248091e+00 -9.810000e+00]
 [-2.110900e+00  2.364800e+00  1.114400e-01 ...  1.000000e+00
   5.248091e+00 -9.810000e+00]
 ...
 [ 1.272000e-01 -1.221000e-01 -6.000000e-03 ...  1.000000e+00
   2.164978e+00 -9.810000e+00]
 [ 1.242000e-01 -1.193000e-01 -5.860000e-03 ...  1.000000e+00
   2.164978e+00 -9.810000e+00]
 [ 1.212000e-01 -1.164000e-01 -5.720000e-03 ...  1.000000e+00
   2.164978e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [12] : batch=torch.Size([128, 860, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 860, 4]), initial position=torch.Size([128, 1, 4])
Output batch [12] : batch=torch.Size([128, 860, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 861, 4]), initial position=torch.Size([128, 1, 4])
[[ 7.858646e+02  5.798575e+02  6.274234e+01 ...  1.000000e+00
   2.220843e+00 -9.810000e+00]
 [ 2.555500e+00 -2.211200e+00 -1.372000e-01 ...  1.000000e+00
   2.220843e+00 -9.810000e+00]
 [ 2.542900e+00 -2.202800e+00 -1.360800e-01 ...  1.000000e+00
   2.220843e+00 -9.810000e+00]
 ...
 [-1.199000e-01  9.430000e-02  5.780000e-03 ...  1.000000e+00
   5.402926e+00 -9.810000e+00]
 [-1.170000e-01  9.190000e-02  5.640000e-03 ...  1.000000e+00
   5.402926e+00 -9.810000e+00]
 [-1.142000e-01  8.980000e-02  5.510000e-03 ...  1.000000e+00
   5.402926e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [13] : batch=torch.Size([128, 853, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 853, 4]), initial position=torch.Size([128, 1, 4])
Output batch [13] : batch=torch.Size([128, 853, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 854, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.089183e+03  4.065557e+02  5.358733e+01 ...  1.000000e+00
   5.418097e+00 -9.810000e+00]
 [-9.950000e-01  3.881000e+00 -6.025000e-02 ...  1.000000e+00
   5.418097e+00 -9.810000e+00]
 [-1.007000e+00  3.845900e+00 -5.849000e-02 ...  0.000000e+00
   5.418097e+00 -9.810000e+00]
 ...
 [ 1.217000e-01 -1.089000e-01 -6.200000e-03 ...  1.000000e+00
   2.179074e+00 -9.810000e+00]
 [ 1.189000e-01 -1.062000e-01 -6.050000e-03 ...  1.000000e+00
   2.179074e+00 -9.810000e+00]
 [ 1.161000e-01 -1.038000e-01 -5.900000e-03 ...  1.000000e+00
   2.179074e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [14] : batch=torch.Size([128, 775, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 775, 4]), initial position=torch.Size([128, 1, 4])
Output batch [14] : batch=torch.Size([128, 775, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 776, 4]), initial position=torch.Size([128, 1, 4])
[[ 7.559959e+02  5.580626e+02  6.138665e+01 ...  1.000000e+00
   2.343018e+00 -9.810000e+00]
 [ 3.241000e+00 -2.430500e+00 -1.441000e-01 ...  1.000000e+00
   2.343018e+00 -9.810000e+00]
 [ 3.217000e+00 -2.430900e+00 -1.434700e-01 ...  1.000000e+00
   2.343018e+00 -9.810000e+00]
 ...
 [-1.687000e-01  6.340000e-02  3.120000e-03 ...  1.000000e+00
   5.769153e+00 -9.810000e+00]
 [-1.647000e-01  6.210000e-02  3.050000e-03 ...  1.000000e+00
   5.769153e+00 -9.810000e+00]
 [-1.607000e-01  6.060000e-02  2.970000e-03 ...  1.000000e+00
   5.769153e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [15] : batch=torch.Size([128, 852, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 852, 4]), initial position=torch.Size([128, 1, 4])
Output batch [15] : batch=torch.Size([128, 852, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 853, 4]), initial position=torch.Size([128, 1, 4])
[[ 7.206026e+02  4.095644e+02  5.357668e+01 ...  1.000000e+00
   3.863241e+00 -9.810000e+00]
 [ 1.057100e+00  2.638100e+00 -5.269000e-02 ...  1.000000e+00
   3.863241e+00 -9.810000e+00]
 [ 1.062300e+00  2.599400e+00 -5.094000e-02 ...  0.000000e+00
   3.863241e+00 -9.810000e+00]
 ...
 [-1.041000e-01  7.780000e-02  5.710000e-03 ...  1.000000e+00
   5.434533e+00 -9.810000e+00]
 [-1.016000e-01  7.590000e-02  5.590000e-03 ...  1.000000e+00
   5.434533e+00 -9.810000e+00]
 [-9.900000e-02  7.410000e-02  5.440000e-03 ...  1.000000e+00
   5.434533e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [16] : batch=torch.Size([128, 918, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 918, 4]), initial position=torch.Size([128, 1, 4])
Output batch [16] : batch=torch.Size([128, 918, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 919, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.022705e+03  4.857508e+02  5.744919e+01 ...  1.000000e+00
   5.761760e+00 -9.810000e+00]
 [-4.292000e+00  1.565800e+00  8.058000e-02 ...  1.000000e+00
   5.761760e+00 -9.810000e+00]
 [-4.242000e+00  1.546400e+00  7.982000e-02 ...  1.000000e+00
   5.761760e+00 -9.810000e+00]
 ...
 [ 1.628000e-01 -1.144000e-01 -5.440000e-03 ...  1.000000e+00
   2.332571e+00 -9.810000e+00]
 [ 1.591000e-01 -1.116000e-01 -5.300000e-03 ...  1.000000e+00
   2.332571e+00 -9.810000e+00]
 [ 1.553000e-01 -1.090000e-01 -5.190000e-03 ...  1.000000e+00
   2.332571e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [17] : batch=torch.Size([128, 953, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 953, 4]), initial position=torch.Size([128, 1, 4])
Output batch [17] : batch=torch.Size([128, 953, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 954, 4]), initial position=torch.Size([128, 1, 4])
[[ 9.595601e+02  4.428758e+02  5.524944e+01 ...  1.000000e+00
   5.361517e+00 -9.810000e+00]
 [-2.836100e+00  2.301700e+00  1.111200e-01 ...  1.000000e+00
   5.361517e+00 -9.810000e+00]
 [-2.799100e+00  2.266700e+00  1.098700e-01 ...  1.000000e+00
   5.361517e+00 -9.810000e+00]
 ...
 [ 1.950000e-01 -1.439000e-01 -5.650000e-03 ...  1.000000e+00
   2.283812e+00 -9.810000e+00]
 [ 1.900000e-01 -1.405000e-01 -5.500000e-03 ...  1.000000e+00
   2.283812e+00 -9.810000e+00]
 [ 1.860000e-01 -1.372000e-01 -5.380000e-03 ...  1.000000e+00
   2.283812e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [18] : batch=torch.Size([128, 966, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 966, 4]), initial position=torch.Size([128, 1, 4])
Output batch [18] : batch=torch.Size([128, 966, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 967, 4]), initial position=torch.Size([128, 1, 4])
[[ 1.036364e+03  5.307521e+02  5.992812e+01 ...  1.000000e+00
   8.550108e-01 -9.810000e+00]
 [-6.660000e-01  1.380200e+00 -1.403400e-01 ...  1.000000e+00
   8.550108e-01 -9.810000e+00]
 [-6.750000e-01  1.344000e+00 -1.385900e-01 ...  0.000000e+00
   8.550108e-01 -9.810000e+00]
 ...
 [ 1.245000e-01  1.095000e-01  5.570000e-03 ...  1.000000e+00
   4.027024e+00 -9.810000e+00]
 [ 1.214000e-01  1.069000e-01  5.430000e-03 ...  1.000000e+00
   4.027024e+00 -9.810000e+00]
 [ 1.184000e-01  1.042000e-01  5.310000e-03 ...  1.000000e+00
   4.027024e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [19] : batch=torch.Size([128, 858, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 858, 4]), initial position=torch.Size([128, 1, 4])
Output batch [19] : batch=torch.Size([128, 858, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 859, 4]), initial position=torch.Size([128, 1, 4])
[[ 7.461187e+02  6.441635e+02  6.703488e+01 ...  1.000000e+00
   2.507614e+00 -9.810000e+00]
 [ 9.642000e-01  1.580900e+00 -1.191200e-01 ...  1.000000e+00
   2.507614e+00 -9.810000e+00]
 [ 9.695000e-01  1.545500e+00 -1.173700e-01 ...  0.000000e+00
   2.507614e+00 -9.810000e+00]
 ...
 [-6.480000e-02 -4.760000e-02 -2.370000e-03 ...  1.000000e+00
   7.636628e-01 -9.810000e+00]
 [-6.310000e-02 -4.650000e-02 -2.300000e-03 ...  1.000000e+00
   7.636628e-01 -9.810000e+00]
 [-6.160000e-02 -4.530000e-02 -2.250000e-03 ...  1.000000e+00
   7.636628e-01 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [20] : batch=torch.Size([128, 860, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 860, 4]), initial position=torch.Size([128, 1, 4])
Output batch [20] : batch=torch.Size([128, 860, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 861, 4]), initial position=torch.Size([128, 1, 4])
[[ 4.867720e+02  3.364156e+02  5.033996e+01 ...  1.000000e+00
   4.246403e+00 -9.810000e+00]
 [ 2.633300e+00  2.797500e+00  1.143200e-01 ...  1.000000e+00
   4.246403e+00 -9.810000e+00]
 [ 2.588100e+00  2.754400e+00  1.130600e-01 ...  1.000000e+00
   4.246403e+00 -9.810000e+00]
 ...
 [ 1.263000e-01  7.680000e-02  5.340000e-03 ...  1.000000e+00
   3.929738e+00 -9.810000e+00]
 [ 1.232000e-01  7.490000e-02  5.200000e-03 ...  1.000000e+00
   3.929738e+00 -9.810000e+00]
 [ 1.203000e-01  7.320000e-02  5.080000e-03 ...  1.000000e+00
   3.929738e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [21] : batch=torch.Size([128, 949, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 949, 4]), initial position=torch.Size([128, 1, 4])
Output batch [21] : batch=torch.Size([128, 949, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 950, 4]), initial position=torch.Size([128, 1, 4])
[[ 9.054706e+02  4.703941e+02  5.659888e+01 ...  1.000000e+00
   5.450750e+00 -9.810000e+00]
 [-3.097400e+00  2.287800e+00  1.157900e-01 ...  1.000000e+00
   5.450750e+00 -9.810000e+00]
 [-3.053100e+00  2.258500e+00  1.147700e-01 ...  1.000000e+00
   5.450750e+00 -9.810000e+00]
 ...
 [ 1.424000e-01 -9.550000e-02 -5.410000e-03 ...  1.000000e+00
   2.338295e+00 -9.810000e+00]
 [ 1.391000e-01 -9.320000e-02 -5.280000e-03 ...  1.000000e+00
   2.338295e+00 -9.810000e+00]
 [ 1.358000e-01 -9.110000e-02 -5.150000e-03 ...  1.000000e+00
   2.338295e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [22] : batch=torch.Size([128, 844, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 844, 4]), initial position=torch.Size([128, 1, 4])
Output batch [22] : batch=torch.Size([128, 844, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 845, 4]), initial position=torch.Size([128, 1, 4])
[[ 7.748287e+02  5.897191e+02  6.336180e+01 ...  1.000000e+00
   2.043566e+00 -9.810000e+00]
 [ 1.592700e+00 -2.249600e+00 -1.429100e-01 ...  1.000000e+00
   2.043566e+00 -9.810000e+00]
 [ 1.578400e+00 -2.240600e+00 -1.416900e-01 ...  1.000000e+00
   2.043566e+00 -9.810000e+00]
 ...
 [-1.343000e-01  7.970000e-02  4.840000e-03 ...  1.000000e+00
   5.554646e+00 -9.810000e+00]
 [-1.309000e-01  7.760000e-02  4.720000e-03 ...  1.000000e+00
   5.554646e+00 -9.810000e+00]
 [-1.279000e-01  7.580000e-02  4.610000e-03 ...  1.000000e+00
   5.554646e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [23] : batch=torch.Size([128, 818, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 818, 4]), initial position=torch.Size([128, 1, 4])
Output batch [23] : batch=torch.Size([128, 818, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 819, 4]), initial position=torch.Size([128, 1, 4])
[[ 9.606281e+02  4.826115e+02  5.725575e+01 ...  1.000000e+00
   5.695459e+00 -9.810000e+00]
 [-1.271900e+00  3.707000e+00 -8.831000e-02 ...  1.000000e+00
   5.695459e+00 -9.810000e+00]
 [-1.280200e+00  3.675000e+00 -8.655000e-02 ...  0.000000e+00
   5.695459e+00 -9.810000e+00]
 ...
 [ 1.381000e-01 -8.160000e-02 -4.940000e-03 ...  1.000000e+00
   2.422232e+00 -9.810000e+00]
 [ 1.349000e-01 -7.970000e-02 -4.810000e-03 ...  1.000000e+00
   2.422232e+00 -9.810000e+00]
 [ 1.315000e-01 -7.770000e-02 -4.690000e-03 ...  1.000000e+00
   2.422232e+00 -9.810000e+00]]
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [24] : batch=torch.Size([128, 899, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 899, 4]), initial position=torch.Size([128, 1, 4])
Output batch [24] : batch=torch.Size([128, 899, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 900, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [25] : batch=torch.Size([128, 922, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 922, 4]), initial position=torch.Size([128, 1, 4])
Output batch [25] : batch=torch.Size([128, 922, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 923, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [26] : batch=torch.Size([128, 837, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 837, 4]), initial position=torch.Size([128, 1, 4])
Output batch [26] : batch=torch.Size([128, 837, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 838, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [27] : batch=torch.Size([128, 892, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 892, 4]), initial position=torch.Size([128, 1, 4])
Output batch [27] : batch=torch.Size([128, 892, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 893, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [28] : batch=torch.Size([128, 862, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 862, 4]), initial position=torch.Size([128, 1, 4])
Output batch [28] : batch=torch.Size([128, 862, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 863, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [29] : batch=torch.Size([128, 960, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 960, 4]), initial position=torch.Size([128, 1, 4])
Output batch [29] : batch=torch.Size([128, 960, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 961, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [30] : batch=torch.Size([128, 797, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 797, 4]), initial position=torch.Size([128, 1, 4])
Output batch [30] : batch=torch.Size([128, 797, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 798, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [31] : batch=torch.Size([128, 855, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 855, 4]), initial position=torch.Size([128, 1, 4])
Output batch [31] : batch=torch.Size([128, 855, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 856, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [32] : batch=torch.Size([128, 992, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 992, 4]), initial position=torch.Size([128, 1, 4])
Output batch [32] : batch=torch.Size([128, 992, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 993, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [33] : batch=torch.Size([128, 863, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 863, 4]), initial position=torch.Size([128, 1, 4])
Output batch [33] : batch=torch.Size([128, 863, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 864, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [34] : batch=torch.Size([128, 885, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 885, 4]), initial position=torch.Size([128, 1, 4])
Output batch [34] : batch=torch.Size([128, 885, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 886, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [35] : batch=torch.Size([128, 845, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 845, 4]), initial position=torch.Size([128, 1, 4])
Output batch [35] : batch=torch.Size([128, 845, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 846, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [36] : batch=torch.Size([128, 925, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 925, 4]), initial position=torch.Size([128, 1, 4])
Output batch [36] : batch=torch.Size([128, 925, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 926, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [37] : batch=torch.Size([128, 875, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 875, 4]), initial position=torch.Size([128, 1, 4])
Output batch [37] : batch=torch.Size([128, 875, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 876, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [38] : batch=torch.Size([128, 962, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 962, 4]), initial position=torch.Size([128, 1, 4])
Output batch [38] : batch=torch.Size([128, 962, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 963, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [39] : batch=torch.Size([128, 891, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 891, 4]), initial position=torch.Size([128, 1, 4])
Output batch [39] : batch=torch.Size([128, 891, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 892, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [40] : batch=torch.Size([128, 894, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 894, 4]), initial position=torch.Size([128, 1, 4])
Output batch [40] : batch=torch.Size([128, 894, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 895, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [41] : batch=torch.Size([128, 786, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 786, 4]), initial position=torch.Size([128, 1, 4])
Output batch [41] : batch=torch.Size([128, 786, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 787, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [42] : batch=torch.Size([128, 932, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 932, 4]), initial position=torch.Size([128, 1, 4])
Output batch [42] : batch=torch.Size([128, 932, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 933, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [43] : batch=torch.Size([128, 939, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 939, 4]), initial position=torch.Size([128, 1, 4])
Output batch [43] : batch=torch.Size([128, 939, 2]), lengths=torch.Size([128]), mask=torch.Size([128, 940, 4]), initial position=torch.Size([128, 1, 4])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
===>No model checkpoint
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - EOT #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(2, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
####### Model - Depth #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(4, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
[[ 9.751692e+02  3.369224e+02  5.053488e+01 ...  1.000000e+00
   5.438771e+00 -9.810000e+00]
 [-3.432900e+00  2.717500e+00  1.097600e-01 ...  1.000000e+00
   5.438771e+00 -9.810000e+00]
 [-3.383700e+00  2.678900e+00  1.086600e-01 ...  1.000000e+00
   5.438771e+00 -9.810000e+00]
 ...
 [ 1.109000e-01  8.010000e-02  5.510000e-03 ...  1.000000e+00
   3.937463e+00 -9.810000e+00]
 [ 1.084000e-01  7.820000e-02  5.350000e-03 ...  1.000000e+00
   3.937463e+00 -9.810000e+00]
 [ 1.057000e-01  7.640000e-02  5.240000e-03 ...  1.000000e+00
   3.937463e+00 -9.810000e+00]]
[[ 1.059059e+03  5.837484e+02  6.314019e+01 ...  1.000000e+00
   8.442305e-01 -9.810000e+00]
 [-1.726000e+00 -1.363400e+00 -8.758000e-02 ...  1.000000e+00
   8.442305e-01 -9.810000e+00]
 [-1.707000e+00 -1.350600e+00 -8.652000e-02 ...  1.000000e+00
   8.442305e-01 -9.810000e+00]
 ...
 [-1.411000e-01  7.790000e-02  4.980000e-03 ...  1.000000e+00
   5.484596e+00 -9.810000e+00]
 [-1.377000e-01  7.590000e-02  4.860000e-03 ...  1.000000e+00
   5.484596e+00 -9.810000e+00]
 [-1.343000e-01  7.410000e-02  4.740000e-03 ...  1.000000e+00
   5.484596e+00 -9.810000e+00]]
[[ 9.784537e+02  5.522704e+02  6.115684e+01 ...  1.000000e+00
   6.861744e-01 -9.810000e+00]
 [-2.225800e+00 -1.185400e+00 -7.184000e-02 ...  1.000000e+00
   6.861744e-01 -9.810000e+00]
 [-2.202000e+00 -1.173100e+00 -7.092000e-02 ...  1.000000e+00
   6.861744e-01 -9.810000e+00]
 ...
 [-8.420000e-02  9.120000e-02  6.340000e-03 ...  1.000000e+00
   5.197679e+00 -9.810000e+00]
 [-8.220000e-02  8.900000e-02  6.210000e-03 ...  1.000000e+00
   5.197679e+00 -9.810000e+00]
 [-8.020000e-02  8.680000e-02  6.040000e-03 ...  1.000000e+00
   5.197679e+00 -9.810000e+00]]
[[ 8.174312e+02  4.554597e+02  5.580709e+01 ...  1.000000e+00
   3.767909e+00 -9.810000e+00]
 [ 3.976600e+00  1.833500e+00  9.302000e-02 ...  1.000000e+00
   3.767909e+00 -9.810000e+00]
 [ 3.929700e+00  1.809200e+00  9.209000e-02 ...  1.000000e+00
   3.767909e+00 -9.810000e+00]
 ...
 [-1.746000e-01 -9.140000e-02 -4.550000e-03 ...  1.000000e+00
   6.664384e-01 -9.810000e+00]
 [-1.705000e-01 -8.930000e-02 -4.440000e-03 ...  1.000000e+00
   6.664384e-01 -9.810000e+00]
 [-1.664000e-01 -8.720000e-02 -4.330000e-03 ...  1.000000e+00
   6.664384e-01 -9.810000e+00]]
[[ 7.516282e+02  5.478057e+02  6.077373e+01 ...  1.000000e+00
   2.277028e+00 -9.810000e+00]
 [ 7.480000e-01  2.486400e+00 -1.780300e-01 ...  1.000000e+00
   2.277028e+00 -9.810000e+00]
 [ 7.544000e-01  2.458100e+00 -1.762900e-01 ...  0.000000e+00
   2.277028e+00 -9.810000e+00]
 ...
 [-1.260000e-01  1.302000e-01  6.240000e-03 ...  1.000000e+00
   5.281438e+00 -9.810000e+00]
 [-1.228000e-01  1.273000e-01  6.100000e-03 ...  1.000000e+00
   5.281438e+00 -9.810000e+00]
 [-1.200000e-01  1.241000e-01  5.940000e-03 ...  1.000000e+00
   5.281438e+00 -9.810000e+00]]
[[ 8.006116e+02  5.574796e+02  6.137518e+01 ...  1.000000e+00
   2.111606e+00 -9.810000e+00]
 [ 8.761000e-01  1.652800e+00 -1.922500e-01 ...  1.000000e+00
   2.111606e+00 -9.810000e+00]
 [ 8.821000e-01  1.620500e+00 -1.905100e-01 ...  0.000000e+00
   2.111606e+00 -9.810000e+00]
 ...
 [-1.715000e-01  1.117000e-01  4.700000e-03 ...  1.000000e+00
   5.584087e+00 -9.810000e+00]
 [-1.674000e-01  1.091000e-01  4.580000e-03 ...  1.000000e+00
   5.584087e+00 -9.810000e+00]
 [-1.634000e-01  1.064000e-01  4.480000e-03 ...  1.000000e+00
   5.584087e+00 -9.810000e+00]]
[[ 9.452314e+02  6.460778e+02  6.729876e+01 ...  1.000000e+00
   9.256128e-01 -9.810000e+00]
 [-2.521900e+00 -1.866400e+00 -1.362200e-01 ...  1.000000e+00
   9.256128e-01 -9.810000e+00]
 [-2.517700e+00 -1.855400e+00 -1.348800e-01 ...  1.000000e+00
   9.256128e-01 -9.810000e+00]
 ...
 [ 8.850000e-02  9.330000e-02  6.530000e-03 ...  1.000000e+00
   4.198469e+00 -9.810000e+00]
 [ 8.650000e-02  9.120000e-02  6.380000e-03 ...  1.000000e+00
   4.198469e+00 -9.810000e+00]
 [ 8.430000e-02  8.910000e-02  6.210000e-03 ...  1.000000e+00
   4.198469e+00 -9.810000e+00]][[ 9.910825e+02  4.581833e+02  5.601915e+01 ...  1.000000e+00
   5.553909e+00 -9.810000e+00]
 [-3.697600e+00  2.068000e+00  1.021200e-01 ...  1.000000e+00
   5.553909e+00 -9.810000e+00]
 [-3.651600e+00  2.039200e+00  1.010600e-01 ...  1.000000e+00
   5.553909e+00 -9.810000e+00]
 ...
 [ 1.990000e-01 -7.800000e-02 -3.920000e-03 ...  1.000000e+00
   2.586019e+00 -9.810000e+00]
 [ 1.950000e-01 -7.610000e-02 -3.830000e-03 ...  1.000000e+00
   2.586019e+00 -9.810000e+00]
 [ 1.900000e-01 -7.440000e-02 -3.740000e-03 ...  1.000000e+00
   2.586019e+00 -9.810000e+00]]

[[ 9.306979e+02  5.939925e+02  6.372546e+01 ...  1.000000e+00
   7.398444e-01 -9.810000e+00]
 [-1.911900e+00 -1.070900e+00 -7.041000e-02 ...  1.000000e+00
   7.398444e-01 -9.810000e+00]
 [-1.889000e+00 -1.058500e+00 -6.944000e-02 ...  1.000000e+00
   7.398444e-01 -9.810000e+00]
 ...
 [ 2.110000e-01 -1.380000e-01 -5.360000e-03 ...  1.000000e+00
   2.389361e+00 -9.810000e+00]
 [ 2.060000e-01 -1.348000e-01 -5.230000e-03 ...  1.000000e+00
   2.389361e+00 -9.810000e+00]
 [ 2.000000e-01 -1.316000e-01 -5.110000e-03 ...  1.000000e+00
   2.389361e+00 -9.810000e+00]]
[[ 8.383459e+02  3.671883e+02  5.174768e+01 ...  1.000000e+00
   3.996732e+00 -9.810000e+00]
 [ 3.472500e+00  2.648200e+00  1.147200e-01 ...  1.000000e+00
   3.996732e+00 -9.810000e+00]
 [ 3.432800e+00  2.606900e+00  1.134300e-01 ...  1.000000e+00
   3.996732e+00 -9.810000e+00]
 ...
 [-1.241000e-01  8.140000e-02  5.550000e-03 ...  1.000000e+00
   5.545016e+00 -9.810000e+00]
 [-1.213000e-01  7.940000e-02  5.420000e-03 ...  1.000000e+00
   5.545016e+00 -9.810000e+00]
 [-1.183000e-01  7.750000e-02  5.290000e-03 ...  1.000000e+00
   5.545016e+00 -9.810000e+00]]
[[ 1.052060e+03  7.338345e+02  7.438410e+01 ...  1.000000e+00
   5.617555e-01 -9.810000e+00]
 [-2.001000e+00 -6.539000e-01 -5.924000e-02 ...  1.000000e+00
   5.617555e-01 -9.810000e+00]
 [-1.981000e+00 -6.459000e-01 -5.843000e-02 ...  1.000000e+00
   5.617555e-01 -9.810000e+00]
 ...
 [-5.130000e-02 -3.160000e-02 -1.830000e-03 ...  1.000000e+00
   8.682117e-01 -9.810000e+00]
 [-5.020000e-02 -3.090000e-02 -1.800000e-03 ...  1.000000e+00
   8.682117e-01 -9.810000e+00]
 [-4.910000e-02 -3.000000e-02 -1.750000e-03 ...  1.000000e+00
   8.682117e-01 -9.810000e+00]]
[[ 1.025985e+03  6.871655e+02  7.046163e+01 ...  1.000000e+00
   9.929547e-01 -9.810000e+00]
 [-1.610000e-01  2.053000e+00 -1.501400e-01 ...  1.000000e+00
   9.929547e-01 -9.810000e+00]
 [-1.670000e-01  2.021600e+00 -1.483900e-01 ...  0.000000e+00
   9.929547e-01 -9.810000e+00]
 ...
 [-2.068000e-01 -7.250000e-02 -3.670000e-03 ...  1.000000e+00
   5.151880e-01 -9.810000e+00]
 [-2.018000e-01 -7.080000e-02 -3.590000e-03 ...  1.000000e+00
   5.151880e-01 -9.810000e+00]
 [-1.969000e-01 -6.910000e-02 -3.500000e-03 ...  1.000000e+00
   5.151880e-01 -9.810000e+00]]
[[ 1.072446e+03  5.595456e+02  6.164425e+01 ...  1.000000e+00
   7.439136e-01 -9.810000e+00]
 [-5.080000e-01  1.320700e+00 -1.286000e-01 ...  1.000000e+00
   7.439136e-01 -9.810000e+00]
 [-5.160000e-01  1.283800e+00 -1.268400e-01 ...  0.000000e+00
   7.439136e-01 -9.810000e+00]
 ...
 [-1.292000e-01  8.090000e-02  5.000000e-03 ...  1.000000e+00
   5.526545e+00 -9.810000e+00]
 [-1.260000e-01  7.890000e-02  4.860000e-03 ...  1.000000e+00
   5.526545e+00 -9.810000e+00]
 [-1.230000e-01  7.710000e-02  4.760000e-03 ...  1.000000e+00
   5.526545e+00 -9.810000e+00]]
[[ 8.853192e+02  4.654096e+02  5.633624e+01 ...  1.000000e+00
   5.637926e+00 -9.810000e+00]
 [-4.545000e+00  2.117000e+00  1.053900e-01 ...  1.000000e+00
   5.637926e+00 -9.810000e+00]
 [-4.503300e+00  2.081800e+00  1.040000e-01 ...  1.000000e+00
   5.637926e+00 -9.810000e+00]
 ...
 [ 1.146000e-01 -3.720000e-02 -2.020000e-03 ...  1.000000e+00
   2.673867e+00 -9.810000e+00]
 [ 1.118000e-01 -3.630000e-02 -1.980000e-03 ...  1.000000e+00
   2.673867e+00 -9.810000e+00]
 [ 1.092000e-01 -3.540000e-02 -1.940000e-03 ...  1.000000e+00
   2.673867e+00 -9.810000e+00]]
[[ 5.451608e+02  3.015839e+02  4.898941e+01 ...  1.000000e+00
   3.769036e+00 -9.810000e+00]
 [ 8.042000e-01  3.873900e+00 -9.848000e-02 ...  1.000000e+00
   3.769036e+00 -9.810000e+00]
 [ 8.172000e-01  3.845300e+00 -9.674000e-02 ...  0.000000e+00
   3.769036e+00 -9.810000e+00]
 ...
 [-5.660000e-02  3.120000e-02  2.070000e-03 ...  1.000000e+00
   5.644665e+00 -9.810000e+00]
 [-5.540000e-02  3.070000e-02  2.010000e-03 ...  1.000000e+00
   5.644665e+00 -9.810000e+00]
 [-5.410000e-02  3.000000e-02  1.970000e-03 ...  1.000000e+00
   5.644665e+00 -9.810000e+00]]
[[ 7.590308e+02  6.188970e+02  6.527847e+01 ...  1.000000e+00
   2.154590e+00 -9.810000e+00]
 [ 1.831100e+00 -1.788700e+00 -1.203100e-01 ...  1.000000e+00
   2.154590e+00 -9.810000e+00]
 [ 1.818700e+00 -1.777200e+00 -1.191100e-01 ...  1.000000e+00
   2.154590e+00 -9.810000e+00]
 ...
 [-3.470000e-02  4.080000e-02  3.370000e-03 ...  1.000000e+00
   5.216365e+00 -9.810000e+00]
 [-3.380000e-02  3.980000e-02  3.280000e-03 ...  1.000000e+00
   5.216365e+00 -9.810000e+00]
 [-3.300000e-02  3.880000e-02  3.210000e-03 ...  1.000000e+00
   5.216365e+00 -9.810000e+00]]
[[ 1.020831e+03  5.090054e+02  5.869971e+01 ...  1.000000e+00
   5.605856e+00 -9.810000e+00]
 [-3.481000e+00  1.880500e+00  1.018800e-01 ...  1.000000e+00
   5.605856e+00 -9.810000e+00]
 [-3.426000e+00  1.864400e+00  1.013900e-01 ...  1.000000e+00
   5.605856e+00 -9.810000e+00]
 ...
 [ 1.270000e-01 -6.050000e-02 -3.200000e-03 ...  1.000000e+00
   2.467326e+00 -9.810000e+00]
 [ 1.230000e-01 -5.890000e-02 -3.130000e-03 ...  1.000000e+00
   2.467326e+00 -9.810000e+00]
 [ 1.210000e-01 -5.760000e-02 -3.040000e-03 ...  1.000000e+00
   2.467326e+00 -9.810000e+00]]
[[ 1.357991e+03  6.535572e+02  6.811136e+01 ...  1.000000e+00
   1.005492e+00 -9.810000e+00]
 [-9.810000e-01 -1.748900e+00 -1.298700e-01 ...  1.000000e+00
   1.005492e+00 -9.810000e+00]
 [-9.720000e-01 -1.739700e+00 -1.286800e-01 ...  1.000000e+00
   1.005492e+00 -9.810000e+00]
 ...
 [-6.100000e-02 -8.250000e-02 -3.300000e-03 ...  1.000000e+00
   9.326661e-01 -9.810000e+00]
 [-6.000000e-02 -8.030000e-02 -3.230000e-03 ...  1.000000e+00
   9.326661e-01 -9.810000e+00]
 [-5.800000e-02 -7.850000e-02 -3.140000e-03 ...  1.000000e+00
   9.326661e-01 -9.810000e+00]][[ 8.897294e+02  5.332112e+02  5.999523e+01 ...  1.000000e+00
   8.209761e-01 -9.810000e+00]
 [-3.354300e+00 -2.511300e+00 -1.455800e-01 ...  1.000000e+00
   8.209761e-01 -9.810000e+00]
 [-3.330900e+00 -2.511900e+00 -1.449100e-01 ...  1.000000e+00
   8.209761e-01 -9.810000e+00]
 ...
 [ 7.320000e-02  3.250000e-02  1.680000e-03 ...  1.000000e+00
   3.761227e+00 -9.810000e+00]
 [ 7.150000e-02  3.190000e-02  1.620000e-03 ...  1.000000e+00
   3.761227e+00 -9.810000e+00]
 [ 6.950000e-02  3.110000e-02  1.580000e-03 ...  1.000000e+00
   3.761227e+00 -9.810000e+00]]

[[ 7.152297e+02  5.266582e+02  5.953426e+01 ...  1.000000e+00
   2.574371e+00 -9.810000e+00]
 [ 2.488800e+00 -1.272800e+00 -7.066000e-02 ...  1.000000e+00
   2.574371e+00 -9.810000e+00]
 [ 2.451800e+00 -1.269100e+00 -7.031000e-02 ...  1.000000e+00
   2.574371e+00 -9.810000e+00]
 ...
 [ 1.310000e-01  7.910000e-02  5.020000e-03 ...  1.000000e+00
   3.940439e+00 -9.810000e+00]
 [ 1.280000e-01  7.740000e-02  4.910000e-03 ...  1.000000e+00
   3.940439e+00 -9.810000e+00]
 [ 1.250000e-01  7.540000e-02  4.790000e-03 ...  1.000000e+00
   3.940439e+00 -9.810000e+00]]
[[ 5.457042e+02  4.859584e+02  5.723996e+01 ...  1.000000e+00
   4.042369e+00 -9.810000e+00]
 [ 3.817500e+00  2.415700e+00  1.283400e-01 ...  1.000000e+00
   4.042369e+00 -9.810000e+00]
 [ 3.773100e+00  2.380400e+00  1.270400e-01 ...  1.000000e+00
   4.042369e+00 -9.810000e+00]
 ...
 [ 1.826000e-01 -6.730000e-02 -3.830000e-03 ...  1.000000e+00
   2.546786e+00 -9.810000e+00]
 [ 1.782000e-01 -6.560000e-02 -3.740000e-03 ...  1.000000e+00
   2.546786e+00 -9.810000e+00]
 [ 1.739000e-01 -6.400000e-02 -3.650000e-03 ...  1.000000e+00
   2.546786e+00 -9.810000e+00]]
===> [Minibatch 1/44].........tensor([[[ -3.4329,   2.7175,   0.0000,   5.4388],
         [ -3.3837,   2.6789,   0.0000,   5.4388],
         [ -3.3351,   2.6407,   0.0000,   5.4388],
         ...,
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000]],

        [[ -1.4930,  -1.5130,   0.0000,   0.9582],
         [ -1.4800,  -1.4987,   0.0000,   0.9582],
         [ -1.4650,  -1.4842,   0.0000,   0.9582],
         ...,
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000]],

        [[  3.1454,  -2.2696,   0.0000,   2.2802],
         [  3.1390,  -2.2613,   0.0000,   2.2802],
         [  3.1303,  -2.2542,   0.0000,   2.2802],
         ...,
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000]],

        ...,

        [[ -2.4632,  -1.4178,   0.0000,   0.7483],
         [ -2.4427,  -1.4070,   0.0000,   0.7483],
         [ -2.4227,  -1.3957,   0.0000,   0.7483],
         ...,
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000]],

        [[ -0.9103,   2.0937,   0.0000,   0.5612],
         [ -0.9177,   2.0613,   0.0000,   0.5612],
         [ -0.9253,   2.0286,   0.0000,   0.5612],
         ...,
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000]],

        [[  3.1982,   1.6179,   0.0000,   3.8502],
         [  3.1550,   1.5965,   0.0000,   3.8502],
         [  3.1124,   1.5750,   0.0000,   3.8502],
         ...,
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000],
         [-10.0000, -10.0000, -10.0000, -10.0000]]], device='cuda:0')
