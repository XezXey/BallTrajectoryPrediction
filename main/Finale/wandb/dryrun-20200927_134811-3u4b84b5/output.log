==============================================Features==============================================
Available features :  ['x-0', 'y-1', 'z-2', 'u-3', 'v-4', 'd-5', 'eot-6', 'og-7', 'rad-8', 'g-9']
Selected features :  [6, 8]
1. input_col =  [3, 4, 6, 8]
2. input_startpos_col =  [3, 4, 5, 6, 8]
3. output_col =  [5, 6, 8]
4. output_startpos_col =  [0, 1, 2, 6, 8]
5. output_xyz_col =  [0, 1, 2, 6, 8]
====================================================================================================
[#]Training : Trajectory Estimation
Mixed:   0%|                                                                                                | 0/3 [00:00<?, ?it/s]===============================Dataset shape===============================
Mixed: 100%|████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 31.93it/s]
Mixed : (5668,)
===========================================================================
Mixed:   0%|                                                                                                | 0/1 [00:00<?, ?it/s]===============================Dataset shape===============================
Mixed: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.68it/s]
Mixed : (1850,)
===========================================================================
======================================================Summary Batch (batch_size = 128)=========================================================================
torch.Size([1001, 3])
SUM :  tensor([[-3.2367, -3.2367, -3.4129],
        [ 0.1161,  0.1161, -0.0474],
        [ 0.1150,  0.1150, -0.0469],
        ...,
        [ 0.0075,  0.0075,  0.0137],
        [ 0.0073,  0.0073,  0.0134],
        [ 0.0071,  0.0071,  0.0131]])
NOT SUM :  tensor([[-3.2367e+00, -1.8173e-08, -1.7626e-01],
        [ 1.1606e-01, -2.3097e-08, -1.6344e-01],
        [ 1.1500e-01, -2.5084e-08, -1.6186e-01],
        ...,
        [ 7.4740e-03,  7.1526e-08,  6.2572e-03],
        [ 7.2930e-03, -2.6325e-08,  6.1068e-03],
        [ 7.1240e-03, -2.4587e-08,  5.9642e-03]])
None
torch.Size([157, 3])
torch.Size([1095, 3])
SUM :  tensor([[-3.5301e+00, -3.5301e+00, -1.3337e+01],
        [ 6.0926e-02,  2.5255e-01,  3.1680e-01],
        [ 6.0925e-02,  2.4982e-01,  3.1407e-01],
        ...,
        [ 7.7270e-03,  7.7271e-03,  1.3687e-02],
        [ 7.5410e-03,  7.5410e-03,  1.3361e-02],
        [ 7.3650e-03,  7.3650e-03,  1.3045e-02]])
NOT SUM :  tensor([[-3.5301e+00, -8.0261e-08, -9.8067e+00],
        [ 6.0926e-02,  1.9162e-01,  6.4248e-02],
        [ 6.0925e-02,  1.8890e-01,  6.4248e-02],
        ...,
        [ 7.7270e-03,  7.1526e-08,  5.9600e-03],
        [ 7.5410e-03, -2.3842e-08,  5.8200e-03],
        [ 7.3650e-03, -2.3842e-08,  5.6800e-03]])
None
SUM :  tensor([[ 1.1017e+01,  1.1017e+01,  4.6190e+00],
        [-1.7646e-01, -1.7646e-01, -6.7950e-02],
        [-1.7507e-01, -1.7507e-01, -6.7951e-02],
        [-1.7351e-01, -1.7351e-01, -6.7485e-02],
        [-1.7189e-01, -1.7189e-01, -6.6883e-02],
        [-1.7027e-01, -1.7027e-01, -6.6264e-02],
        [-1.6864e-01, -1.6864e-01, -6.5626e-02],
        [-1.6701e-01, -1.6701e-01, -6.4997e-02],
        [-1.6539e-01, -1.6539e-01, -6.4364e-02],
        [-1.6376e-01, -1.6376e-01, -6.3730e-02],
        [-1.6213e-01, -1.6213e-01, -6.3096e-02],
        [-1.6050e-01, -1.6050e-01, -6.2463e-02],
        [-1.5887e-01, -1.5887e-01, -6.1830e-02],
        [-1.5724e-01, -1.5725e-01, -6.1195e-02],
        [-1.5562e-01, -1.5562e-01, -6.0562e-02],
        [-1.5399e-01, -1.5399e-01, -5.9929e-02],
        [-1.5236e-01, -1.5236e-01, -5.9295e-02],
        [-1.5074e-01, -1.5074e-01, -5.8662e-02],
        [-1.4911e-01, -1.4911e-01, -5.8029e-02],
        [-1.4748e-01, -1.4748e-01, -5.7395e-02],
        [-1.4585e-01, -1.4585e-01, -5.6761e-02],
        [-1.4422e-01, -1.4422e-01, -5.6128e-02],
        [-1.4260e-01, -1.4260e-01, -5.5495e-02],
        [-1.4097e-01, -1.4097e-01, -5.4860e-02],
        [-1.3934e-01, -1.3934e-01, -5.4227e-02],
        [-1.3771e-01, -1.3771e-01, -5.3594e-02],
        [-1.3608e-01, -1.3608e-01, -5.2960e-02],
        [-1.3446e-01, -1.3446e-01, -5.2328e-02],
        [-1.3283e-01, -1.3283e-01, -5.1693e-02],
        [-1.3120e-01, -1.3120e-01, -5.1060e-02],
        [-1.2957e-01, -1.2957e-01, -5.0426e-02],
        [-1.2794e-01, -1.2794e-01, -4.9792e-02],
        [-1.2632e-01, -1.2632e-01, -4.9160e-02],
        [-1.2469e-01, -1.2469e-01, -4.8525e-02],
        [-1.2306e-01, -1.2306e-01, -4.7892e-02],
        [-1.2143e-01, -1.2143e-01, -4.7259e-02],
        [-1.1981e-01, -1.1981e-01, -4.6625e-02],
        [-1.1818e-01, -1.1818e-01, -4.5991e-02],
        [-1.1655e-01, -1.1655e-01, -4.5358e-02],
        [-1.1492e-01, -1.1492e-01, -4.4725e-02],
        [-1.1329e-01, -1.1329e-01, -4.4091e-02],
        [-1.1167e-01, -1.1167e-01, -4.3458e-02],
        [-1.1004e-01, -1.1004e-01, -4.2824e-02],
        [-1.0841e-01, -1.0841e-01, -4.2190e-02],
        [-1.0678e-01, -1.0678e-01, -4.1557e-02],
        [-1.0515e-01, -1.0516e-01, -4.0923e-02],
        [-1.0353e-01, -1.0353e-01, -4.0290e-02],
        [-1.0190e-01, -1.0190e-01, -3.9656e-02],
        [-1.0027e-01, -1.0027e-01, -3.9024e-02],
        [-9.8643e-02, -9.8643e-02, -3.8389e-02],
        [-9.7016e-02, -9.7016e-02, -3.7756e-02],
        [-9.5388e-02, -9.5388e-02, -3.7123e-02],
        [-9.3760e-02, -9.3760e-02, -3.6489e-02],
        [-9.2132e-02, -9.2132e-02, -3.5855e-02],
        [-9.0504e-02, -9.0504e-02, -3.5222e-02],
        [-8.8877e-02, -8.8877e-02, -3.4589e-02],
        [-8.7248e-02, -8.7248e-02, -3.3954e-02],
        [-8.5621e-02, -8.5621e-02, -3.3321e-02],
        [-8.3993e-02, -8.3993e-02, -3.2688e-02],
        [-8.2365e-02, -8.2365e-02, -3.2054e-02],
        [-8.0738e-02, -8.0738e-02, -3.1422e-02],
        [-7.9109e-02, -7.9109e-02, -3.0787e-02],
        [-7.7481e-02, -7.7481e-02, -3.0153e-02],
        [-7.5854e-02, -7.5854e-02, -2.9520e-02],
        [-7.4226e-02, -7.4226e-02, -2.8887e-02],
        [-7.2598e-02, -7.2598e-02, -2.8254e-02],
        [-7.0970e-02, -7.0970e-02, -2.7619e-02],
        [-6.9343e-02, -6.9343e-02, -2.6987e-02],
        [-6.7714e-02, -6.7714e-02, -2.6352e-02],
        [-6.6087e-02, -6.6087e-02, -2.5720e-02],
        [-6.4459e-02, -6.4459e-02, -2.5085e-02],
        [-6.2831e-02, -6.2831e-02, -2.4453e-02],
        [-6.1203e-02, -6.1203e-02, -2.3818e-02],
        [-5.9575e-02, -5.9575e-02, -2.3185e-02],
        [-5.7948e-02, -5.7948e-02, -2.2552e-02],
        [-5.6319e-02, -5.6319e-02, -2.1918e-02],
        [-5.4692e-02, -5.4692e-02, -2.1284e-02],
        [-5.3064e-02, -5.3064e-02, -2.0652e-02],
        [-5.1436e-02, -5.1436e-02, -2.0017e-02],
        [-4.9808e-02, -4.9808e-02, -1.9384e-02],
        [-4.8366e-02, -4.8366e-02, -1.8823e-02],
        [-4.7213e-02, -4.7213e-02, -1.8375e-02],
        [-4.6088e-02, -4.6088e-02, -1.7936e-02],
        [-4.4991e-02, -4.4991e-02, -1.7509e-02],
        [-4.3920e-02, -4.3920e-02, -1.7093e-02],
        [-4.2874e-02, -4.2874e-02, -1.6685e-02],
        [-4.1853e-02, -4.1853e-02, -1.6288e-02],
        [-4.0856e-02, -4.0856e-02, -1.5900e-02],
        [-3.9884e-02, -3.9884e-02, -1.5522e-02],
        [-3.8934e-02, -3.8934e-02, -1.5152e-02],
        [-3.8008e-02, -3.8008e-02, -1.4792e-02],
        [-3.7102e-02, -3.7102e-02, -1.4439e-02],
        [-3.6219e-02, -3.6219e-02, -1.4095e-02],
        [-3.5356e-02, -3.5356e-02, -1.3759e-02],
        [-3.4515e-02, -3.4515e-02, -1.3433e-02],
        [-3.3693e-02, -3.3693e-02, -1.3112e-02],
        [-3.2891e-02, -3.2891e-02, -1.2800e-02],
        [-3.2107e-02, -3.2107e-02, -1.2495e-02],
        [-3.1343e-02, -3.1343e-02, -1.2198e-02],
        [-3.0597e-02, -3.0597e-02, -1.1908e-02],
        [-2.9869e-02, -2.9869e-02, -1.1625e-02],
        [-2.9157e-02, -2.9157e-02, -1.1347e-02],
        [-2.8463e-02, -2.8463e-02, -1.1077e-02],
        [-2.7785e-02, -2.7785e-02, -1.0813e-02],
        [-2.7124e-02, -2.7124e-02, -1.0556e-02],
        [-2.6478e-02, -2.6478e-02, -1.0304e-02],
        [-2.5848e-02, -2.5848e-02, -1.0060e-02],
        [-2.5232e-02, -2.5232e-02, -9.8196e-03],
        [-2.4631e-02, -2.4631e-02, -9.5855e-03],
        [-2.4045e-02, -2.4045e-02, -9.3576e-03],
        [-2.3472e-02, -2.3472e-02, -9.1348e-03],
        [-2.2914e-02, -2.2914e-02, -8.9172e-03],
        [-2.2368e-02, -2.2368e-02, -8.7050e-03],
        [-2.1835e-02, -2.1835e-02, -8.4976e-03],
        [-2.1316e-02, -2.1316e-02, -8.2956e-03],
        [-2.0808e-02, -2.0808e-02, -8.0978e-03],
        [-2.0313e-02, -2.0313e-02, -7.9050e-03],
        [-1.9829e-02, -1.9829e-02, -7.7169e-03],
        [-1.9357e-02, -1.9357e-02, -7.5332e-03],
        [-1.8896e-02, -1.8896e-02, -7.3538e-03],
        [-1.8446e-02, -1.8446e-02, -7.1785e-03],
        [-1.8007e-02, -1.8007e-02, -7.0079e-03],
        [-1.7568e-02, -1.7568e-02, -6.8369e-03],
        [-1.7159e-02, -1.7159e-02, -6.6778e-03],
        [-1.6741e-02, -1.6741e-02, -6.5153e-03],
        [-1.6351e-02, -1.6351e-02, -6.3634e-03],
        [-1.5954e-02, -1.5954e-02, -6.2087e-03],
        [-1.5581e-02, -1.5581e-02, -6.0638e-03],
        [-1.5203e-02, -1.5203e-02, -5.9166e-03],
        [-1.4848e-02, -1.4848e-02, -5.7784e-03],
        [-1.4488e-02, -1.4488e-02, -5.6382e-03],
        [-1.4149e-02, -1.4149e-02, -5.5064e-03],
        [-1.3806e-02, -1.3806e-02, -5.3729e-03],
        [-1.3483e-02, -1.3483e-02, -5.2471e-03],
        [-1.3156e-02, -1.3156e-02, -5.1201e-03],
        [-1.2848e-02, -1.2848e-02, -5.0002e-03],
        [-1.2537e-02, -1.2538e-02, -4.8794e-03],
        [-1.2243e-02, -1.2243e-02, -4.7647e-03],
        [-1.1947e-02, -1.1948e-02, -4.6497e-03],
        [-1.1667e-02, -1.1667e-02, -4.5406e-03],
        [-1.1385e-02, -1.1385e-02, -4.4309e-03],
        [-1.1118e-02, -1.1118e-02, -4.3268e-03],
        [-1.0850e-02, -1.0850e-02, -4.2224e-03],
        [-1.0595e-02, -1.0595e-02, -4.1233e-03],
        [-1.0339e-02, -1.0339e-02, -4.0237e-03],
        [-1.0096e-02, -1.0096e-02, -3.9291e-03],
        [-9.8527e-03, -9.8527e-03, -3.8344e-03],
        [-9.6210e-03, -9.6210e-03, -3.7442e-03],
        [-9.3891e-03, -9.3891e-03, -3.6540e-03],
        [-9.1683e-03, -9.1682e-03, -3.5681e-03],
        [-8.9473e-03, -8.9473e-03, -3.4820e-03],
        [-8.7316e-03, -8.7316e-03, -3.3981e-03],
        [-8.5285e-03, -8.5284e-03, -3.3190e-03],
        [-8.3231e-03, -8.3231e-03, -3.2391e-03],
        [-8.1227e-03, -8.1227e-03, -3.1611e-03],
        [-7.9334e-03, -7.9334e-03, -3.0875e-03],
        [-7.7425e-03, -7.7424e-03, -3.0131e-03]])
torch.Size([646, 3])
torch.Size([967, 3])
SUM :  tensor([[ 7.4891e+00,  7.4891e+00,  2.0729e+00],
        [-4.3542e-02,  1.4188e-01,  5.9275e-02],
        [-4.3542e-02,  1.3916e-01,  5.6549e-02],
        ...,
        [ 7.3730e-03,  7.3720e-03,  1.3562e-02],
        [ 7.2020e-03,  7.2018e-03,  1.3242e-02],
        [ 7.0290e-03,  7.0290e-03,  1.2929e-02]])
NOT SUM :  tensor([[ 7.4891e+00, -1.3834e-08, -5.4161e+00],
        [-4.3542e-02,  1.8542e-01, -8.2607e-02],
        [-4.3542e-02,  1.8270e-01, -8.2608e-02],
        ...,
        [ 7.3730e-03, -1.0014e-06,  6.1900e-03],
        [ 7.2020e-03, -1.9073e-07,  6.0400e-03],
        [ 7.0290e-03, -2.3842e-08,  5.9000e-03]])
None
SUM :  tensor([[ 9.1428e+00,  9.1428e+00, -4.0563e+00],
        [-2.1326e-01, -2.1326e-01, -6.9203e-04],
        [-2.1194e-01, -2.1194e-01, -7.4003e-04],
        ...,
        [ 2.3700e-03,  2.3603e-03, -9.3566e-04],
        [ 2.3140e-03,  2.3121e-03, -9.0691e-04],
        [ 2.2510e-03,  2.2506e-03, -8.8043e-04]])
torch.Size([1094, 3])
NOT SUM :  tensor([[ 9.1428e+00, -2.6134e-08, -1.3199e+01],
        [-2.1326e-01, -2.3842e-08,  2.1257e-01],
        [-2.1194e-01, -2.3842e-08,  2.1120e-01],
        ...,
        [ 2.3700e-03, -9.6560e-06, -3.2960e-03],
        [ 2.3140e-03, -1.9073e-06, -3.2190e-03],
        [ 2.2510e-03, -4.2915e-07, -3.1310e-03]])
None
NOT SUM :  tensor([[ 1.1017e+01, -2.1859e-08, -6.3985e+00],
        [-1.7646e-01, -2.3842e-08,  1.0851e-01],
        [-1.7507e-01, -2.3842e-08,  1.0712e-01],
        [-1.7351e-01,  7.1526e-08,  1.0603e-01],
        [-1.7189e-01, -2.3842e-08,  1.0501e-01],
        [-1.7027e-01, -2.3842e-08,  1.0401e-01],
        [-1.6864e-01, -2.3842e-08,  1.0301e-01],
        [-1.6701e-01,  7.1526e-08,  1.0202e-01],
        [-1.6539e-01, -2.3842e-08,  1.0102e-01],
        [-1.6376e-01, -2.3842e-08,  1.0003e-01],
        [-1.6213e-01, -2.3842e-08,  9.9033e-02],
        [-1.6050e-01,  7.1526e-08,  9.8039e-02],
        [-1.5887e-01, -2.3842e-08,  9.7044e-02],
        [-1.5724e-01, -2.3842e-08,  9.6050e-02],
        [-1.5562e-01, -2.3842e-08,  9.5056e-02],
        [-1.5399e-01,  7.1526e-08,  9.4061e-02],
        [-1.5236e-01, -2.3842e-08,  9.3067e-02],
        [-1.5074e-01, -2.3842e-08,  9.2073e-02],
        [-1.4911e-01, -2.3842e-08,  9.1078e-02],
        [-1.4748e-01,  7.1526e-08,  9.0084e-02],
        [-1.4585e-01, -2.3842e-08None
,  8.9090e-02],
        [-1.4422e-01, -2.3842e-08,  8.8095e-02],
        [-1.4260e-01, -2.3842e-08,  8.7101e-02],
        [-1.4097e-01,  7.1526e-08,  8.6107e-02],
        [-1.3934e-01, -2.3842e-08,  8.5112e-02],
        [-1.3771e-01, -2.3842e-08,  8.4118e-02],
        [-1.3608e-01, -2.3842e-08,  8.3124e-02],
        [-1.3446e-01,  7.1526e-08,  8.2129e-02],
        [-1.3283e-01, -2.3842e-08,  8.1135e-02],
        [-1.3120e-01, -2.3842e-08,  8.0140e-02],
        [-1.2957e-01, -2.3842e-08,  7.9147e-02],
        [-1.2794e-01,  7.1526e-08,  7.8152e-02],
        [-1.2632e-01, -2.3842e-08,  7.7157e-02],
        [-1.2469e-01, -2.3842e-08,  7.6164e-02],
        [-1.2306e-01, -2.3842e-08,  7.5169e-02],
        [-1.2143e-01,  7.1526e-08,  7.4175e-02],
        [-1.1981e-01, -2.3842e-08,  7.3180e-02],
        [-1.1818e-01, -2.3842e-08,  7.2186e-02],
        [-1.1655e-01, -2.3842e-08,  7.1192e-02],
        [-1.1492e-01,  7.1526e-08,  7.0197e-02],
        [-1.1329e-01, -2.3842e-08,  6.9203e-02],
        [-1.1167e-01, -2.3842e-08,  6.8209e-02],
        [-1.1004e-01, -2.3842e-08,  6.7214e-02],
        [-1.0841e-01,  7.1526e-08,  6.6220e-02],
        [-1.0678e-01, -2.3842e-08,  6.5226e-02],
        [-1.0515e-01, -2.3842e-08,  6.4232e-02],
        [-1.0353e-01, -2.3842e-08,  6.3237e-02],
        [-1.0190e-01,  7.1526e-08,  6.2243e-02],
        [-1.0027e-01, -2.3842e-08,  6.1248e-02],
        [-9.8643e-02, -2.3842e-08,  6.0254e-02],
        [-9.7016e-02, -2.3842e-08,  5.9260e-02],
        [-9.5388e-02,  7.1526e-08,  5.8265e-02],
        [-9.3760e-02, -2.3842e-08,  5.7271e-02],
        [-9.2132e-02, -2.3842e-08,  5.6277e-02],
        [-9.0504e-02, -2.3842e-08,  5.5282e-02],
        [-8.8877e-02,  6.4323e-08,  5.4288e-02],
        [-8.7248e-02, -3.8495e-08,  5.3294e-02],
        [-8.5621e-02, -1.6640e-08,  5.2300e-02],
        [-8.3993e-02,  7.8728e-08,  5.1305e-02],
        [-8.2365e-02, -3.1044e-08,  5.0311e-02],
        [-8.0738e-02, -1.6640e-08,  4.9316e-02],
        [-7.9109e-02, -2.3842e-08,  4.8322e-02],
        [-7.7481e-02, -2.3842e-08,  4.7328e-02],
        [-7.5854e-02,  5.6873e-08,  4.6334e-02],
        [-7.4226e-02, -1.6640e-08,  4.5339e-02],
        [-7.2598e-02, -1.6640e-08,  4.4344e-02],
        [-7.0970e-02, -9.1890e-09,  4.3351e-02],
        [-6.9343e-02,  7.1526e-08,  4.2356e-02],
        [-6.7714e-02, -3.1044e-08,  4.1362e-02],
        [-6.6087e-02, -3.1044e-08,  4.0367e-02],
        [-6.4459e-02, -2.3842e-08,  3.9374e-02],
        [-6.2831e-02,  8.6427e-08,  3.8378e-02],
        [-6.1203e-02, -1.6640e-08,  3.7385e-02],
        [-5.9575e-02, -1.6640e-08,  3.6390e-02],
        [-5.7948e-02, -3.8743e-08,  3.5396e-02],
        [-5.6319e-02,  7.1526e-08,  3.4401e-02],
        [-5.4692e-02, -2.3842e-08,  3.3408e-02],
        [-5.3064e-02, -2.3842e-08,  3.2412e-02],
        [-5.1436e-02, -1.6640e-08,  3.1419e-02],
        [-4.9808e-02, -3.1044e-08,  3.0424e-02],
        [-4.8366e-02,  5.6873e-08,  2.9543e-02],
        [-4.7213e-02, -2.7567e-08,  2.8839e-02],
        [-4.6088e-02, -2.0365e-08,  2.8152e-02],
        [-4.4991e-02,  8.1708e-08,  2.7482e-02],
        [-4.3920e-02, -1.7136e-08,  2.6827e-02],
        [-4.2874e-02, -1.4156e-08,  2.6189e-02],
        [-4.1853e-02, -2.3842e-08,  2.5565e-02],
        [-4.0856e-02, -1.7881e-08,  2.4956e-02],
        [-3.9884e-02,  7.1526e-08,  2.4362e-02],
        [-3.8934e-02, -2.6822e-08,  2.3782e-02],
        [-3.8008e-02, -1.8130e-08,  2.3216e-02],
        [-3.7102e-02, -2.0862e-08,  2.2663e-02],
        [-3.6219e-02,  7.6989e-08,  2.2124e-02],
        [-3.5356e-02, -2.3842e-08,  2.1597e-02],
        [-3.4515e-02, -1.5895e-08,  2.1082e-02],
        [-3.3693e-02, -2.1110e-08,  2.0581e-02],
        [-3.2891e-02, -3.1292e-08,  2.0091e-02],
        [-3.2107e-02,  6.4075e-08,  1.9612e-02],
        [-3.1343e-02, -2.6325e-08,  1.9145e-02],
        [-3.0597e-02, -1.6888e-08,  1.8689e-02],
        [-2.9869e-02, -2.6325e-08,  1.8244e-02],
        [-2.9157e-02,  6.4820e-08,  1.7810e-02],
        [-2.8463e-02, -1.9620e-08,  1.7386e-02],
        [-2.7785e-02, -1.9620e-08,  1.6972e-02],
        [-2.7124e-02, -1.8875e-08,  1.6568e-02],
        [-2.6478e-02,  6.9539e-08,  1.6174e-02],
        [-2.5848e-02, -2.8809e-08,  1.5788e-02],
        [-2.5232e-02, -2.2848e-08,  1.5412e-02],
        [-2.4631e-02, -2.6822e-08,  1.5046e-02],
        [-2.4045e-02,  7.3264e-08,  1.4687e-02],
        [-2.3472e-02, -2.8312e-08,  1.4337e-02],
        [-2.2914e-02, -2.6077e-08,  1.3996e-02],
        [-2.2368e-02,  7.7238e-08,  1.3663e-02],
        [-2.1835e-02, -2.2352e-08,  1.3338e-02],
        [-2.1316e-02, -2.5829e-08,  1.3020e-02],
        [-2.0808e-02, -2.4090e-08,  1.2710e-02],
        [-2.0313e-02,  7.1277e-08,  1.2408e-02],
        [-1.9829e-02, -2.8064e-08,  1.2112e-02],
        [-1.9357e-02, -2.5332e-08,  1.1824e-02],
        [-1.8896e-02, -2.5084e-08,  1.1542e-02],
        [-1.8446e-02,  7.2022e-08,  1.1267e-02],
        [-1.8007e-02, -2.4587e-08,  1.0999e-02],
        [-1.7568e-02, -1.8875e-08,  1.0731e-02],
        [-1.7159e-02, -2.3097e-08,  1.0481e-02],
        [-1.6741e-02,  7.6989e-08,  1.0226e-02],
        [-1.6351e-02, -2.6822e-08,  9.9877e-03],
        [-1.5954e-02, -2.3594e-08,  9.7449e-03],
        [-1.5581e-02, -1.9620e-08,  9.5175e-03],
        [-1.5203e-02, -2.3345e-08,  9.2864e-03],
        [-1.4848e-02,  7.2271e-08,  9.0694e-03],
        [-1.4488e-02, -2.4835e-08,  8.8495e-03],
        [-1.4149e-02, -2.0365e-08,  8.6425e-03],
        [-1.3806e-02, -2.8809e-08,  8.4331e-03],
        [-1.3483e-02,  7.4009e-08,  8.2357e-03],
        [-1.3156e-02, -2.6325e-08,  8.0363e-03],
        [-1.2848e-02, -2.1110e-08,  7.8480e-03],
        [-1.2537e-02, -2.6325e-08,  7.6582e-03],
        [-1.2243e-02,  7.5251e-08,  7.4786e-03],
        [-1.1947e-02, -2.5084e-08,  7.2978e-03],
        [-1.1667e-02, -2.5332e-08,  7.1266e-03],
        [-1.1385e-02, -2.1358e-08,  6.9545e-03],
        [-1.1118e-02,  7.0035e-08,  6.7912e-03],
        [-1.0850e-02, -2.7319e-08,  6.6273e-03],
        [-1.0595e-02, -2.1358e-08,  6.4716e-03],
        [-1.0339e-02, -2.0613e-08,  6.3154e-03],
        [-1.0096e-02,  6.9539e-08,  6.1670e-03],
        [-9.8527e-03, -2.4835e-08,  6.0183e-03],
        [-9.6210e-03, -2.0862e-08,  5.8768e-03],
        [-9.3891e-03, -2.6077e-08,  5.7351e-03],
        [-9.1683e-03,  6.8297e-08,  5.6002e-03],
        [-8.9473e-03, -2.1607e-08,  5.4653e-03],
        [-8.7316e-03, -2.7070e-08,  5.3335e-03],
        [-8.5285e-03,  7.1774e-08,  5.2094e-03],
        [-8.3231e-03, -2.4339e-08,  5.0840e-03],
        [-8.1227e-03, -2.5580e-08,  4.9616e-03],
        [-7.9334e-03, -2.3594e-08,  4.8459e-03],
        [-7.7425e-03,  6.9042e-08,  4.7293e-03]])
SUM :  tensor([[ 8.3009e+00,  8.3009e+00, -4.8782e-01],
        [-1.0563e-01, -1.0563e-01,  6.4204e-02],
        [-1.0451e-01, -1.0451e-01,  6.3772e-02],
        ...,
        [-6.6870e-03, -6.6870e-03, -1.3690e-02],
        [-6.5270e-03, -6.5269e-03, -1.3362e-02],
        [-6.3690e-03, -6.3690e-03, -1.3039e-02]])
torch.Size([565, 3])
torch.Size([1061, 3])
NOT SUM :  tensor([[ 8.3009e+00, -9.9025e-09, -8.7887e+00],
        [-1.0563e-01, -2.3842e-08,  1.6983e-01],
        [-1.0451e-01, -2.3842e-08,  1.6828e-01],
        ...,
        [-6.6870e-03, -2.3842e-08, -7.0030e-03],
        [-6.5270e-03,  7.1526e-08, -6.8350e-03],
        [-6.3690e-03, -2.3842e-08, -6.6700e-03]])
None
SUM :  tensor([[-4.6083e+00, -4.6083e+00,  4.6816e+00],
        [ 9.2925e-02,  9.2925e-02, -8.6298e-02],
        [ 9.1991e-02,  9.1991e-02, -8.5568e-02],
        ...,
        [-7.5250e-03, -7.5401e-03, -1.6111e-03],
        [-7.3450e-03, -7.3481e-03, -1.5631e-03],
        [-7.1670e-03, -7.1676e-03, -1.5216e-03]])
SUM :  tensor([[-2.8079e+00, -2.8079e+00, -2.0721e+01],
        [ 1.8688e-01,  1.8688e-01,  2.7727e-01],
        [ 1.8523e-01,  1.8523e-01,  2.7464e-01],
        ...,
        [ 6.3740e-03,  6.3741e-03, -9.0193e-04],
        [ 6.2200e-03,  6.2200e-03, -8.8002e-04],
        [ 6.0710e-03,  6.0710e-03, -8.5902e-04]])
NOT SUM :  tensor([[-2.8079e+00, -7.2674e-08, -1.7913e+01],
        [ 1.8688e-01,  7.2767e-08,  9.0390e-02],
        [ 1.8523e-01, -2.3097e-08,  8.9410e-02],
        ...,
        [ 6.3740e-03,  7.1526e-08, -7.2760e-03],
        [ 6.2200e-03, -2.3842e-08, -7.1000e-03],
        [ 6.0710e-03, -2.3842e-08, -6.9300e-03]])NOT SUM :  tensor([[-4.6083e+00, -2.0384e-08,  9.2899e+00],
        [ 9.2925e-02, -2.3842e-08, -1.7922e-01],
        [ 9.1991e-02, -2.3842e-08, -1.7756e-01],
        ...,
        [-7.5250e-03, -1.5089e-05,  5.9290e-03],
        [-7.3450e-03, -3.0518e-06,  5.7850e-03],
        [-7.1670e-03, -6.0151e-07,  5.6460e-03]])

None
None
torch.Size([1119, 3])
torch.Size([1188, 3])
SUM :  tensor([[-2.5784e+00, -2.5784e+00, -1.2096e+01],
        [ 1.4164e-01,  1.4163e-01,  2.5442e-01],
        [ 1.4070e-01,  1.4070e-01,  2.5160e-01],
        ...,
        [-6.7530e-03, -6.7530e-03, -1.3786e-02],
        [-6.5900e-03, -6.5900e-03, -1.3453e-02],
        [-6.4370e-03, -6.4369e-03, -1.3141e-02]])SUM :  tensor([[-1.2894e+00, -1.2894e+00, -1.8178e+01],
        [ 1.1544e-01,  1.1544e-01,  2.1300e-01],
        [ 1.1408e-01,  1.1408e-01,  2.1029e-01],
        ...,
        [-4.0864e-03, -4.0864e-03,  4.8116e-03],
        [-3.9879e-03, -3.9879e-03,  4.6961e-03],
        [-3.8949e-03, -3.8949e-03,  4.5871e-03]])

NOT SUM :  tensor([[-1.2894e+00, -3.6432e-08, -1.6889e+01],
        [ 1.1544e-01, -2.3345e-08,  9.7560e-02],
        [ 1.1408e-01,  7.1526e-08,  9.6210e-02],
        ...,
        [-4.0864e-03, -2.4339e-08,  8.8980e-03],
        [-3.9879e-03, -2.3842e-08,  8.6840e-03],
        [-3.8949e-03, -2.3842e-08,  8.4820e-03]])NOT SUM :  tensor([[-2.5784e+00, -5.4042e-08, -9.5174e+00],
        [ 1.4164e-01, -2.1110e-08,  1.1279e-01],
        [ 1.4070e-01,  7.1526e-08,  1.1090e-01],
        ...,
        [-6.7530e-03, -2.7319e-08, -7.0330e-03],
        [-6.5900e-03, -2.3842e-08, -6.8630e-03],
        [-6.4370e-03,  6.8297e-08, -6.7040e-03]])

None
None
Traceback (most recent call last):
  File "train_ball_trajectory_depth.py", line 294, in <module>
    for key, batch in enumerate(trajectory_train_dataloader):
  File "/home/puntawat/Mint/Work/Vision/working_environment/ball_venv3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 279, in __iter__
    return _MultiProcessingDataLoaderIter(self)
  File "/home/puntawat/Mint/Work/Vision/working_environment/ball_venv3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 704, in __init__
    index_queue = multiprocessing_context.Queue()
  File "/usr/lib/python3.6/multiprocessing/context.py", line 102, in Queue
    return Queue(maxsize, ctx=self.get_context())
  File "/usr/lib/python3.6/multiprocessing/queues.py", line 48, in __init__
    self._sem = ctx.BoundedSemaphore(maxsize)
  File "/usr/lib/python3.6/multiprocessing/context.py", line 87, in BoundedSemaphore
    return BoundedSemaphore(value, ctx=self.get_context())
  File "/usr/lib/python3.6/multiprocessing/synchronize.py", line 145, in __init__
    SemLock.__init__(self, SEMAPHORE, value, value, ctx=ctx)
  File "/usr/lib/python3.6/multiprocessing/synchronize.py", line 73, in __init__
    util.register_after_fork(self, _after_fork)
  File "/usr/lib/python3.6/multiprocessing/util.py", line 137, in register_after_fork
    _afterfork_registry[(next(_afterfork_counter), id(obj), func)] = obj
  File "/usr/lib/python3.6/weakref.py", line 168, in __setitem__
    self.data[key] = KeyedRef(value, self._remove, key)
  File "/usr/lib/python3.6/weakref.py", line 340, in __init__
    super().__init__(ob, callback)
  File "/home/puntawat/Mint/Work/Vision/working_environment/ball_venv3/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 31386) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
