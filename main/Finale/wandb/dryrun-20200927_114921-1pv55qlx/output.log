==============================================Features==============================================
Available features :  ['x-0', 'y-1', 'z-2', 'u-3', 'v-4', 'd-5', 'eot-6', 'og-7', 'rad-8', 'g-9']
Selected features :  [6, 8]
1. input_col =  [3, 4, 6, 8]
2. input_startpos_col =  [3, 4, 5, 6, 8]
3. output_col =  [5, 6, 8]
4. output_startpos_col =  [0, 1, 2, 6, 8]
5. output_xyz_col =  [0, 1, 2, 6, 8]
====================================================================================================
[#]Training : Trajectory Estimation
Mixed:   0%|                                                                                                | 0/3 [00:00<?, ?it/s]Mixed: 100%|████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 30.46it/s]
===============================Dataset shape===============================
Mixed : (5668,)
===========================================================================
Mixed:   0%|                                                                                                | 0/1 [00:00<?, ?it/s]Mixed: 100%|████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.64it/s]
===============================Dataset shape===============================
Mixed : (1850,)
===========================================================================
======================================================Summary Batch (batch_size = 128)=========================================================================
Input batch [0] : batch=torch.Size([128, 891, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 891, 4]), initial position=torch.Size([128, 1, 5])
gt batch [0] : batch=torch.Size([128, 891, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 892, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [1] : batch=torch.Size([128, 922, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 922, 4]), initial position=torch.Size([128, 1, 5])
gt batch [1] : batch=torch.Size([128, 922, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 923, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [2] : batch=torch.Size([128, 949, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 949, 4]), initial position=torch.Size([128, 1, 5])
gt batch [2] : batch=torch.Size([128, 949, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 950, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [3] : batch=torch.Size([128, 802, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 802, 4]), initial position=torch.Size([128, 1, 5])
gt batch [3] : batch=torch.Size([128, 802, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 803, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [4] : batch=torch.Size([128, 845, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 845, 4]), initial position=torch.Size([128, 1, 5])
gt batch [4] : batch=torch.Size([128, 845, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 846, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [5] : batch=torch.Size([128, 860, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 860, 4]), initial position=torch.Size([128, 1, 5])
gt batch [5] : batch=torch.Size([128, 860, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 861, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [6] : batch=torch.Size([128, 865, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 865, 4]), initial position=torch.Size([128, 1, 5])
gt batch [6] : batch=torch.Size([128, 865, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 866, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [7] : batch=torch.Size([128, 863, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 863, 4]), initial position=torch.Size([128, 1, 5])
gt batch [7] : batch=torch.Size([128, 863, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 864, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [8] : batch=torch.Size([128, 899, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 899, 4]), initial position=torch.Size([128, 1, 5])
gt batch [8] : batch=torch.Size([128, 899, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 900, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [9] : batch=torch.Size([128, 851, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 851, 4]), initial position=torch.Size([128, 1, 5])
gt batch [9] : batch=torch.Size([128, 851, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 852, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [10] : batch=torch.Size([128, 866, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 866, 4]), initial position=torch.Size([128, 1, 5])
gt batch [10] : batch=torch.Size([128, 866, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 867, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [11] : batch=torch.Size([128, 799, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 799, 4]), initial position=torch.Size([128, 1, 5])
gt batch [11] : batch=torch.Size([128, 799, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 800, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [12] : batch=torch.Size([128, 939, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 939, 4]), initial position=torch.Size([128, 1, 5])
gt batch [12] : batch=torch.Size([128, 939, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 940, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [13] : batch=torch.Size([128, 868, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 868, 4]), initial position=torch.Size([128, 1, 5])
gt batch [13] : batch=torch.Size([128, 868, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 869, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [14] : batch=torch.Size([128, 860, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 860, 4]), initial position=torch.Size([128, 1, 5])
gt batch [14] : batch=torch.Size([128, 860, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 861, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [15] : batch=torch.Size([128, 837, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 837, 4]), initial position=torch.Size([128, 1, 5])
gt batch [15] : batch=torch.Size([128, 837, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 838, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [16] : batch=torch.Size([128, 951, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 951, 4]), initial position=torch.Size([128, 1, 5])
gt batch [16] : batch=torch.Size([128, 951, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 952, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [17] : batch=torch.Size([128, 842, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 842, 4]), initial position=torch.Size([128, 1, 5])
gt batch [17] : batch=torch.Size([128, 842, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 843, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [18] : batch=torch.Size([128, 932, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 932, 4]), initial position=torch.Size([128, 1, 5])
gt batch [18] : batch=torch.Size([128, 932, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 933, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [19] : batch=torch.Size([128, 881, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 881, 4]), initial position=torch.Size([128, 1, 5])
gt batch [19] : batch=torch.Size([128, 881, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 882, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [20] : batch=torch.Size([128, 870, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 870, 4]), initial position=torch.Size([128, 1, 5])
gt batch [20] : batch=torch.Size([128, 870, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 871, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [21] : batch=torch.Size([128, 925, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 925, 4]), initial position=torch.Size([128, 1, 5])
gt batch [21] : batch=torch.Size([128, 925, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 926, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [22] : batch=torch.Size([128, 883, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 883, 4]), initial position=torch.Size([128, 1, 5])
gt batch [22] : batch=torch.Size([128, 883, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 884, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [23] : batch=torch.Size([128, 915, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 915, 4]), initial position=torch.Size([128, 1, 5])
gt batch [23] : batch=torch.Size([128, 915, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 916, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [24] : batch=torch.Size([128, 830, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 830, 4]), initial position=torch.Size([128, 1, 5])
gt batch [24] : batch=torch.Size([128, 830, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 831, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [25] : batch=torch.Size([128, 1002, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 1002, 4]), initial position=torch.Size([128, 1, 5])
gt batch [25] : batch=torch.Size([128, 1002, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 1003, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [26] : batch=torch.Size([128, 959, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 959, 4]), initial position=torch.Size([128, 1, 5])
gt batch [26] : batch=torch.Size([128, 959, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 960, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [27] : batch=torch.Size([128, 852, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 852, 4]), initial position=torch.Size([128, 1, 5])
gt batch [27] : batch=torch.Size([128, 852, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 853, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [28] : batch=torch.Size([128, 786, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 786, 4]), initial position=torch.Size([128, 1, 5])
gt batch [28] : batch=torch.Size([128, 786, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 787, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [29] : batch=torch.Size([128, 836, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 836, 4]), initial position=torch.Size([128, 1, 5])
gt batch [29] : batch=torch.Size([128, 836, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 837, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [30] : batch=torch.Size([128, 845, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 845, 4]), initial position=torch.Size([128, 1, 5])
gt batch [30] : batch=torch.Size([128, 845, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 846, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [31] : batch=torch.Size([128, 885, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 885, 4]), initial position=torch.Size([128, 1, 5])
gt batch [31] : batch=torch.Size([128, 885, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 886, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [32] : batch=torch.Size([128, 962, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 962, 4]), initial position=torch.Size([128, 1, 5])
gt batch [32] : batch=torch.Size([128, 962, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 963, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [33] : batch=torch.Size([128, 918, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 918, 4]), initial position=torch.Size([128, 1, 5])
gt batch [33] : batch=torch.Size([128, 918, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 919, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [34] : batch=torch.Size([128, 953, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 953, 4]), initial position=torch.Size([128, 1, 5])
gt batch [34] : batch=torch.Size([128, 953, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 954, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [35] : batch=torch.Size([128, 862, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 862, 4]), initial position=torch.Size([128, 1, 5])
gt batch [35] : batch=torch.Size([128, 862, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 863, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [36] : batch=torch.Size([128, 990, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 990, 4]), initial position=torch.Size([128, 1, 5])
gt batch [36] : batch=torch.Size([128, 990, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 991, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [37] : batch=torch.Size([128, 842, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 842, 4]), initial position=torch.Size([128, 1, 5])
gt batch [37] : batch=torch.Size([128, 842, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 843, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [38] : batch=torch.Size([128, 892, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 892, 4]), initial position=torch.Size([128, 1, 5])
gt batch [38] : batch=torch.Size([128, 892, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 893, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [39] : batch=torch.Size([128, 836, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 836, 4]), initial position=torch.Size([128, 1, 5])
gt batch [39] : batch=torch.Size([128, 836, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 837, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [40] : batch=torch.Size([128, 825, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 825, 4]), initial position=torch.Size([128, 1, 5])
gt batch [40] : batch=torch.Size([128, 825, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 826, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [41] : batch=torch.Size([128, 898, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 898, 4]), initial position=torch.Size([128, 1, 5])
gt batch [41] : batch=torch.Size([128, 898, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 899, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [42] : batch=torch.Size([128, 900, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 900, 4]), initial position=torch.Size([128, 1, 5])
gt batch [42] : batch=torch.Size([128, 900, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 901, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
Input batch [43] : batch=torch.Size([128, 992, 4]), lengths=torch.Size([128]), mask=torch.Size([128, 992, 4]), initial position=torch.Size([128, 1, 5])
gt batch [43] : batch=torch.Size([128, 992, 3]), lengths=torch.Size([128]), mask=torch.Size([128, 993, 5]), initial position=torch.Size([128, 1, 5])
Unpacked equality :  tensor(True)
===============================================================================================================================================================
===>No model checkpoint
[#] Define the Learning rate, Optimizer, Decay rate and Scheduler...
[#]Model Architecture
####### Model - EOT #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(2, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
####### Model - Depth #######
BiGRUResidualAdd(
  (recurrent_blocks): ModuleList(
    (0): GRU(4, 32, batch_first=True, bidirectional=True)
    (1): GRU(64, 32, batch_first=True, bidirectional=True)
    (2): GRU(64, 32, batch_first=True, bidirectional=True)
    (3): GRU(64, 32, batch_first=True, bidirectional=True)
  )
  (fc_blocks): Sequential(
    (0): Sequential(
      (0): Linear(in_features=64, out_features=32, bias=True)
      (1): ReLU()
    )
    (1): Sequential(
      (0): Linear(in_features=32, out_features=16, bias=True)
      (1): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=16, out_features=8, bias=True)
      (1): ReLU()
    )
    (3): Sequential(
      (0): Linear(in_features=8, out_features=4, bias=True)
      (1): ReLU()
    )
    (4): Sequential(
      (0): Linear(in_features=4, out_features=1, bias=True)
    )
  )
)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>[Epoch : 1/100000]<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[#]Learning rate (Depth & EOT) :  0.01
/home/puntawat/Mint/Work/Vision/BallTrajectory/BallTrajectoryProject_Branches/end_of_trajectory_flag/BallTrajectoryPrediction/main/Finale/loss.py:95: RuntimeWarning:

invalid value encountered in long_scalars

===> [Minibatch 1/44].........Train Loss : 672.142, Val Loss : 1566.111
======> Trajectory Loss : 519.992, Gravity Loss : 0.001, EndOfTrajectory Loss : 1.377, BelowGroundPenalize Loss : 0.000, Depth Loss : 0.014
torch.Size([128, 951, 1]) torch.Size([128, 951, 1]) torch.Size([128, 1, 1]) torch.Size([128, 952, 1])
torch.Size([128, 952, 1]) torch.Size([128, 952, 1]) torch.Size([128, 1, 1]) torch.Size([128, 952, 1])
[ 22 126  48 100  34]
0 22
(128, 952, 1)
[[-2.1334220e-08]
 [ 4.7741774e-01]
 [ 4.7582585e-01]
 [ 4.7458559e-01]
 [ 4.7458550e-01]
 [ 4.7331813e-01]
 [ 4.7405994e-01]
 [ 4.7356489e-01]
 [ 4.7363734e-01]
 [ 4.7298956e-01]
 [ 4.7347283e-01]
 [ 4.7356302e-01]
 [ 4.7272462e-01]
 [ 4.7390336e-01]
 [ 4.7308293e-01]
 [ 4.7483951e-01]
 [ 4.7403008e-01]
 [ 4.7413850e-01]
 [ 4.7447035e-01]
 [ 4.7454056e-01]
 [ 4.7456798e-01]
 [ 4.7506469e-01]
 [ 4.7442091e-01]
 [ 4.7518048e-01]
 [ 4.7555989e-01]
 [ 4.7480136e-01]
 [ 4.7525522e-01]
 [ 4.7498718e-01]
 [ 4.7563604e-01]
 [ 4.7629741e-01]
 [ 4.7612813e-01]
 [ 4.7636423e-01]
 [ 4.7640538e-01]
 [ 4.7633553e-01]
 [ 4.7633943e-01]
 [ 4.7630006e-01]
 [ 4.7651759e-01]
 [ 4.7627619e-01]
 [ 4.7642526e-01]
 [ 4.7636569e-01]
 [ 4.7645968e-01]
 [ 4.7684240e-01]
 [ 4.7713101e-01]
 [ 4.7706750e-01]
 [ 4.7730502e-01]
 [ 4.7702810e-01]
 [ 4.7697136e-01]
 [ 4.7767007e-01]
 [ 4.7738239e-01]
 [ 4.7773746e-01]
 [ 4.7786814e-01]
 [ 4.7724679e-01]
 [ 4.7770032e-01]
 [ 4.7774249e-01]
 [ 4.7822636e-01]
 [ 4.7791779e-01]
 [ 4.7863945e-01]
 [ 4.7789776e-01]
 [ 4.7825706e-01]
 [ 4.7790155e-01]
 [ 4.7894523e-01]
 [ 4.7826985e-01]
 [ 4.7820646e-01]
 [ 4.7880280e-01]
 [ 4.7839433e-01]
 [ 4.7885770e-01]
 [ 4.7887138e-01]
 [ 4.7843960e-01]
 [ 4.7860646e-01]
 [ 4.7867200e-01]
 [ 4.7909826e-01]
 [ 4.7870061e-01]
 [ 4.7925416e-01]
 [ 4.7934723e-01]
 [ 4.7899792e-01]
 [ 4.7903544e-01]
 [ 4.7926140e-01]
 [ 4.7900578e-01]
 [ 4.7904998e-01]
 [ 4.7956085e-01]
 [ 4.7876292e-01]
 [ 4.7879472e-01]
 [ 4.7929421e-01]
 [ 4.7944009e-01]
 [ 4.7979614e-01]
 [ 4.7975251e-01]
 [ 4.7929382e-01]
 [ 4.7926927e-01]
 [ 4.7874281e-01]
 [ 4.7952873e-01]
 [ 4.7969198e-01]
 [ 4.7947025e-01]
 [ 4.7978616e-01]
 [ 4.7981855e-01]
 [ 4.7974271e-01]
 [ 4.7939408e-01]
 [ 4.7979143e-01]
 [ 4.7951683e-01]
 [ 4.7998393e-01]
 [ 4.7975460e-01]
 [ 4.7990659e-01]
 [ 4.7956860e-01]
 [ 4.8000929e-01]
 [ 4.7951069e-01]
 [ 4.7967246e-01]
 [ 4.7953996e-01]
 [ 4.8009661e-01]
 [ 4.8002920e-01]
 [ 4.7957671e-01]
 [ 4.7948354e-01]
 [ 4.7973332e-01]
 [ 4.7989517e-01]
 [ 4.8006248e-01]
 [ 4.7974297e-01]
 [ 4.8004821e-01]
 [ 4.7980878e-01]
 [ 4.7962102e-01]
 [ 4.8011512e-01]
 [ 4.7997481e-01]
 [ 4.7976196e-01]
 [ 4.7987419e-01]
 [ 4.7978389e-01]
 [ 4.8029250e-01]
 [ 4.8006085e-01]
 [ 4.8001876e-01]
 [ 4.8023000e-01]
 [ 4.7992012e-01]
 [ 4.7934562e-01]
 [ 4.7998413e-01]
 [ 4.7992745e-01]
 [ 4.7985795e-01]
 [ 4.8002535e-01]
 [ 4.7996569e-01]
 [ 4.7990462e-01]
 [ 4.7984076e-01]
 [ 4.8002172e-01]
 [ 4.8007050e-01]
 [ 4.8004666e-01]
 [ 4.8024809e-01]
 [ 4.7969407e-01]
 [ 4.7980657e-01]
 [ 4.8007369e-01]
 [ 4.7998062e-01]
 [ 4.8042738e-01]
 [ 4.8020467e-01]
 [ 4.8003468e-01]
 [ 4.7960183e-01]
 [ 4.7973165e-01]
 [ 4.8020422e-01]
 [ 4.8025486e-01]
 [ 4.7997084e-01]
 [ 4.7977918e-01]
 [ 4.7963285e-01]
 [ 4.7988668e-01]
 [ 4.8042253e-01]
 [ 4.8007116e-01]
 [ 4.8018080e-01]
 [ 4.7992572e-01]
 [ 4.7929108e-01]
 [ 4.7980964e-01]
 [ 4.7960427e-01]
 [ 4.7984290e-01]
 [ 4.8057607e-01]
 [ 4.8022023e-01]
 [ 4.8041919e-01]
 [ 4.8029998e-01]
 [ 4.8015141e-01]
 [ 4.8021230e-01]
 [ 4.7988135e-01]
 [ 4.8010808e-01]
 [ 4.8008651e-01]
 [ 4.7979295e-01]
 [ 4.8010272e-01]
 [ 4.7997811e-01]
 [ 4.8030272e-01]
 [ 4.7977990e-01]
 [ 4.7984180e-01]
 [ 4.7992685e-01]
 [ 4.7985542e-01]
 [ 4.7985086e-01]
 [ 4.7973540e-01]
 [ 4.7982797e-01]
 [ 4.8006374e-01]
 [ 4.7989848e-01]
 [ 4.7992614e-01]
 [ 4.7999820e-01]
 [ 4.7964695e-01]
 [ 4.7984445e-01]
 [ 4.7991484e-01]
 [ 4.7998634e-01]
 [ 4.8016080e-01]
 [ 4.8007309e-01]
 [ 4.7979295e-01]
 [ 4.8001644e-01]
 [ 4.7997323e-01]
 [ 4.7999239e-01]
 [ 4.8005390e-01]
 [ 4.7992262e-01]
 [ 4.7992423e-01]
 [ 4.7991395e-01]
 [ 4.8000622e-01]
 [ 4.8006853e-01]
 [ 4.7996834e-01]
 [ 4.8018646e-01]
 [ 4.8013273e-01]
 [ 4.7993702e-01]
 [ 4.7970286e-01]
 [ 4.8002046e-01]
 [ 4.8018104e-01]
 [ 4.7995624e-01]
 [ 4.8011139e-01]
 [ 4.8000041e-01]
 [ 4.7990298e-01]
 [ 4.7994295e-01]
 [ 4.7999534e-01]
 [ 4.8009655e-01]
 [ 4.7989759e-01]
 [ 4.7986838e-01]
 [ 4.8014128e-01]
 [ 4.7991955e-01]
 [ 4.7996262e-01]
 [ 4.7973457e-01]
 [ 4.8008618e-01]
 [ 4.7992659e-01]
 [ 4.8005104e-01]
 [ 4.7985631e-01]
 [ 4.8004061e-01]
 [ 4.7991675e-01]
 [ 4.7997358e-01]
 [ 4.7999975e-01]
 [ 4.8009166e-01]
 [ 4.8000479e-01]
 [ 4.7979680e-01]
 [ 4.7987893e-01]
 [ 4.7990692e-01]
 [ 4.8004991e-01]
 [ 4.8003566e-01]
 [ 4.7983864e-01]
 [ 4.7998732e-01]
 [ 4.7993824e-01]
 [ 4.8014250e-01]
 [ 4.7949040e-01]
 [ 4.7989321e-01]
 [ 4.8030996e-01]
 [ 4.7997338e-01]
 [ 4.7993734e-01]
 [ 4.7993225e-01]
 [ 4.7992614e-01]
 [ 4.8022398e-01]
 [ 4.8001227e-01]
 [ 4.7994137e-01]
 [ 4.8023909e-01]
 [ 4.7981799e-01]
 [ 4.7995690e-01]
 [ 4.7989023e-01]
 [ 4.8009935e-01]
 [ 4.8000458e-01]
 [ 4.8032373e-01]
 [ 4.8011386e-01]
 [ 4.7994053e-01]
 [ 4.7990260e-01]
 [ 4.7965229e-01]
 [ 4.7991440e-01]
 [ 4.8004052e-01]
 [ 4.8007759e-01]
 [ 4.8018065e-01]
 [ 4.8008457e-01]
 [ 4.7978178e-01]
 [ 4.7997075e-01]
 [ 4.7990513e-01]
 [ 4.7990254e-01]
 [ 4.8013106e-01]
 [ 4.8032868e-01]
 [ 4.8002732e-01]
 [ 4.8000860e-01]
 [ 4.8006260e-01]
 [ 4.7998300e-01]
 [ 4.7988597e-01]
 [ 4.7994393e-01]
 [ 4.8001501e-01]
 [ 4.8022914e-01]
 [ 4.7999415e-01]
 [ 4.8002654e-01]
 [ 4.8011503e-01]
 [ 4.7993350e-01]
 [ 4.8005956e-01]
 [ 4.8019972e-01]
 [ 4.7975630e-01]
 [ 4.7984850e-01]
 [ 4.8021331e-01]
 [ 4.8021230e-01]
 [ 4.7982886e-01]
 [ 4.8007980e-01]
 [ 4.8020235e-01]
 [ 4.8029304e-01]
 [ 4.7984666e-01]
 [ 4.7963944e-01]
 [ 4.7999930e-01]
 [ 4.8004347e-01]
 [ 4.8016733e-01]
 [ 4.7993383e-01]
 [ 4.8004875e-01]
 [ 4.8002902e-01]
 [ 4.8008496e-01]
 [ 4.7962859e-01]
 [ 4.7992992e-01]
 [ 4.7983512e-01]
 [ 4.7981337e-01]
 [ 4.7965810e-01]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]
 [ 0.0000000e+00]]
Traceback (most recent call last):
  File "train_ball_trajectory_depth.py", line 371, in <module>
    cam_params_dict=cam_params_dict, visualization_path=args.visualization_path)
  File "train_ball_trajectory_depth.py", line 205, in train
    utils_func.make_visualize(input_train_dict=input_train_dict, gt_train_dict=gt_train_dict, input_val_dict=input_val_dict, gt_val_dict=gt_val_dict, pred_train_dict=pred_train_dict, pred_val_dict=pred_val_dict)
  File "/home/puntawat/Mint/Work/Vision/BallTrajectory/BallTrajectoryProject_Branches/end_of_trajectory_flag/BallTrajectoryPrediction/utils/utils_func.py", line 86, in make_visualize
    visualize_eot(pred=pred_train_dict['flag'], gt=gt_train_dict['d_with_f'][..., [1]], startpos=gt_train_dict['startpos'][..., [1]], lengths=gt_train_dict['lengths'][..., [1]], mask=gt_train_dict['mask'][..., [1]], fig=fig_eot, flag='Train', n_vis=n_vis, vis_idx=train_vis_idx)
  File "/home/puntawat/Mint/Work/Vision/BallTrajectory/BallTrajectoryProject_Branches/end_of_trajectory_flag/BallTrajectoryPrediction/utils/utils_func.py", line 151, in visualize_eot
    fig.add_trace(go.Scatter(x=np.arange(lengths[i]).reshape(-1,), y=pred[i][:lengths[i], :].reshape(-1,), mode='markers+lines', marker=marker_dict_pred, name="{}-EOT Predicted [{}], EOTLoss = {:.3f}".format(flag, i, eot_loss[i][0])), row=idx+1, col=col)
IndexError: index 22 is out of bounds for axis 0 with size 1
